---
layout: single
title:  "[ECC DS 10주차] 분류1_캐글 산단테르 고객 만족 예측
categories: ML
tags: [ECC, DS, Santander] 
author_profile: false
---

<head>
  <style>
    table.dataframe {
      white-space: normal;
      width: 100%;
      height: 240px;
      display: block;
      overflow: auto;
      font-family: Arial, sans-serif;
      font-size: 0.9rem;
      line-height: 20px;
      text-align: center;
      border: 0px !important;
    }

    table.dataframe th {
      text-align: center;
      font-weight: bold;
      padding: 8px;
    }

    table.dataframe td {
      text-align: center;
      padding: 8px;
    }

    table.dataframe tr:hover {
      background: #b8d1f3; 
    }

    .output_prompt {
      overflow: auto;
      font-size: 0.9rem;
      line-height: 1.45;
      border-radius: 0.3rem;
      -webkit-overflow-scrolling: touch;
      padding: 0.8rem;
      margin-top: 0;
      margin-bottom: 15px;
      font: 1rem Consolas, "Liberation Mono", Menlo, Courier, monospace;
      color: $code-text-color;
      border: solid 1px $border-color;
      border-radius: 0.3rem;
      word-break: normal;
      white-space: pre;
    }

  .dataframe tbody tr th:only-of-type {
      vertical-align: middle;
  }

  .dataframe tbody tr th {
      vertical-align: top;
  }

  .dataframe thead th {
      text-align: center !important;
      padding: 8px;
  }

  .page__content p {
      margin: 0 0 0px !important;
  }

  .page__content p > strong {
    font-size: 0.8rem !important;
  }

  </style>
</head>


# **0. 대회 소개**


- 370개의 피처로 주어진 데이터 세트를 기반으로 ```고객 만족 여부```를 예측하는 문제

- 피처 이름의 경우 모두 익명 처리됨 -> 이름만을 가지고 어떤 속성인지는 추정할 수 x

- 클래스 레이블: TARGET

  - 1: 불만족

  - 0: 만족

- 성능 평가 지표: ```ROC-AUC```

  - 대부분이 만족이고 불만족인 데이터는 **일부**일 것이기 때문

- 데이터 출처: https://www.kaggle.com/competitions/santander-customer-satisfaction/data


# **1. 데이터 전처리**


## **1-1. 라이브러리 import & 데이터 로딩**



```python
import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
import matplotlib
```


```python
cust_df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/ESAA 8기/YB/10주차/data/train_santander.csv",encoding = 'latin-1')
print('dataset shape:', cust_df.shape)
cust_df.head(3)
```

<pre>
dataset shape: (76020, 371)
</pre>

  <div id="df-a6e54d3f-3576-4ec3-8a91-9a46281d315b">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>var3</th>
      <th>var15</th>
      <th>imp_ent_var16_ult1</th>
      <th>imp_op_var39_comer_ult1</th>
      <th>imp_op_var39_comer_ult3</th>
      <th>imp_op_var40_comer_ult1</th>
      <th>imp_op_var40_comer_ult3</th>
      <th>imp_op_var40_efect_ult1</th>
      <th>imp_op_var40_efect_ult3</th>
      <th>...</th>
      <th>saldo_medio_var33_hace2</th>
      <th>saldo_medio_var33_hace3</th>
      <th>saldo_medio_var33_ult1</th>
      <th>saldo_medio_var33_ult3</th>
      <th>saldo_medio_var44_hace2</th>
      <th>saldo_medio_var44_hace3</th>
      <th>saldo_medio_var44_ult1</th>
      <th>saldo_medio_var44_ult3</th>
      <th>var38</th>
      <th>TARGET</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>2</td>
      <td>23</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>39205.17</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3</td>
      <td>2</td>
      <td>34</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>49278.03</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4</td>
      <td>2</td>
      <td>23</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>67333.77</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 371 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-a6e54d3f-3576-4ec3-8a91-9a46281d315b')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-a6e54d3f-3576-4ec3-8a91-9a46281d315b button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-a6e54d3f-3576-4ec3-8a91-9a46281d315b');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  


- 클래스 값 컬럼을 포함하여 피처가 **371개** 존재함 


## **1-2. EDA**



```python
### 데이터 정보 확인

cust_df.info()
```

<pre>
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 76020 entries, 0 to 76019
Columns: 371 entries, ID to TARGET
dtypes: float64(111), int64(260)
memory usage: 215.2 MB
</pre>
- 111개의 피처가 float형, 260개의 피처가 int형

- 모든 피처가 숫자형임

- Null 값은 없음



```python
### target 속성값의 분포

print(cust_df['TARGET'].value_counts())
unsatisfied_cnt = cust_df[cust_df['TARGET'] == 1].TARGET.count()
total_cnt = cust_df.TARGET.count()

print()
print('unsatisfied 비율은 {0:.2f}'.format((unsatisfied_cnt / total_cnt)))
```

<pre>
0    73012
1     3008
Name: TARGET, dtype: int64

unsatisfied 비율은 0.04
</pre>
- 대부분이 만족(0)이며, 불만족인 고객은 얼마 되지 않는 4%에 불과



```python
### 각 피처의 값 분포

cust_df.describe( )
```


  <div id="df-892249b6-b02c-4ae0-966f-418d2a646121">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>var3</th>
      <th>var15</th>
      <th>imp_ent_var16_ult1</th>
      <th>imp_op_var39_comer_ult1</th>
      <th>imp_op_var39_comer_ult3</th>
      <th>imp_op_var40_comer_ult1</th>
      <th>imp_op_var40_comer_ult3</th>
      <th>imp_op_var40_efect_ult1</th>
      <th>imp_op_var40_efect_ult3</th>
      <th>...</th>
      <th>saldo_medio_var33_hace2</th>
      <th>saldo_medio_var33_hace3</th>
      <th>saldo_medio_var33_ult1</th>
      <th>saldo_medio_var33_ult3</th>
      <th>saldo_medio_var44_hace2</th>
      <th>saldo_medio_var44_hace3</th>
      <th>saldo_medio_var44_ult1</th>
      <th>saldo_medio_var44_ult3</th>
      <th>var38</th>
      <th>TARGET</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>76020.000000</td>
      <td>76020.000000</td>
      <td>76020.000000</td>
      <td>76020.000000</td>
      <td>76020.000000</td>
      <td>76020.000000</td>
      <td>76020.000000</td>
      <td>76020.000000</td>
      <td>76020.000000</td>
      <td>76020.000000</td>
      <td>...</td>
      <td>76020.000000</td>
      <td>76020.000000</td>
      <td>76020.000000</td>
      <td>76020.000000</td>
      <td>76020.000000</td>
      <td>76020.000000</td>
      <td>76020.000000</td>
      <td>76020.000000</td>
      <td>7.602000e+04</td>
      <td>76020.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>75964.050723</td>
      <td>-1523.199277</td>
      <td>33.212865</td>
      <td>86.208265</td>
      <td>72.363067</td>
      <td>119.529632</td>
      <td>3.559130</td>
      <td>6.472698</td>
      <td>0.412946</td>
      <td>0.567352</td>
      <td>...</td>
      <td>7.935824</td>
      <td>1.365146</td>
      <td>12.215580</td>
      <td>8.784074</td>
      <td>31.505324</td>
      <td>1.858575</td>
      <td>76.026165</td>
      <td>56.614351</td>
      <td>1.172358e+05</td>
      <td>0.039569</td>
    </tr>
    <tr>
      <th>std</th>
      <td>43781.947379</td>
      <td>39033.462364</td>
      <td>12.956486</td>
      <td>1614.757313</td>
      <td>339.315831</td>
      <td>546.266294</td>
      <td>93.155749</td>
      <td>153.737066</td>
      <td>30.604864</td>
      <td>36.513513</td>
      <td>...</td>
      <td>455.887218</td>
      <td>113.959637</td>
      <td>783.207399</td>
      <td>538.439211</td>
      <td>2013.125393</td>
      <td>147.786584</td>
      <td>4040.337842</td>
      <td>2852.579397</td>
      <td>1.826646e+05</td>
      <td>0.194945</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>-999999.000000</td>
      <td>5.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>5.163750e+03</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>38104.750000</td>
      <td>2.000000</td>
      <td>23.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>6.787061e+04</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>76043.000000</td>
      <td>2.000000</td>
      <td>28.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.064092e+05</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>113748.750000</td>
      <td>2.000000</td>
      <td>40.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.187563e+05</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>151838.000000</td>
      <td>238.000000</td>
      <td>105.000000</td>
      <td>210000.000000</td>
      <td>12888.030000</td>
      <td>21024.810000</td>
      <td>8237.820000</td>
      <td>11073.570000</td>
      <td>6600.000000</td>
      <td>6600.000000</td>
      <td>...</td>
      <td>50003.880000</td>
      <td>20385.720000</td>
      <td>138831.630000</td>
      <td>91778.730000</td>
      <td>438329.220000</td>
      <td>24650.010000</td>
      <td>681462.900000</td>
      <td>397884.300000</td>
      <td>2.203474e+07</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 371 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-892249b6-b02c-4ae0-966f-418d2a646121')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-892249b6-b02c-4ae0-966f-418d2a646121 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-892249b6-b02c-4ae0-966f-418d2a646121');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  


- ```var3``` 컬럼의 경우 min 값이 -999999임

  - NaN이나 특정 예외 값을 -999999로 변환했을 것이라고 예상할 수 있음

  - ```print(cust_df, var3.value_counts()[:10])```으로 조사 결과 -999999 값이 116개나 있음을 확인할 수 있음





> var3의 이상치를 최빈값인 2로 변환



```python
cust_df['var3'].replace(-999999, 2, inplace = True) # 이상치 변환
cust_df.drop('ID', axis = 1, inplace = True) # 불필요한 컬럼 제거
```

## **1-3. 데이터 구성하기**



```python
### 피처 세트와 레이블 세트 분리
# 레이블 컬럼은 DataFrame의 맨 마지막에 위치해 컬럼 위치 -1로 분리

X_features = cust_df.iloc[:, :-1]
y_labels = cust_df.iloc[:, -1]

print('피처 데이터 shape:{0}'.format(X_features.shape))
```

<pre>
피처 데이터 shape:(76020, 369)
</pre>

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels,
                                                    test_size = 0.2, random_state = 0)
train_cnt = y_train.count()
test_cnt = y_test.count()
print('학습 세트 Shape:{0}, 테스트 세트 Shape:{1}'.format(X_train.shape , X_test.shape))
```

<pre>
학습 세트 Shape:(60816, 369), 테스트 세트 Shape:(15204, 369)
</pre>

```python
# 비대칭한 데이터 세트이므로 클래스인 Target 값 분포도가 train과 test에 모두 비슷한지 확인

print('학습 세트 레이블 값 분포 비율')
print(y_train.value_counts()/train_cnt)

print('\n 테스트 세트 레이블 값 분포 비율')
print(y_test.value_counts()/test_cnt)
```

<pre>
학습 세트 레이블 값 분포 비율
0    0.960964
1    0.039036
Name: TARGET, dtype: float64

 테스트 세트 레이블 값 분포 비율
0    0.9583
1    0.0417
Name: TARGET, dtype: float64
</pre>
- train과 test 모두 TARGET 값의 분포가 원본 데이터와 유사하게 전체 4% 정도의 불만족 값(= 1)으로 만들어짐


# **2. 모델링(Modeling)**

- ```XGBoost``` 와 ```LightGBM``` 활용


## **2-1. XGBoost**



```python
from xgboost import XGBClassifier
from sklearn.metrics import roc_auc_score
```

※ 테스트 데이터 세트를 XGBoost의 평가 데이터 세트로 사용하면 과적합의 가능성을 증가시킬 수 있음


### **a) 기본 모델 생성/학습/예측**



```python
### 모델 객체 생성
xgb_clf = XGBClassifier(n_estimators = 500, random_state = 156)

### 모델 학습
# 성능 평가 지표를 auc로, 조기 중단 파라미터는 100으로 설정
xgb_clf.fit(X_train, y_train, early_stopping_rounds = 100,
            eval_metric = "auc", eval_set = [(X_train, y_train), (X_test, y_test)])

### 모델 성능 평가
xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1], average = 'macro')
print('ROC AUC: {0:.4f}'.format(xgb_roc_score))
```

<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.82005	validation_1-auc:0.81157
[1]	validation_0-auc:0.83400	validation_1-auc:0.82452
[2]	validation_0-auc:0.83870	validation_1-auc:0.82745
[3]	validation_0-auc:0.84419	validation_1-auc:0.82922
[4]	validation_0-auc:0.84783	validation_1-auc:0.83298
[5]	validation_0-auc:0.85125	validation_1-auc:0.83500
[6]	validation_0-auc:0.85501	validation_1-auc:0.83653
[7]	validation_0-auc:0.85831	validation_1-auc:0.83782
[8]	validation_0-auc:0.86143	validation_1-auc:0.83802
[9]	validation_0-auc:0.86452	validation_1-auc:0.83914
[10]	validation_0-auc:0.86717	validation_1-auc:0.83954
[11]	validation_0-auc:0.87013	validation_1-auc:0.83983
[12]	validation_0-auc:0.87369	validation_1-auc:0.84033
[13]	validation_0-auc:0.87620	validation_1-auc:0.84055
[14]	validation_0-auc:0.87799	validation_1-auc:0.84135
[15]	validation_0-auc:0.88071	validation_1-auc:0.84117
[16]	validation_0-auc:0.88237	validation_1-auc:0.84101
[17]	validation_0-auc:0.88352	validation_1-auc:0.84071
[18]	validation_0-auc:0.88457	validation_1-auc:0.84052
[19]	validation_0-auc:0.88592	validation_1-auc:0.84023
[20]	validation_0-auc:0.88788	validation_1-auc:0.84012
[21]	validation_0-auc:0.88845	validation_1-auc:0.84022
[22]	validation_0-auc:0.88980	validation_1-auc:0.84007
[23]	validation_0-auc:0.89019	validation_1-auc:0.84009
[24]	validation_0-auc:0.89193	validation_1-auc:0.83974
[25]	validation_0-auc:0.89253	validation_1-auc:0.84015
[26]	validation_0-auc:0.89329	validation_1-auc:0.84101
[27]	validation_0-auc:0.89386	validation_1-auc:0.84087
[28]	validation_0-auc:0.89416	validation_1-auc:0.84074
[29]	validation_0-auc:0.89660	validation_1-auc:0.83999
[30]	validation_0-auc:0.89737	validation_1-auc:0.83959
[31]	validation_0-auc:0.89911	validation_1-auc:0.83952
[32]	validation_0-auc:0.90103	validation_1-auc:0.83901
[33]	validation_0-auc:0.90250	validation_1-auc:0.83885
[34]	validation_0-auc:0.90275	validation_1-auc:0.83887
[35]	validation_0-auc:0.90290	validation_1-auc:0.83864
[36]	validation_0-auc:0.90460	validation_1-auc:0.83834
[37]	validation_0-auc:0.90497	validation_1-auc:0.83810
[38]	validation_0-auc:0.90515	validation_1-auc:0.83811
[39]	validation_0-auc:0.90533	validation_1-auc:0.83813
[40]	validation_0-auc:0.90574	validation_1-auc:0.83776
[41]	validation_0-auc:0.90690	validation_1-auc:0.83720
[42]	validation_0-auc:0.90715	validation_1-auc:0.83684
[43]	validation_0-auc:0.90736	validation_1-auc:0.83672
[44]	validation_0-auc:0.90758	validation_1-auc:0.83674
[45]	validation_0-auc:0.90767	validation_1-auc:0.83694
[46]	validation_0-auc:0.90778	validation_1-auc:0.83687
[47]	validation_0-auc:0.90791	validation_1-auc:0.83678
[48]	validation_0-auc:0.90829	validation_1-auc:0.83694
[49]	validation_0-auc:0.90869	validation_1-auc:0.83676
[50]	validation_0-auc:0.90890	validation_1-auc:0.83655
[51]	validation_0-auc:0.91067	validation_1-auc:0.83669
[52]	validation_0-auc:0.91238	validation_1-auc:0.83641
[53]	validation_0-auc:0.91352	validation_1-auc:0.83690
[54]	validation_0-auc:0.91386	validation_1-auc:0.83693
[55]	validation_0-auc:0.91406	validation_1-auc:0.83681
[56]	validation_0-auc:0.91545	validation_1-auc:0.83680
[57]	validation_0-auc:0.91556	validation_1-auc:0.83667
[58]	validation_0-auc:0.91628	validation_1-auc:0.83665
[59]	validation_0-auc:0.91725	validation_1-auc:0.83591
[60]	validation_0-auc:0.91762	validation_1-auc:0.83576
[61]	validation_0-auc:0.91784	validation_1-auc:0.83534
[62]	validation_0-auc:0.91872	validation_1-auc:0.83513
[63]	validation_0-auc:0.91892	validation_1-auc:0.83510
[64]	validation_0-auc:0.91896	validation_1-auc:0.83508
[65]	validation_0-auc:0.91907	validation_1-auc:0.83519
[66]	validation_0-auc:0.91970	validation_1-auc:0.83510
[67]	validation_0-auc:0.91982	validation_1-auc:0.83523
[68]	validation_0-auc:0.92007	validation_1-auc:0.83457
[69]	validation_0-auc:0.92015	validation_1-auc:0.83460
[70]	validation_0-auc:0.92024	validation_1-auc:0.83446
[71]	validation_0-auc:0.92037	validation_1-auc:0.83462
[72]	validation_0-auc:0.92087	validation_1-auc:0.83394
[73]	validation_0-auc:0.92094	validation_1-auc:0.83410
[74]	validation_0-auc:0.92133	validation_1-auc:0.83394
[75]	validation_0-auc:0.92141	validation_1-auc:0.83368
[76]	validation_0-auc:0.92321	validation_1-auc:0.83413
[77]	validation_0-auc:0.92415	validation_1-auc:0.83359
[78]	validation_0-auc:0.92503	validation_1-auc:0.83353
[79]	validation_0-auc:0.92539	validation_1-auc:0.83293
[80]	validation_0-auc:0.92577	validation_1-auc:0.83253
[81]	validation_0-auc:0.92677	validation_1-auc:0.83187
[82]	validation_0-auc:0.92706	validation_1-auc:0.83230
[83]	validation_0-auc:0.92800	validation_1-auc:0.83216
[84]	validation_0-auc:0.92822	validation_1-auc:0.83206
[85]	validation_0-auc:0.92870	validation_1-auc:0.83196
[86]	validation_0-auc:0.92875	validation_1-auc:0.83200
[87]	validation_0-auc:0.92881	validation_1-auc:0.83208
[88]	validation_0-auc:0.92919	validation_1-auc:0.83174
[89]	validation_0-auc:0.92940	validation_1-auc:0.83160
[90]	validation_0-auc:0.92948	validation_1-auc:0.83155
[91]	validation_0-auc:0.92959	validation_1-auc:0.83165
[92]	validation_0-auc:0.92964	validation_1-auc:0.83172
[93]	validation_0-auc:0.93031	validation_1-auc:0.83160
[94]	validation_0-auc:0.93032	validation_1-auc:0.83150
[95]	validation_0-auc:0.93037	validation_1-auc:0.83132
[96]	validation_0-auc:0.93084	validation_1-auc:0.83090
[97]	validation_0-auc:0.93091	validation_1-auc:0.83091
[98]	validation_0-auc:0.93168	validation_1-auc:0.83066
[99]	validation_0-auc:0.93245	validation_1-auc:0.83058
[100]	validation_0-auc:0.93286	validation_1-auc:0.83029
[101]	validation_0-auc:0.93361	validation_1-auc:0.82955
[102]	validation_0-auc:0.93359	validation_1-auc:0.82962
[103]	validation_0-auc:0.93435	validation_1-auc:0.82893
[104]	validation_0-auc:0.93446	validation_1-auc:0.82837
[105]	validation_0-auc:0.93480	validation_1-auc:0.82815
[106]	validation_0-auc:0.93579	validation_1-auc:0.82744
[107]	validation_0-auc:0.93583	validation_1-auc:0.82728
[108]	validation_0-auc:0.93610	validation_1-auc:0.82651
[109]	validation_0-auc:0.93617	validation_1-auc:0.82650
[110]	validation_0-auc:0.93659	validation_1-auc:0.82621
[111]	validation_0-auc:0.93663	validation_1-auc:0.82620
[112]	validation_0-auc:0.93710	validation_1-auc:0.82591
[113]	validation_0-auc:0.93781	validation_1-auc:0.82498
ROC AUC: 0.8413
</pre>
### **b) Hyper Parameter Tuning**


- 칼럼의 개수가 많음 -> ```과적합``` 가능성

> max_depth, min_child_weight, colsample_bytree 하이퍼 파라미터만 일차 튜닝 대상으로 튜닝



- 학습 시간이 많이 필요한 ML 모델인 경우 처음에는 먼저 2 ~ 3개 정도의 파라미터를 결합해 최적 파라미터를 찾아낸 뒤에 해당 최적 파라미터를 기반으로 다시 1 ~ 2개의 파라미터를 결합하여 파라미터 튜닝을 수행하는 방법도 존재


- 다음 코드는 8개의 하이퍼 파라미터 경우의 수를 가짐

  - 수행 시간이 오래 걸림

  - ```n_estimator = 100```, ```early_stopping_rounds = 30```으로 하여 테스트 한 뒤 나중에 하이퍼 파라미터 튜닝이 완료되면 다시 증가시키자.



```python
from sklearn.model_selection import GridSearchCV

# 하이퍼 파라미터 테스트의 수행 속도를 향상시키기 위해 n_estimators를 100으로 감소
xgb_clf = XGBClassifier(n_estimators = 100)


### 하이퍼 파라미터 튜닝
params = {'max_depth':[5, 7] , 
          'min_child_weight':[1,3] ,
          'colsample_bytree':[0.5, 0.75] }

### 교차 검증
# cv는 3으로 지정 
gridcv = GridSearchCV(xgb_clf, param_grid = params, cv = 3)
gridcv.fit(X_train, y_train, early_stopping_rounds = 30, 
           eval_metric = "auc", eval_set = [(X_train, y_train), (X_test, y_test)])
print('GridSearchCV 최적 파라미터:',gridcv.best_params_) 

### 성능 평가
xgb_roc_score = roc_auc_score(y_test, gridcv.predict_proba(X_test)[:,1], average = 'macro')
print('ROC AUC: {0:.4f}'.format(xgb_roc_score))
```

<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.80289	validation_1-auc:0.80420
[1]	validation_0-auc:0.80677	validation_1-auc:0.80892
[2]	validation_0-auc:0.82161	validation_1-auc:0.81979
[3]	validation_0-auc:0.82877	validation_1-auc:0.82509
[4]	validation_0-auc:0.83227	validation_1-auc:0.82868
[5]	validation_0-auc:0.83179	validation_1-auc:0.82649
[6]	validation_0-auc:0.82662	validation_1-auc:0.81879
[7]	validation_0-auc:0.83687	validation_1-auc:0.82901
[8]	validation_0-auc:0.84136	validation_1-auc:0.83545
[9]	validation_0-auc:0.84304	validation_1-auc:0.83301
[10]	validation_0-auc:0.84221	validation_1-auc:0.83210
[11]	validation_0-auc:0.84723	validation_1-auc:0.83457
[12]	validation_0-auc:0.85187	validation_1-auc:0.83740
[13]	validation_0-auc:0.85373	validation_1-auc:0.83434
[14]	validation_0-auc:0.85631	validation_1-auc:0.83641
[15]	validation_0-auc:0.85719	validation_1-auc:0.83617
[16]	validation_0-auc:0.85906	validation_1-auc:0.83443
[17]	validation_0-auc:0.86100	validation_1-auc:0.83417
[18]	validation_0-auc:0.86275	validation_1-auc:0.83579
[19]	validation_0-auc:0.86439	validation_1-auc:0.83680
[20]	validation_0-auc:0.86511	validation_1-auc:0.83633
[21]	validation_0-auc:0.86619	validation_1-auc:0.83515
[22]	validation_0-auc:0.86671	validation_1-auc:0.83481
[23]	validation_0-auc:0.86748	validation_1-auc:0.83488
[24]	validation_0-auc:0.86861	validation_1-auc:0.83440
[25]	validation_0-auc:0.86928	validation_1-auc:0.83477
[26]	validation_0-auc:0.86955	validation_1-auc:0.83447
[27]	validation_0-auc:0.86969	validation_1-auc:0.83420
[28]	validation_0-auc:0.87033	validation_1-auc:0.83437
[29]	validation_0-auc:0.87109	validation_1-auc:0.83385
[30]	validation_0-auc:0.87112	validation_1-auc:0.83374
[31]	validation_0-auc:0.87144	validation_1-auc:0.83318
[32]	validation_0-auc:0.87162	validation_1-auc:0.83293
[33]	validation_0-auc:0.87226	validation_1-auc:0.83267
[34]	validation_0-auc:0.87256	validation_1-auc:0.83229
[35]	validation_0-auc:0.87290	validation_1-auc:0.83248
[36]	validation_0-auc:0.87326	validation_1-auc:0.83255
[37]	validation_0-auc:0.87348	validation_1-auc:0.83267
[38]	validation_0-auc:0.87418	validation_1-auc:0.83279
[39]	validation_0-auc:0.87460	validation_1-auc:0.83252
[40]	validation_0-auc:0.87483	validation_1-auc:0.83230
[41]	validation_0-auc:0.87490	validation_1-auc:0.83221
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.80699	validation_1-auc:0.80599
[1]	validation_0-auc:0.81029	validation_1-auc:0.81309
[2]	validation_0-auc:0.82504	validation_1-auc:0.82148
[3]	validation_0-auc:0.83183	validation_1-auc:0.82497
[4]	validation_0-auc:0.83585	validation_1-auc:0.82786
[5]	validation_0-auc:0.83864	validation_1-auc:0.83222
[6]	validation_0-auc:0.83483	validation_1-auc:0.83054
[7]	validation_0-auc:0.84061	validation_1-auc:0.83365
[8]	validation_0-auc:0.84451	validation_1-auc:0.83729
[9]	validation_0-auc:0.84411	validation_1-auc:0.83520
[10]	validation_0-auc:0.84329	validation_1-auc:0.83367
[11]	validation_0-auc:0.84914	validation_1-auc:0.83676
[12]	validation_0-auc:0.85414	validation_1-auc:0.83983
[13]	validation_0-auc:0.85569	validation_1-auc:0.83826
[14]	validation_0-auc:0.85887	validation_1-auc:0.83916
[15]	validation_0-auc:0.85987	validation_1-auc:0.84004
[16]	validation_0-auc:0.86042	validation_1-auc:0.84034
[17]	validation_0-auc:0.86156	validation_1-auc:0.84030
[18]	validation_0-auc:0.86302	validation_1-auc:0.84172
[19]	validation_0-auc:0.86434	validation_1-auc:0.84223
[20]	validation_0-auc:0.86568	validation_1-auc:0.84250
[21]	validation_0-auc:0.86605	validation_1-auc:0.84272
[22]	validation_0-auc:0.86705	validation_1-auc:0.84268
[23]	validation_0-auc:0.86850	validation_1-auc:0.84327
[24]	validation_0-auc:0.86954	validation_1-auc:0.84271
[25]	validation_0-auc:0.87027	validation_1-auc:0.84226
[26]	validation_0-auc:0.87095	validation_1-auc:0.84241
[27]	validation_0-auc:0.87150	validation_1-auc:0.84239
[28]	validation_0-auc:0.87169	validation_1-auc:0.84245
[29]	validation_0-auc:0.87285	validation_1-auc:0.84238
[30]	validation_0-auc:0.87363	validation_1-auc:0.84227
[31]	validation_0-auc:0.87384	validation_1-auc:0.84226
[32]	validation_0-auc:0.87479	validation_1-auc:0.84213
[33]	validation_0-auc:0.87543	validation_1-auc:0.84204
[34]	validation_0-auc:0.87578	validation_1-auc:0.84186
[35]	validation_0-auc:0.87612	validation_1-auc:0.84176
[36]	validation_0-auc:0.87654	validation_1-auc:0.84157
[37]	validation_0-auc:0.87698	validation_1-auc:0.84108
[38]	validation_0-auc:0.87713	validation_1-auc:0.84137
[39]	validation_0-auc:0.87756	validation_1-auc:0.84143
[40]	validation_0-auc:0.87780	validation_1-auc:0.84092
[41]	validation_0-auc:0.87789	validation_1-auc:0.84109
[42]	validation_0-auc:0.87835	validation_1-auc:0.84125
[43]	validation_0-auc:0.87964	validation_1-auc:0.84079
[44]	validation_0-auc:0.87993	validation_1-auc:0.84053
[45]	validation_0-auc:0.88044	validation_1-auc:0.84021
[46]	validation_0-auc:0.88062	validation_1-auc:0.83972
[47]	validation_0-auc:0.88088	validation_1-auc:0.83934
[48]	validation_0-auc:0.88092	validation_1-auc:0.83930
[49]	validation_0-auc:0.88111	validation_1-auc:0.83903
[50]	validation_0-auc:0.88121	validation_1-auc:0.83876
[51]	validation_0-auc:0.88145	validation_1-auc:0.83816
[52]	validation_0-auc:0.88161	validation_1-auc:0.83800
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.81203	validation_1-auc:0.80951
[1]	validation_0-auc:0.81450	validation_1-auc:0.81585
[2]	validation_0-auc:0.82678	validation_1-auc:0.82141
[3]	validation_0-auc:0.82958	validation_1-auc:0.82431
[4]	validation_0-auc:0.83590	validation_1-auc:0.82659
[5]	validation_0-auc:0.83743	validation_1-auc:0.82696
[6]	validation_0-auc:0.83508	validation_1-auc:0.82420
[7]	validation_0-auc:0.84130	validation_1-auc:0.82966
[8]	validation_0-auc:0.84500	validation_1-auc:0.83477
[9]	validation_0-auc:0.84551	validation_1-auc:0.83453
[10]	validation_0-auc:0.84494	validation_1-auc:0.83201
[11]	validation_0-auc:0.85031	validation_1-auc:0.83706
[12]	validation_0-auc:0.85489	validation_1-auc:0.83832
[13]	validation_0-auc:0.85636	validation_1-auc:0.83727
[14]	validation_0-auc:0.85873	validation_1-auc:0.83913
[15]	validation_0-auc:0.85979	validation_1-auc:0.83969
[16]	validation_0-auc:0.86059	validation_1-auc:0.83876
[17]	validation_0-auc:0.86171	validation_1-auc:0.83857
[18]	validation_0-auc:0.86319	validation_1-auc:0.83998
[19]	validation_0-auc:0.86468	validation_1-auc:0.84007
[20]	validation_0-auc:0.86530	validation_1-auc:0.83958
[21]	validation_0-auc:0.86518	validation_1-auc:0.83915
[22]	validation_0-auc:0.86705	validation_1-auc:0.84024
[23]	validation_0-auc:0.86779	validation_1-auc:0.84019
[24]	validation_0-auc:0.86845	validation_1-auc:0.83978
[25]	validation_0-auc:0.86932	validation_1-auc:0.83934
[26]	validation_0-auc:0.87042	validation_1-auc:0.83894
[27]	validation_0-auc:0.87131	validation_1-auc:0.83872
[28]	validation_0-auc:0.87186	validation_1-auc:0.83869
[29]	validation_0-auc:0.87253	validation_1-auc:0.83839
[30]	validation_0-auc:0.87319	validation_1-auc:0.83821
[31]	validation_0-auc:0.87335	validation_1-auc:0.83813
[32]	validation_0-auc:0.87371	validation_1-auc:0.83779
[33]	validation_0-auc:0.87403	validation_1-auc:0.83776
[34]	validation_0-auc:0.87413	validation_1-auc:0.83795
[35]	validation_0-auc:0.87489	validation_1-auc:0.83786
[36]	validation_0-auc:0.87566	validation_1-auc:0.83761
[37]	validation_0-auc:0.87603	validation_1-auc:0.83823
[38]	validation_0-auc:0.87664	validation_1-auc:0.83826
[39]	validation_0-auc:0.87714	validation_1-auc:0.83797
[40]	validation_0-auc:0.87757	validation_1-auc:0.83761
[41]	validation_0-auc:0.87773	validation_1-auc:0.83762
[42]	validation_0-auc:0.87793	validation_1-auc:0.83730
[43]	validation_0-auc:0.87820	validation_1-auc:0.83743
[44]	validation_0-auc:0.87859	validation_1-auc:0.83740
[45]	validation_0-auc:0.87926	validation_1-auc:0.83654
[46]	validation_0-auc:0.87939	validation_1-auc:0.83637
[47]	validation_0-auc:0.87958	validation_1-auc:0.83568
[48]	validation_0-auc:0.87991	validation_1-auc:0.83543
[49]	validation_0-auc:0.88008	validation_1-auc:0.83578
[50]	validation_0-auc:0.88098	validation_1-auc:0.83606
[51]	validation_0-auc:0.88118	validation_1-auc:0.83609
[52]	validation_0-auc:0.88161	validation_1-auc:0.83581
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.80246	validation_1-auc:0.80463
[1]	validation_0-auc:0.80769	validation_1-auc:0.80995
[2]	validation_0-auc:0.82216	validation_1-auc:0.82059
[3]	validation_0-auc:0.82983	validation_1-auc:0.82797
[4]	validation_0-auc:0.83294	validation_1-auc:0.82964
[5]	validation_0-auc:0.83289	validation_1-auc:0.82807
[6]	validation_0-auc:0.82913	validation_1-auc:0.82282
[7]	validation_0-auc:0.83623	validation_1-auc:0.82949
[8]	validation_0-auc:0.84169	validation_1-auc:0.83424
[9]	validation_0-auc:0.84276	validation_1-auc:0.83206
[10]	validation_0-auc:0.84290	validation_1-auc:0.83209
[11]	validation_0-auc:0.84726	validation_1-auc:0.83490
[12]	validation_0-auc:0.85185	validation_1-auc:0.83765
[13]	validation_0-auc:0.85354	validation_1-auc:0.83497
[14]	validation_0-auc:0.85519	validation_1-auc:0.83661
[15]	validation_0-auc:0.85551	validation_1-auc:0.83619
[16]	validation_0-auc:0.85658	validation_1-auc:0.83520
[17]	validation_0-auc:0.85731	validation_1-auc:0.83493
[18]	validation_0-auc:0.85941	validation_1-auc:0.83637
[19]	validation_0-auc:0.86073	validation_1-auc:0.83734
[20]	validation_0-auc:0.86157	validation_1-auc:0.83716
[21]	validation_0-auc:0.86194	validation_1-auc:0.83656
[22]	validation_0-auc:0.86311	validation_1-auc:0.83636
[23]	validation_0-auc:0.86348	validation_1-auc:0.83664
[24]	validation_0-auc:0.86439	validation_1-auc:0.83728
[25]	validation_0-auc:0.86552	validation_1-auc:0.83601
[26]	validation_0-auc:0.86573	validation_1-auc:0.83583
[27]	validation_0-auc:0.86633	validation_1-auc:0.83558
[28]	validation_0-auc:0.86674	validation_1-auc:0.83562
[29]	validation_0-auc:0.86736	validation_1-auc:0.83573
[30]	validation_0-auc:0.86746	validation_1-auc:0.83562
[31]	validation_0-auc:0.86771	validation_1-auc:0.83550
[32]	validation_0-auc:0.86803	validation_1-auc:0.83440
[33]	validation_0-auc:0.86825	validation_1-auc:0.83457
[34]	validation_0-auc:0.86835	validation_1-auc:0.83427
[35]	validation_0-auc:0.86835	validation_1-auc:0.83423
[36]	validation_0-auc:0.86872	validation_1-auc:0.83430
[37]	validation_0-auc:0.86910	validation_1-auc:0.83374
[38]	validation_0-auc:0.86924	validation_1-auc:0.83396
[39]	validation_0-auc:0.86930	validation_1-auc:0.83367
[40]	validation_0-auc:0.86965	validation_1-auc:0.83269
[41]	validation_0-auc:0.86998	validation_1-auc:0.83297
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.80418	validation_1-auc:0.81169
[1]	validation_0-auc:0.81174	validation_1-auc:0.81122
[2]	validation_0-auc:0.82946	validation_1-auc:0.82272
[3]	validation_0-auc:0.83495	validation_1-auc:0.82851
[4]	validation_0-auc:0.83721	validation_1-auc:0.82887
[5]	validation_0-auc:0.83847	validation_1-auc:0.83206
[6]	validation_0-auc:0.83511	validation_1-auc:0.83097
[7]	validation_0-auc:0.84116	validation_1-auc:0.83427
[8]	validation_0-auc:0.84533	validation_1-auc:0.83959
[9]	validation_0-auc:0.84475	validation_1-auc:0.83715
[10]	validation_0-auc:0.84396	validation_1-auc:0.83646
[11]	validation_0-auc:0.84838	validation_1-auc:0.83860
[12]	validation_0-auc:0.85328	validation_1-auc:0.84141
[13]	validation_0-auc:0.85385	validation_1-auc:0.83952
[14]	validation_0-auc:0.85744	validation_1-auc:0.84166
[15]	validation_0-auc:0.85825	validation_1-auc:0.84222
[16]	validation_0-auc:0.85867	validation_1-auc:0.84194
[17]	validation_0-auc:0.85911	validation_1-auc:0.84171
[18]	validation_0-auc:0.86072	validation_1-auc:0.84333
[19]	validation_0-auc:0.86168	validation_1-auc:0.84403
[20]	validation_0-auc:0.86273	validation_1-auc:0.84473
[21]	validation_0-auc:0.86330	validation_1-auc:0.84493
[22]	validation_0-auc:0.86370	validation_1-auc:0.84488
[23]	validation_0-auc:0.86444	validation_1-auc:0.84467
[24]	validation_0-auc:0.86512	validation_1-auc:0.84399
[25]	validation_0-auc:0.86602	validation_1-auc:0.84429
[26]	validation_0-auc:0.86702	validation_1-auc:0.84386
[27]	validation_0-auc:0.86718	validation_1-auc:0.84389
[28]	validation_0-auc:0.86744	validation_1-auc:0.84382
[29]	validation_0-auc:0.86878	validation_1-auc:0.84331
[30]	validation_0-auc:0.86953	validation_1-auc:0.84300
[31]	validation_0-auc:0.86968	validation_1-auc:0.84289
[32]	validation_0-auc:0.87033	validation_1-auc:0.84275
[33]	validation_0-auc:0.87049	validation_1-auc:0.84252
[34]	validation_0-auc:0.87068	validation_1-auc:0.84259
[35]	validation_0-auc:0.87119	validation_1-auc:0.84231
[36]	validation_0-auc:0.87249	validation_1-auc:0.84221
[37]	validation_0-auc:0.87261	validation_1-auc:0.84213
[38]	validation_0-auc:0.87335	validation_1-auc:0.84278
[39]	validation_0-auc:0.87373	validation_1-auc:0.84275
[40]	validation_0-auc:0.87403	validation_1-auc:0.84327
[41]	validation_0-auc:0.87425	validation_1-auc:0.84291
[42]	validation_0-auc:0.87434	validation_1-auc:0.84252
[43]	validation_0-auc:0.87496	validation_1-auc:0.84230
[44]	validation_0-auc:0.87507	validation_1-auc:0.84221
[45]	validation_0-auc:0.87596	validation_1-auc:0.84185
[46]	validation_0-auc:0.87641	validation_1-auc:0.84240
[47]	validation_0-auc:0.87666	validation_1-auc:0.84239
[48]	validation_0-auc:0.87674	validation_1-auc:0.84242
[49]	validation_0-auc:0.87750	validation_1-auc:0.84146
[50]	validation_0-auc:0.87773	validation_1-auc:0.84133
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.81098	validation_1-auc:0.80916
[1]	validation_0-auc:0.81358	validation_1-auc:0.81313
[2]	validation_0-auc:0.82606	validation_1-auc:0.82075
[3]	validation_0-auc:0.83126	validation_1-auc:0.82413
[4]	validation_0-auc:0.83431	validation_1-auc:0.82739
[5]	validation_0-auc:0.83669	validation_1-auc:0.82762
[6]	validation_0-auc:0.83388	validation_1-auc:0.82326
[7]	validation_0-auc:0.83882	validation_1-auc:0.82781
[8]	validation_0-auc:0.84310	validation_1-auc:0.83488
[9]	validation_0-auc:0.84383	validation_1-auc:0.83609
[10]	validation_0-auc:0.84300	validation_1-auc:0.83454
[11]	validation_0-auc:0.84807	validation_1-auc:0.83811
[12]	validation_0-auc:0.85239	validation_1-auc:0.84034
[13]	validation_0-auc:0.85437	validation_1-auc:0.83857
[14]	validation_0-auc:0.85624	validation_1-auc:0.83976
[15]	validation_0-auc:0.85747	validation_1-auc:0.83981
[16]	validation_0-auc:0.85828	validation_1-auc:0.83989
[17]	validation_0-auc:0.85956	validation_1-auc:0.83887
[18]	validation_0-auc:0.86130	validation_1-auc:0.84004
[19]	validation_0-auc:0.86217	validation_1-auc:0.84007
[20]	validation_0-auc:0.86326	validation_1-auc:0.84087
[21]	validation_0-auc:0.86345	validation_1-auc:0.84050
[22]	validation_0-auc:0.86461	validation_1-auc:0.84070
[23]	validation_0-auc:0.86511	validation_1-auc:0.84144
[24]	validation_0-auc:0.86593	validation_1-auc:0.84165
[25]	validation_0-auc:0.86742	validation_1-auc:0.84260
[26]	validation_0-auc:0.86788	validation_1-auc:0.84219
[27]	validation_0-auc:0.86837	validation_1-auc:0.84252
[28]	validation_0-auc:0.86907	validation_1-auc:0.84149
[29]	validation_0-auc:0.87030	validation_1-auc:0.84211
[30]	validation_0-auc:0.87049	validation_1-auc:0.84191
[31]	validation_0-auc:0.87085	validation_1-auc:0.84221
[32]	validation_0-auc:0.87159	validation_1-auc:0.84200
[33]	validation_0-auc:0.87168	validation_1-auc:0.84175
[34]	validation_0-auc:0.87189	validation_1-auc:0.84138
[35]	validation_0-auc:0.87226	validation_1-auc:0.84093
[36]	validation_0-auc:0.87252	validation_1-auc:0.84096
[37]	validation_0-auc:0.87273	validation_1-auc:0.84114
[38]	validation_0-auc:0.87290	validation_1-auc:0.84116
[39]	validation_0-auc:0.87358	validation_1-auc:0.84104
[40]	validation_0-auc:0.87408	validation_1-auc:0.84014
[41]	validation_0-auc:0.87440	validation_1-auc:0.84087
[42]	validation_0-auc:0.87511	validation_1-auc:0.84141
[43]	validation_0-auc:0.87539	validation_1-auc:0.84138
[44]	validation_0-auc:0.87551	validation_1-auc:0.84102
[45]	validation_0-auc:0.87605	validation_1-auc:0.84065
[46]	validation_0-auc:0.87596	validation_1-auc:0.84070
[47]	validation_0-auc:0.87660	validation_1-auc:0.84067
[48]	validation_0-auc:0.87690	validation_1-auc:0.84070
[49]	validation_0-auc:0.87697	validation_1-auc:0.84027
[50]	validation_0-auc:0.87744	validation_1-auc:0.84041
[51]	validation_0-auc:0.87813	validation_1-auc:0.83980
[52]	validation_0-auc:0.87852	validation_1-auc:0.83997
[53]	validation_0-auc:0.87858	validation_1-auc:0.83974
[54]	validation_0-auc:0.87878	validation_1-auc:0.83966
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.80902	validation_1-auc:0.80594
[1]	validation_0-auc:0.80814	validation_1-auc:0.80463
[2]	validation_0-auc:0.82929	validation_1-auc:0.82254
[3]	validation_0-auc:0.83621	validation_1-auc:0.82625
[4]	validation_0-auc:0.83964	validation_1-auc:0.82813
[5]	validation_0-auc:0.84237	validation_1-auc:0.82614
[6]	validation_0-auc:0.84139	validation_1-auc:0.82316
[7]	validation_0-auc:0.84976	validation_1-auc:0.82936
[8]	validation_0-auc:0.85363	validation_1-auc:0.83274
[9]	validation_0-auc:0.85616	validation_1-auc:0.82987
[10]	validation_0-auc:0.85494	validation_1-auc:0.82878
[11]	validation_0-auc:0.86353	validation_1-auc:0.83263
[12]	validation_0-auc:0.86904	validation_1-auc:0.83413
[13]	validation_0-auc:0.87058	validation_1-auc:0.83155
[14]	validation_0-auc:0.87381	validation_1-auc:0.83338
[15]	validation_0-auc:0.87435	validation_1-auc:0.83100
[16]	validation_0-auc:0.87537	validation_1-auc:0.83110
[17]	validation_0-auc:0.87745	validation_1-auc:0.82964
[18]	validation_0-auc:0.87937	validation_1-auc:0.83110
[19]	validation_0-auc:0.88050	validation_1-auc:0.83177
[20]	validation_0-auc:0.88231	validation_1-auc:0.83124
[21]	validation_0-auc:0.88279	validation_1-auc:0.83070
[22]	validation_0-auc:0.88427	validation_1-auc:0.83181
[23]	validation_0-auc:0.88508	validation_1-auc:0.83200
[24]	validation_0-auc:0.88601	validation_1-auc:0.83232
[25]	validation_0-auc:0.88695	validation_1-auc:0.83234
[26]	validation_0-auc:0.88704	validation_1-auc:0.83209
[27]	validation_0-auc:0.88695	validation_1-auc:0.83143
[28]	validation_0-auc:0.88713	validation_1-auc:0.83145
[29]	validation_0-auc:0.88756	validation_1-auc:0.83132
[30]	validation_0-auc:0.88828	validation_1-auc:0.83070
[31]	validation_0-auc:0.88847	validation_1-auc:0.83061
[32]	validation_0-auc:0.89001	validation_1-auc:0.82997
[33]	validation_0-auc:0.89022	validation_1-auc:0.83029
[34]	validation_0-auc:0.89046	validation_1-auc:0.83034
[35]	validation_0-auc:0.89048	validation_1-auc:0.83034
[36]	validation_0-auc:0.89095	validation_1-auc:0.83025
[37]	validation_0-auc:0.89116	validation_1-auc:0.82992
[38]	validation_0-auc:0.89208	validation_1-auc:0.82934
[39]	validation_0-auc:0.89214	validation_1-auc:0.82947
[40]	validation_0-auc:0.89232	validation_1-auc:0.82920
[41]	validation_0-auc:0.89219	validation_1-auc:0.82938
[42]	validation_0-auc:0.89215	validation_1-auc:0.82918
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.80941	validation_1-auc:0.80686
[1]	validation_0-auc:0.81556	validation_1-auc:0.81361
[2]	validation_0-auc:0.83096	validation_1-auc:0.82315
[3]	validation_0-auc:0.83933	validation_1-auc:0.82851
[4]	validation_0-auc:0.84416	validation_1-auc:0.83167
[5]	validation_0-auc:0.84872	validation_1-auc:0.83320
[6]	validation_0-auc:0.84648	validation_1-auc:0.82990
[7]	validation_0-auc:0.85307	validation_1-auc:0.83396
[8]	validation_0-auc:0.85680	validation_1-auc:0.83723
[9]	validation_0-auc:0.85902	validation_1-auc:0.83808
[10]	validation_0-auc:0.85868	validation_1-auc:0.83643
[11]	validation_0-auc:0.86500	validation_1-auc:0.83869
[12]	validation_0-auc:0.87073	validation_1-auc:0.84082
[13]	validation_0-auc:0.87241	validation_1-auc:0.83814
[14]	validation_0-auc:0.87685	validation_1-auc:0.84077
[15]	validation_0-auc:0.87782	validation_1-auc:0.84085
[16]	validation_0-auc:0.87873	validation_1-auc:0.83983
[17]	validation_0-auc:0.87990	validation_1-auc:0.83837
[18]	validation_0-auc:0.88157	validation_1-auc:0.83933
[19]	validation_0-auc:0.88369	validation_1-auc:0.84017
[20]	validation_0-auc:0.88632	validation_1-auc:0.83959
[21]	validation_0-auc:0.88679	validation_1-auc:0.83942
[22]	validation_0-auc:0.88774	validation_1-auc:0.83931
[23]	validation_0-auc:0.88957	validation_1-auc:0.83775
[24]	validation_0-auc:0.89009	validation_1-auc:0.83695
[25]	validation_0-auc:0.89144	validation_1-auc:0.83624
[26]	validation_0-auc:0.89167	validation_1-auc:0.83623
[27]	validation_0-auc:0.89187	validation_1-auc:0.83593
[28]	validation_0-auc:0.89200	validation_1-auc:0.83571
[29]	validation_0-auc:0.89291	validation_1-auc:0.83684
[30]	validation_0-auc:0.89339	validation_1-auc:0.83775
[31]	validation_0-auc:0.89391	validation_1-auc:0.83791
[32]	validation_0-auc:0.89486	validation_1-auc:0.83760
[33]	validation_0-auc:0.89506	validation_1-auc:0.83720
[34]	validation_0-auc:0.89503	validation_1-auc:0.83710
[35]	validation_0-auc:0.89507	validation_1-auc:0.83697
[36]	validation_0-auc:0.89515	validation_1-auc:0.83723
[37]	validation_0-auc:0.89528	validation_1-auc:0.83679
[38]	validation_0-auc:0.89543	validation_1-auc:0.83675
[39]	validation_0-auc:0.89565	validation_1-auc:0.83689
[40]	validation_0-auc:0.89623	validation_1-auc:0.83681
[41]	validation_0-auc:0.89693	validation_1-auc:0.83614
[42]	validation_0-auc:0.89682	validation_1-auc:0.83621
[43]	validation_0-auc:0.89687	validation_1-auc:0.83620
[44]	validation_0-auc:0.89704	validation_1-auc:0.83620
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.81702	validation_1-auc:0.81220
[1]	validation_0-auc:0.82046	validation_1-auc:0.81514
[2]	validation_0-auc:0.83453	validation_1-auc:0.82323
[3]	validation_0-auc:0.83849	validation_1-auc:0.82737
[4]	validation_0-auc:0.84346	validation_1-auc:0.82934
[5]	validation_0-auc:0.84713	validation_1-auc:0.83083
[6]	validation_0-auc:0.84430	validation_1-auc:0.82628
[7]	validation_0-auc:0.85255	validation_1-auc:0.83025
[8]	validation_0-auc:0.85662	validation_1-auc:0.83387
[9]	validation_0-auc:0.85863	validation_1-auc:0.83446
[10]	validation_0-auc:0.85883	validation_1-auc:0.83329
[11]	validation_0-auc:0.86666	validation_1-auc:0.83528
[12]	validation_0-auc:0.87216	validation_1-auc:0.83776
[13]	validation_0-auc:0.87498	validation_1-auc:0.83590
[14]	validation_0-auc:0.87717	validation_1-auc:0.83829
[15]	validation_0-auc:0.87780	validation_1-auc:0.83772
[16]	validation_0-auc:0.87851	validation_1-auc:0.83749
[17]	validation_0-auc:0.88025	validation_1-auc:0.83555
[18]	validation_0-auc:0.88120	validation_1-auc:0.83778
[19]	validation_0-auc:0.88283	validation_1-auc:0.83794
[20]	validation_0-auc:0.88426	validation_1-auc:0.83717
[21]	validation_0-auc:0.88470	validation_1-auc:0.83607
[22]	validation_0-auc:0.88607	validation_1-auc:0.83626
[23]	validation_0-auc:0.88681	validation_1-auc:0.83728
[24]	validation_0-auc:0.88772	validation_1-auc:0.83696
[25]	validation_0-auc:0.88896	validation_1-auc:0.83704
[26]	validation_0-auc:0.89040	validation_1-auc:0.83579
[27]	validation_0-auc:0.89050	validation_1-auc:0.83515
[28]	validation_0-auc:0.89076	validation_1-auc:0.83454
[29]	validation_0-auc:0.89237	validation_1-auc:0.83393
[30]	validation_0-auc:0.89325	validation_1-auc:0.83474
[31]	validation_0-auc:0.89338	validation_1-auc:0.83483
[32]	validation_0-auc:0.89376	validation_1-auc:0.83487
[33]	validation_0-auc:0.89379	validation_1-auc:0.83532
[34]	validation_0-auc:0.89386	validation_1-auc:0.83511
[35]	validation_0-auc:0.89388	validation_1-auc:0.83448
[36]	validation_0-auc:0.89480	validation_1-auc:0.83427
[37]	validation_0-auc:0.89515	validation_1-auc:0.83394
[38]	validation_0-auc:0.89520	validation_1-auc:0.83383
[39]	validation_0-auc:0.89518	validation_1-auc:0.83341
[40]	validation_0-auc:0.89532	validation_1-auc:0.83310
[41]	validation_0-auc:0.89573	validation_1-auc:0.83306
[42]	validation_0-auc:0.89584	validation_1-auc:0.83301
[43]	validation_0-auc:0.89601	validation_1-auc:0.83272
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.80956	validation_1-auc:0.80714
[1]	validation_0-auc:0.81193	validation_1-auc:0.80854
[2]	validation_0-auc:0.82506	validation_1-auc:0.81970
[3]	validation_0-auc:0.83477	validation_1-auc:0.82709
[4]	validation_0-auc:0.83821	validation_1-auc:0.82847
[5]	validation_0-auc:0.84212	validation_1-auc:0.82840
[6]	validation_0-auc:0.83981	validation_1-auc:0.82187
[7]	validation_0-auc:0.84643	validation_1-auc:0.82964
[8]	validation_0-auc:0.85106	validation_1-auc:0.83246
[9]	validation_0-auc:0.85265	validation_1-auc:0.83022
[10]	validation_0-auc:0.85202	validation_1-auc:0.82886
[11]	validation_0-auc:0.85929	validation_1-auc:0.83305
[12]	validation_0-auc:0.86421	validation_1-auc:0.83632
[13]	validation_0-auc:0.86580	validation_1-auc:0.83527
[14]	validation_0-auc:0.86836	validation_1-auc:0.83751
[15]	validation_0-auc:0.86917	validation_1-auc:0.83644
[16]	validation_0-auc:0.86964	validation_1-auc:0.83589
[17]	validation_0-auc:0.87138	validation_1-auc:0.83500
[18]	validation_0-auc:0.87334	validation_1-auc:0.83720
[19]	validation_0-auc:0.87495	validation_1-auc:0.83866
[20]	validation_0-auc:0.87628	validation_1-auc:0.83891
[21]	validation_0-auc:0.87623	validation_1-auc:0.83803
[22]	validation_0-auc:0.87796	validation_1-auc:0.83851
[23]	validation_0-auc:0.87830	validation_1-auc:0.83796
[24]	validation_0-auc:0.87964	validation_1-auc:0.83699
[25]	validation_0-auc:0.88010	validation_1-auc:0.83691
[26]	validation_0-auc:0.88121	validation_1-auc:0.83606
[27]	validation_0-auc:0.88186	validation_1-auc:0.83456
[28]	validation_0-auc:0.88208	validation_1-auc:0.83477
[29]	validation_0-auc:0.88224	validation_1-auc:0.83469
[30]	validation_0-auc:0.88357	validation_1-auc:0.83484
[31]	validation_0-auc:0.88396	validation_1-auc:0.83445
[32]	validation_0-auc:0.88414	validation_1-auc:0.83445
[33]	validation_0-auc:0.88423	validation_1-auc:0.83429
[34]	validation_0-auc:0.88451	validation_1-auc:0.83355
[35]	validation_0-auc:0.88482	validation_1-auc:0.83345
[36]	validation_0-auc:0.88503	validation_1-auc:0.83251
[37]	validation_0-auc:0.88608	validation_1-auc:0.83220
[38]	validation_0-auc:0.88619	validation_1-auc:0.83167
[39]	validation_0-auc:0.88643	validation_1-auc:0.83142
[40]	validation_0-auc:0.88673	validation_1-auc:0.83086
[41]	validation_0-auc:0.88682	validation_1-auc:0.83056
[42]	validation_0-auc:0.88683	validation_1-auc:0.83060
[43]	validation_0-auc:0.88697	validation_1-auc:0.83031
[44]	validation_0-auc:0.88705	validation_1-auc:0.83048
[45]	validation_0-auc:0.88751	validation_1-auc:0.83085
[46]	validation_0-auc:0.88820	validation_1-auc:0.83037
[47]	validation_0-auc:0.88821	validation_1-auc:0.83055
[48]	validation_0-auc:0.88864	validation_1-auc:0.83022
[49]	validation_0-auc:0.88880	validation_1-auc:0.83001
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.80761	validation_1-auc:0.81297
[1]	validation_0-auc:0.81426	validation_1-auc:0.81464
[2]	validation_0-auc:0.83333	validation_1-auc:0.82937
[3]	validation_0-auc:0.83932	validation_1-auc:0.83359
[4]	validation_0-auc:0.84334	validation_1-auc:0.83390
[5]	validation_0-auc:0.84685	validation_1-auc:0.83404
[6]	validation_0-auc:0.84426	validation_1-auc:0.83247
[7]	validation_0-auc:0.84963	validation_1-auc:0.83651
[8]	validation_0-auc:0.85390	validation_1-auc:0.84200
[9]	validation_0-auc:0.85566	validation_1-auc:0.84119
[10]	validation_0-auc:0.85553	validation_1-auc:0.83994
[11]	validation_0-auc:0.86125	validation_1-auc:0.84109
[12]	validation_0-auc:0.86665	validation_1-auc:0.84226
[13]	validation_0-auc:0.86779	validation_1-auc:0.84071
[14]	validation_0-auc:0.87189	validation_1-auc:0.84338
[15]	validation_0-auc:0.87286	validation_1-auc:0.84417
[16]	validation_0-auc:0.87300	validation_1-auc:0.84269
[17]	validation_0-auc:0.87369	validation_1-auc:0.84204
[18]	validation_0-auc:0.87513	validation_1-auc:0.84383
[19]	validation_0-auc:0.87658	validation_1-auc:0.84430
[20]	validation_0-auc:0.87874	validation_1-auc:0.84447
[21]	validation_0-auc:0.87942	validation_1-auc:0.84448
[22]	validation_0-auc:0.88042	validation_1-auc:0.84426
[23]	validation_0-auc:0.88118	validation_1-auc:0.84371
[24]	validation_0-auc:0.88234	validation_1-auc:0.84268
[25]	validation_0-auc:0.88340	validation_1-auc:0.84221
[26]	validation_0-auc:0.88386	validation_1-auc:0.84182
[27]	validation_0-auc:0.88412	validation_1-auc:0.84124
[28]	validation_0-auc:0.88415	validation_1-auc:0.84149
[29]	validation_0-auc:0.88433	validation_1-auc:0.84107
[30]	validation_0-auc:0.88466	validation_1-auc:0.84142
[31]	validation_0-auc:0.88484	validation_1-auc:0.84150
[32]	validation_0-auc:0.88568	validation_1-auc:0.84190
[33]	validation_0-auc:0.88596	validation_1-auc:0.84186
[34]	validation_0-auc:0.88708	validation_1-auc:0.84122
[35]	validation_0-auc:0.88747	validation_1-auc:0.84035
[36]	validation_0-auc:0.88797	validation_1-auc:0.83999
[37]	validation_0-auc:0.88837	validation_1-auc:0.83991
[38]	validation_0-auc:0.88845	validation_1-auc:0.83952
[39]	validation_0-auc:0.88860	validation_1-auc:0.83968
[40]	validation_0-auc:0.88902	validation_1-auc:0.83928
[41]	validation_0-auc:0.88904	validation_1-auc:0.83914
[42]	validation_0-auc:0.88986	validation_1-auc:0.83941
[43]	validation_0-auc:0.89016	validation_1-auc:0.83914
[44]	validation_0-auc:0.89020	validation_1-auc:0.83878
[45]	validation_0-auc:0.89032	validation_1-auc:0.83835
[46]	validation_0-auc:0.89047	validation_1-auc:0.83831
[47]	validation_0-auc:0.89129	validation_1-auc:0.83823
[48]	validation_0-auc:0.89246	validation_1-auc:0.83784
[49]	validation_0-auc:0.89287	validation_1-auc:0.83787
[50]	validation_0-auc:0.89304	validation_1-auc:0.83772
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.81604	validation_1-auc:0.81235
[1]	validation_0-auc:0.82253	validation_1-auc:0.81400
[2]	validation_0-auc:0.83498	validation_1-auc:0.82366
[3]	validation_0-auc:0.84183	validation_1-auc:0.82843
[4]	validation_0-auc:0.84412	validation_1-auc:0.82954
[5]	validation_0-auc:0.84630	validation_1-auc:0.82708
[6]	validation_0-auc:0.84502	validation_1-auc:0.82381
[7]	validation_0-auc:0.85257	validation_1-auc:0.82814
[8]	validation_0-auc:0.85582	validation_1-auc:0.83553
[9]	validation_0-auc:0.85747	validation_1-auc:0.83650
[10]	validation_0-auc:0.85660	validation_1-auc:0.83364
[11]	validation_0-auc:0.86296	validation_1-auc:0.83958
[12]	validation_0-auc:0.86754	validation_1-auc:0.84099
[13]	validation_0-auc:0.86875	validation_1-auc:0.83850
[14]	validation_0-auc:0.87078	validation_1-auc:0.84079
[15]	validation_0-auc:0.87244	validation_1-auc:0.84106
[16]	validation_0-auc:0.87329	validation_1-auc:0.83940
[17]	validation_0-auc:0.87409	validation_1-auc:0.83849
[18]	validation_0-auc:0.87675	validation_1-auc:0.83885
[19]	validation_0-auc:0.87832	validation_1-auc:0.83891
[20]	validation_0-auc:0.87964	validation_1-auc:0.83841
[21]	validation_0-auc:0.87980	validation_1-auc:0.83807
[22]	validation_0-auc:0.88082	validation_1-auc:0.83794
[23]	validation_0-auc:0.88101	validation_1-auc:0.83832
[24]	validation_0-auc:0.88205	validation_1-auc:0.83779
[25]	validation_0-auc:0.88319	validation_1-auc:0.83835
[26]	validation_0-auc:0.88435	validation_1-auc:0.83902
[27]	validation_0-auc:0.88475	validation_1-auc:0.83897
[28]	validation_0-auc:0.88505	validation_1-auc:0.83825
[29]	validation_0-auc:0.88624	validation_1-auc:0.83658
[30]	validation_0-auc:0.88669	validation_1-auc:0.83637
[31]	validation_0-auc:0.88701	validation_1-auc:0.83654
[32]	validation_0-auc:0.88724	validation_1-auc:0.83621
[33]	validation_0-auc:0.88758	validation_1-auc:0.83656
[34]	validation_0-auc:0.88769	validation_1-auc:0.83656
[35]	validation_0-auc:0.88812	validation_1-auc:0.83592
[36]	validation_0-auc:0.88823	validation_1-auc:0.83557
[37]	validation_0-auc:0.88861	validation_1-auc:0.83561
[38]	validation_0-auc:0.88872	validation_1-auc:0.83449
[39]	validation_0-auc:0.88902	validation_1-auc:0.83423
[40]	validation_0-auc:0.89022	validation_1-auc:0.83465
[41]	validation_0-auc:0.89038	validation_1-auc:0.83434
[42]	validation_0-auc:0.89041	validation_1-auc:0.83390
[43]	validation_0-auc:0.89095	validation_1-auc:0.83365
[44]	validation_0-auc:0.89104	validation_1-auc:0.83275
[45]	validation_0-auc:0.89108	validation_1-auc:0.83254
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.80593	validation_1-auc:0.80898
[1]	validation_0-auc:0.80943	validation_1-auc:0.80802
[2]	validation_0-auc:0.82441	validation_1-auc:0.82007
[3]	validation_0-auc:0.83164	validation_1-auc:0.82390
[4]	validation_0-auc:0.83772	validation_1-auc:0.82921
[5]	validation_0-auc:0.83842	validation_1-auc:0.83047
[6]	validation_0-auc:0.84104	validation_1-auc:0.83226
[7]	validation_0-auc:0.84469	validation_1-auc:0.83537
[8]	validation_0-auc:0.84683	validation_1-auc:0.83548
[9]	validation_0-auc:0.84814	validation_1-auc:0.83619
[10]	validation_0-auc:0.84998	validation_1-auc:0.83683
[11]	validation_0-auc:0.85144	validation_1-auc:0.83648
[12]	validation_0-auc:0.85391	validation_1-auc:0.83602
[13]	validation_0-auc:0.85621	validation_1-auc:0.83614
[14]	validation_0-auc:0.85711	validation_1-auc:0.83651
[15]	validation_0-auc:0.85910	validation_1-auc:0.83675
[16]	validation_0-auc:0.86083	validation_1-auc:0.83563
[17]	validation_0-auc:0.86138	validation_1-auc:0.83521
[18]	validation_0-auc:0.86217	validation_1-auc:0.83553
[19]	validation_0-auc:0.86277	validation_1-auc:0.83468
[20]	validation_0-auc:0.86429	validation_1-auc:0.83389
[21]	validation_0-auc:0.86521	validation_1-auc:0.83337
[22]	validation_0-auc:0.86556	validation_1-auc:0.83346
[23]	validation_0-auc:0.86612	validation_1-auc:0.83304
[24]	validation_0-auc:0.86641	validation_1-auc:0.83371
[25]	validation_0-auc:0.86666	validation_1-auc:0.83331
[26]	validation_0-auc:0.86741	validation_1-auc:0.83306
[27]	validation_0-auc:0.86773	validation_1-auc:0.83277
[28]	validation_0-auc:0.86801	validation_1-auc:0.83259
[29]	validation_0-auc:0.86801	validation_1-auc:0.83250
[30]	validation_0-auc:0.86866	validation_1-auc:0.83234
[31]	validation_0-auc:0.86964	validation_1-auc:0.83222
[32]	validation_0-auc:0.87137	validation_1-auc:0.83277
[33]	validation_0-auc:0.87222	validation_1-auc:0.83281
[34]	validation_0-auc:0.87254	validation_1-auc:0.83300
[35]	validation_0-auc:0.87342	validation_1-auc:0.83264
[36]	validation_0-auc:0.87366	validation_1-auc:0.83223
[37]	validation_0-auc:0.87397	validation_1-auc:0.83247
[38]	validation_0-auc:0.87426	validation_1-auc:0.83302
[39]	validation_0-auc:0.87454	validation_1-auc:0.83187
[40]	validation_0-auc:0.87481	validation_1-auc:0.83193
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.80863	validation_1-auc:0.80011
[1]	validation_0-auc:0.80571	validation_1-auc:0.80437
[2]	validation_0-auc:0.82796	validation_1-auc:0.82018
[3]	validation_0-auc:0.83445	validation_1-auc:0.82662
[4]	validation_0-auc:0.83787	validation_1-auc:0.82864
[5]	validation_0-auc:0.84117	validation_1-auc:0.83429
[6]	validation_0-auc:0.84465	validation_1-auc:0.83836
[7]	validation_0-auc:0.84676	validation_1-auc:0.83896
[8]	validation_0-auc:0.84853	validation_1-auc:0.83854
[9]	validation_0-auc:0.85047	validation_1-auc:0.83875
[10]	validation_0-auc:0.85238	validation_1-auc:0.83996
[11]	validation_0-auc:0.85450	validation_1-auc:0.83884
[12]	validation_0-auc:0.85576	validation_1-auc:0.84019
[13]	validation_0-auc:0.85703	validation_1-auc:0.84096
[14]	validation_0-auc:0.85943	validation_1-auc:0.84124
[15]	validation_0-auc:0.86088	validation_1-auc:0.84081
[16]	validation_0-auc:0.86188	validation_1-auc:0.84113
[17]	validation_0-auc:0.86250	validation_1-auc:0.84169
[18]	validation_0-auc:0.86372	validation_1-auc:0.84212
[19]	validation_0-auc:0.86530	validation_1-auc:0.84257
[20]	validation_0-auc:0.86633	validation_1-auc:0.84221
[21]	validation_0-auc:0.86695	validation_1-auc:0.84267
[22]	validation_0-auc:0.86752	validation_1-auc:0.84307
[23]	validation_0-auc:0.86781	validation_1-auc:0.84318
[24]	validation_0-auc:0.86879	validation_1-auc:0.84368
[25]	validation_0-auc:0.86911	validation_1-auc:0.84397
[26]	validation_0-auc:0.86973	validation_1-auc:0.84365
[27]	validation_0-auc:0.87007	validation_1-auc:0.84368
[28]	validation_0-auc:0.87031	validation_1-auc:0.84414
[29]	validation_0-auc:0.87098	validation_1-auc:0.84442
[30]	validation_0-auc:0.87178	validation_1-auc:0.84452
[31]	validation_0-auc:0.87200	validation_1-auc:0.84428
[32]	validation_0-auc:0.87239	validation_1-auc:0.84424
[33]	validation_0-auc:0.87282	validation_1-auc:0.84353
[34]	validation_0-auc:0.87332	validation_1-auc:0.84315
[35]	validation_0-auc:0.87339	validation_1-auc:0.84293
[36]	validation_0-auc:0.87369	validation_1-auc:0.84312
[37]	validation_0-auc:0.87406	validation_1-auc:0.84332
[38]	validation_0-auc:0.87417	validation_1-auc:0.84355
[39]	validation_0-auc:0.87447	validation_1-auc:0.84348
[40]	validation_0-auc:0.87487	validation_1-auc:0.84267
[41]	validation_0-auc:0.87560	validation_1-auc:0.84227
[42]	validation_0-auc:0.87584	validation_1-auc:0.84230
[43]	validation_0-auc:0.87643	validation_1-auc:0.84230
[44]	validation_0-auc:0.87714	validation_1-auc:0.84183
[45]	validation_0-auc:0.87746	validation_1-auc:0.84178
[46]	validation_0-auc:0.87768	validation_1-auc:0.84155
[47]	validation_0-auc:0.87800	validation_1-auc:0.84126
[48]	validation_0-auc:0.87831	validation_1-auc:0.84108
[49]	validation_0-auc:0.87876	validation_1-auc:0.84056
[50]	validation_0-auc:0.87896	validation_1-auc:0.84038
[51]	validation_0-auc:0.87932	validation_1-auc:0.83964
[52]	validation_0-auc:0.87947	validation_1-auc:0.83961
[53]	validation_0-auc:0.87968	validation_1-auc:0.83957
[54]	validation_0-auc:0.87976	validation_1-auc:0.83944
[55]	validation_0-auc:0.87992	validation_1-auc:0.83952
[56]	validation_0-auc:0.88011	validation_1-auc:0.83974
[57]	validation_0-auc:0.88042	validation_1-auc:0.84042
[58]	validation_0-auc:0.88054	validation_1-auc:0.84027
[59]	validation_0-auc:0.88062	validation_1-auc:0.84035
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.82051	validation_1-auc:0.81706
[1]	validation_0-auc:0.81489	validation_1-auc:0.81463
[2]	validation_0-auc:0.82613	validation_1-auc:0.82392
[3]	validation_0-auc:0.83159	validation_1-auc:0.82687
[4]	validation_0-auc:0.83529	validation_1-auc:0.82743
[5]	validation_0-auc:0.84072	validation_1-auc:0.83137
[6]	validation_0-auc:0.84302	validation_1-auc:0.83442
[7]	validation_0-auc:0.84511	validation_1-auc:0.83555
[8]	validation_0-auc:0.84587	validation_1-auc:0.83638
[9]	validation_0-auc:0.84812	validation_1-auc:0.83673
[10]	validation_0-auc:0.85143	validation_1-auc:0.83526
[11]	validation_0-auc:0.85397	validation_1-auc:0.83620
[12]	validation_0-auc:0.85616	validation_1-auc:0.83763
[13]	validation_0-auc:0.85783	validation_1-auc:0.83704
[14]	validation_0-auc:0.85973	validation_1-auc:0.83846
[15]	validation_0-auc:0.86155	validation_1-auc:0.83830
[16]	validation_0-auc:0.86278	validation_1-auc:0.83844
[17]	validation_0-auc:0.86419	validation_1-auc:0.83895
[18]	validation_0-auc:0.86488	validation_1-auc:0.83874
[19]	validation_0-auc:0.86616	validation_1-auc:0.83966
[20]	validation_0-auc:0.86668	validation_1-auc:0.83973
[21]	validation_0-auc:0.86747	validation_1-auc:0.83954
[22]	validation_0-auc:0.86830	validation_1-auc:0.84018
[23]	validation_0-auc:0.86902	validation_1-auc:0.83987
[24]	validation_0-auc:0.86929	validation_1-auc:0.83983
[25]	validation_0-auc:0.86938	validation_1-auc:0.83959
[26]	validation_0-auc:0.86970	validation_1-auc:0.83898
[27]	validation_0-auc:0.87019	validation_1-auc:0.83939
[28]	validation_0-auc:0.87097	validation_1-auc:0.83947
[29]	validation_0-auc:0.87104	validation_1-auc:0.83980
[30]	validation_0-auc:0.87112	validation_1-auc:0.83968
[31]	validation_0-auc:0.87148	validation_1-auc:0.83949
[32]	validation_0-auc:0.87202	validation_1-auc:0.83963
[33]	validation_0-auc:0.87219	validation_1-auc:0.83981
[34]	validation_0-auc:0.87369	validation_1-auc:0.83896
[35]	validation_0-auc:0.87390	validation_1-auc:0.83899
[36]	validation_0-auc:0.87403	validation_1-auc:0.83903
[37]	validation_0-auc:0.87436	validation_1-auc:0.83901
[38]	validation_0-auc:0.87455	validation_1-auc:0.83884
[39]	validation_0-auc:0.87532	validation_1-auc:0.83887
[40]	validation_0-auc:0.87636	validation_1-auc:0.83877
[41]	validation_0-auc:0.87660	validation_1-auc:0.83889
[42]	validation_0-auc:0.87782	validation_1-auc:0.83865
[43]	validation_0-auc:0.87821	validation_1-auc:0.83833
[44]	validation_0-auc:0.87862	validation_1-auc:0.83833
[45]	validation_0-auc:0.87869	validation_1-auc:0.83843
[46]	validation_0-auc:0.87908	validation_1-auc:0.83817
[47]	validation_0-auc:0.87924	validation_1-auc:0.83787
[48]	validation_0-auc:0.87956	validation_1-auc:0.83809
[49]	validation_0-auc:0.87973	validation_1-auc:0.83826
[50]	validation_0-auc:0.87980	validation_1-auc:0.83813
[51]	validation_0-auc:0.88012	validation_1-auc:0.83836
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.80803	validation_1-auc:0.80806
[1]	validation_0-auc:0.80888	validation_1-auc:0.80894
[2]	validation_0-auc:0.82405	validation_1-auc:0.81945
[3]	validation_0-auc:0.83156	validation_1-auc:0.82609
[4]	validation_0-auc:0.83401	validation_1-auc:0.82772
[5]	validation_0-auc:0.83658	validation_1-auc:0.82950
[6]	validation_0-auc:0.84047	validation_1-auc:0.83059
[7]	validation_0-auc:0.84358	validation_1-auc:0.83185
[8]	validation_0-auc:0.84541	validation_1-auc:0.83323
[9]	validation_0-auc:0.84653	validation_1-auc:0.83440
[10]	validation_0-auc:0.84920	validation_1-auc:0.83548
[11]	validation_0-auc:0.85030	validation_1-auc:0.83627
[12]	validation_0-auc:0.85268	validation_1-auc:0.83664
[13]	validation_0-auc:0.85483	validation_1-auc:0.83676
[14]	validation_0-auc:0.85628	validation_1-auc:0.83643
[15]	validation_0-auc:0.85783	validation_1-auc:0.83561
[16]	validation_0-auc:0.85833	validation_1-auc:0.83599
[17]	validation_0-auc:0.85876	validation_1-auc:0.83658
[18]	validation_0-auc:0.85988	validation_1-auc:0.83665
[19]	validation_0-auc:0.86047	validation_1-auc:0.83641
[20]	validation_0-auc:0.86213	validation_1-auc:0.83672
[21]	validation_0-auc:0.86221	validation_1-auc:0.83658
[22]	validation_0-auc:0.86260	validation_1-auc:0.83668
[23]	validation_0-auc:0.86371	validation_1-auc:0.83622
[24]	validation_0-auc:0.86459	validation_1-auc:0.83612
[25]	validation_0-auc:0.86483	validation_1-auc:0.83655
[26]	validation_0-auc:0.86517	validation_1-auc:0.83589
[27]	validation_0-auc:0.86547	validation_1-auc:0.83557
[28]	validation_0-auc:0.86581	validation_1-auc:0.83558
[29]	validation_0-auc:0.86586	validation_1-auc:0.83583
[30]	validation_0-auc:0.86616	validation_1-auc:0.83515
[31]	validation_0-auc:0.86638	validation_1-auc:0.83521
[32]	validation_0-auc:0.86697	validation_1-auc:0.83518
[33]	validation_0-auc:0.86719	validation_1-auc:0.83535
[34]	validation_0-auc:0.86757	validation_1-auc:0.83520
[35]	validation_0-auc:0.86812	validation_1-auc:0.83506
[36]	validation_0-auc:0.86869	validation_1-auc:0.83428
[37]	validation_0-auc:0.86935	validation_1-auc:0.83442
[38]	validation_0-auc:0.86997	validation_1-auc:0.83406
[39]	validation_0-auc:0.87001	validation_1-auc:0.83394
[40]	validation_0-auc:0.87003	validation_1-auc:0.83399
[41]	validation_0-auc:0.87011	validation_1-auc:0.83382
[42]	validation_0-auc:0.87020	validation_1-auc:0.83370
[43]	validation_0-auc:0.87117	validation_1-auc:0.83317
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.80906	validation_1-auc:0.80435
[1]	validation_0-auc:0.80610	validation_1-auc:0.80703
[2]	validation_0-auc:0.82829	validation_1-auc:0.82098
[3]	validation_0-auc:0.83657	validation_1-auc:0.82669
[4]	validation_0-auc:0.83911	validation_1-auc:0.82849
[5]	validation_0-auc:0.84163	validation_1-auc:0.83122
[6]	validation_0-auc:0.84566	validation_1-auc:0.83619
[7]	validation_0-auc:0.84720	validation_1-auc:0.83653
[8]	validation_0-auc:0.84844	validation_1-auc:0.83526
[9]	validation_0-auc:0.84960	validation_1-auc:0.83672
[10]	validation_0-auc:0.85155	validation_1-auc:0.83775
[11]	validation_0-auc:0.85323	validation_1-auc:0.83779
[12]	validation_0-auc:0.85457	validation_1-auc:0.83858
[13]	validation_0-auc:0.85554	validation_1-auc:0.83864
[14]	validation_0-auc:0.85653	validation_1-auc:0.83865
[15]	validation_0-auc:0.85860	validation_1-auc:0.83784
[16]	validation_0-auc:0.85972	validation_1-auc:0.83823
[17]	validation_0-auc:0.86067	validation_1-auc:0.83797
[18]	validation_0-auc:0.86144	validation_1-auc:0.83898
[19]	validation_0-auc:0.86230	validation_1-auc:0.83909
[20]	validation_0-auc:0.86313	validation_1-auc:0.83899
[21]	validation_0-auc:0.86356	validation_1-auc:0.83833
[22]	validation_0-auc:0.86385	validation_1-auc:0.83846
[23]	validation_0-auc:0.86472	validation_1-auc:0.83755
[24]	validation_0-auc:0.86502	validation_1-auc:0.83757
[25]	validation_0-auc:0.86617	validation_1-auc:0.83725
[26]	validation_0-auc:0.86736	validation_1-auc:0.83663
[27]	validation_0-auc:0.86768	validation_1-auc:0.83683
[28]	validation_0-auc:0.86785	validation_1-auc:0.83707
[29]	validation_0-auc:0.86868	validation_1-auc:0.83690
[30]	validation_0-auc:0.86924	validation_1-auc:0.83645
[31]	validation_0-auc:0.86947	validation_1-auc:0.83698
[32]	validation_0-auc:0.86992	validation_1-auc:0.83699
[33]	validation_0-auc:0.87008	validation_1-auc:0.83722
[34]	validation_0-auc:0.87030	validation_1-auc:0.83671
[35]	validation_0-auc:0.87040	validation_1-auc:0.83635
[36]	validation_0-auc:0.87083	validation_1-auc:0.83606
[37]	validation_0-auc:0.87100	validation_1-auc:0.83600
[38]	validation_0-auc:0.87123	validation_1-auc:0.83581
[39]	validation_0-auc:0.87191	validation_1-auc:0.83518
[40]	validation_0-auc:0.87261	validation_1-auc:0.83526
[41]	validation_0-auc:0.87289	validation_1-auc:0.83530
[42]	validation_0-auc:0.87363	validation_1-auc:0.83549
[43]	validation_0-auc:0.87382	validation_1-auc:0.83527
[44]	validation_0-auc:0.87395	validation_1-auc:0.83509
[45]	validation_0-auc:0.87422	validation_1-auc:0.83512
[46]	validation_0-auc:0.87461	validation_1-auc:0.83508
[47]	validation_0-auc:0.87471	validation_1-auc:0.83492
[48]	validation_0-auc:0.87482	validation_1-auc:0.83531
[49]	validation_0-auc:0.87589	validation_1-auc:0.83511
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.81882	validation_1-auc:0.81739
[1]	validation_0-auc:0.81386	validation_1-auc:0.81337
[2]	validation_0-auc:0.82661	validation_1-auc:0.82334
[3]	validation_0-auc:0.83557	validation_1-auc:0.82907
[4]	validation_0-auc:0.83892	validation_1-auc:0.83167
[5]	validation_0-auc:0.84144	validation_1-auc:0.83105
[6]	validation_0-auc:0.84403	validation_1-auc:0.83360
[7]	validation_0-auc:0.84648	validation_1-auc:0.83417
[8]	validation_0-auc:0.84841	validation_1-auc:0.83581
[9]	validation_0-auc:0.84876	validation_1-auc:0.83592
[10]	validation_0-auc:0.85065	validation_1-auc:0.83624
[11]	validation_0-auc:0.85204	validation_1-auc:0.83676
[12]	validation_0-auc:0.85449	validation_1-auc:0.83495
[13]	validation_0-auc:0.85519	validation_1-auc:0.83583
[14]	validation_0-auc:0.85682	validation_1-auc:0.83720
[15]	validation_0-auc:0.85847	validation_1-auc:0.83743
[16]	validation_0-auc:0.85930	validation_1-auc:0.83756
[17]	validation_0-auc:0.86089	validation_1-auc:0.83841
[18]	validation_0-auc:0.86188	validation_1-auc:0.83752
[19]	validation_0-auc:0.86281	validation_1-auc:0.83698
[20]	validation_0-auc:0.86303	validation_1-auc:0.83774
[21]	validation_0-auc:0.86344	validation_1-auc:0.83706
[22]	validation_0-auc:0.86436	validation_1-auc:0.83797
[23]	validation_0-auc:0.86510	validation_1-auc:0.83779
[24]	validation_0-auc:0.86599	validation_1-auc:0.83699
[25]	validation_0-auc:0.86622	validation_1-auc:0.83717
[26]	validation_0-auc:0.86666	validation_1-auc:0.83686
[27]	validation_0-auc:0.86676	validation_1-auc:0.83677
[28]	validation_0-auc:0.86725	validation_1-auc:0.83654
[29]	validation_0-auc:0.86801	validation_1-auc:0.83721
[30]	validation_0-auc:0.86835	validation_1-auc:0.83702
[31]	validation_0-auc:0.86855	validation_1-auc:0.83695
[32]	validation_0-auc:0.86923	validation_1-auc:0.83718
[33]	validation_0-auc:0.86939	validation_1-auc:0.83721
[34]	validation_0-auc:0.86989	validation_1-auc:0.83775
[35]	validation_0-auc:0.87036	validation_1-auc:0.83726
[36]	validation_0-auc:0.87093	validation_1-auc:0.83715
[37]	validation_0-auc:0.87206	validation_1-auc:0.83741
[38]	validation_0-auc:0.87238	validation_1-auc:0.83684
[39]	validation_0-auc:0.87238	validation_1-auc:0.83715
[40]	validation_0-auc:0.87273	validation_1-auc:0.83752
[41]	validation_0-auc:0.87301	validation_1-auc:0.83752
[42]	validation_0-auc:0.87315	validation_1-auc:0.83757
[43]	validation_0-auc:0.87336	validation_1-auc:0.83705
[44]	validation_0-auc:0.87348	validation_1-auc:0.83684
[45]	validation_0-auc:0.87353	validation_1-auc:0.83677
[46]	validation_0-auc:0.87404	validation_1-auc:0.83655
[47]	validation_0-auc:0.87446	validation_1-auc:0.83642
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.81573	validation_1-auc:0.81067
[1]	validation_0-auc:0.81402	validation_1-auc:0.80774
[2]	validation_0-auc:0.82912	validation_1-auc:0.81864
[3]	validation_0-auc:0.83834	validation_1-auc:0.82490
[4]	validation_0-auc:0.84340	validation_1-auc:0.82924
[5]	validation_0-auc:0.84800	validation_1-auc:0.83252
[6]	validation_0-auc:0.85152	validation_1-auc:0.83472
[7]	validation_0-auc:0.85737	validation_1-auc:0.83466
[8]	validation_0-auc:0.86002	validation_1-auc:0.83343
[9]	validation_0-auc:0.86333	validation_1-auc:0.83595
[10]	validation_0-auc:0.86764	validation_1-auc:0.83618
[11]	validation_0-auc:0.87055	validation_1-auc:0.83591
[12]	validation_0-auc:0.87303	validation_1-auc:0.83511
[13]	validation_0-auc:0.87531	validation_1-auc:0.83573
[14]	validation_0-auc:0.87644	validation_1-auc:0.83532
[15]	validation_0-auc:0.87864	validation_1-auc:0.83346
[16]	validation_0-auc:0.87995	validation_1-auc:0.83380
[17]	validation_0-auc:0.88099	validation_1-auc:0.83336
[18]	validation_0-auc:0.88257	validation_1-auc:0.83356
[19]	validation_0-auc:0.88371	validation_1-auc:0.83321
[20]	validation_0-auc:0.88439	validation_1-auc:0.83356
[21]	validation_0-auc:0.88586	validation_1-auc:0.83317
[22]	validation_0-auc:0.88709	validation_1-auc:0.83316
[23]	validation_0-auc:0.88830	validation_1-auc:0.83373
[24]	validation_0-auc:0.88935	validation_1-auc:0.83351
[25]	validation_0-auc:0.88952	validation_1-auc:0.83307
[26]	validation_0-auc:0.89008	validation_1-auc:0.83344
[27]	validation_0-auc:0.89029	validation_1-auc:0.83254
[28]	validation_0-auc:0.89092	validation_1-auc:0.83229
[29]	validation_0-auc:0.89101	validation_1-auc:0.83245
[30]	validation_0-auc:0.89101	validation_1-auc:0.83259
[31]	validation_0-auc:0.89140	validation_1-auc:0.83219
[32]	validation_0-auc:0.89238	validation_1-auc:0.83116
[33]	validation_0-auc:0.89233	validation_1-auc:0.83080
[34]	validation_0-auc:0.89242	validation_1-auc:0.83077
[35]	validation_0-auc:0.89254	validation_1-auc:0.83114
[36]	validation_0-auc:0.89271	validation_1-auc:0.83110
[37]	validation_0-auc:0.89290	validation_1-auc:0.83083
[38]	validation_0-auc:0.89336	validation_1-auc:0.83049
[39]	validation_0-auc:0.89530	validation_1-auc:0.82890
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.81428	validation_1-auc:0.80541
[1]	validation_0-auc:0.81563	validation_1-auc:0.81177
[2]	validation_0-auc:0.83592	validation_1-auc:0.82066
[3]	validation_0-auc:0.84379	validation_1-auc:0.82740
[4]	validation_0-auc:0.85017	validation_1-auc:0.83233
[5]	validation_0-auc:0.85384	validation_1-auc:0.83517
[6]	validation_0-auc:0.85918	validation_1-auc:0.83931
[7]	validation_0-auc:0.86245	validation_1-auc:0.83779
[8]	validation_0-auc:0.86419	validation_1-auc:0.83818
[9]	validation_0-auc:0.86613	validation_1-auc:0.83712
[10]	validation_0-auc:0.86933	validation_1-auc:0.83600
[11]	validation_0-auc:0.87184	validation_1-auc:0.83711
[12]	validation_0-auc:0.87415	validation_1-auc:0.83710
[13]	validation_0-auc:0.87716	validation_1-auc:0.83639
[14]	validation_0-auc:0.87865	validation_1-auc:0.83795
[15]	validation_0-auc:0.88110	validation_1-auc:0.83841
[16]	validation_0-auc:0.88358	validation_1-auc:0.83779
[17]	validation_0-auc:0.88461	validation_1-auc:0.83794
[18]	validation_0-auc:0.88528	validation_1-auc:0.83693
[19]	validation_0-auc:0.88665	validation_1-auc:0.83657
[20]	validation_0-auc:0.88726	validation_1-auc:0.83669
[21]	validation_0-auc:0.88784	validation_1-auc:0.83639
[22]	validation_0-auc:0.88877	validation_1-auc:0.83675
[23]	validation_0-auc:0.88977	validation_1-auc:0.83683
[24]	validation_0-auc:0.89106	validation_1-auc:0.83613
[25]	validation_0-auc:0.89126	validation_1-auc:0.83660
[26]	validation_0-auc:0.89187	validation_1-auc:0.83647
[27]	validation_0-auc:0.89194	validation_1-auc:0.83668
[28]	validation_0-auc:0.89241	validation_1-auc:0.83639
[29]	validation_0-auc:0.89287	validation_1-auc:0.83627
[30]	validation_0-auc:0.89301	validation_1-auc:0.83632
[31]	validation_0-auc:0.89311	validation_1-auc:0.83618
[32]	validation_0-auc:0.89323	validation_1-auc:0.83561
[33]	validation_0-auc:0.89324	validation_1-auc:0.83535
[34]	validation_0-auc:0.89379	validation_1-auc:0.83478
[35]	validation_0-auc:0.89558	validation_1-auc:0.83419
[36]	validation_0-auc:0.89575	validation_1-auc:0.83435
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.82448	validation_1-auc:0.81823
[1]	validation_0-auc:0.82212	validation_1-auc:0.81592
[2]	validation_0-auc:0.83464	validation_1-auc:0.82639
[3]	validation_0-auc:0.84121	validation_1-auc:0.82994
[4]	validation_0-auc:0.84804	validation_1-auc:0.83439
[5]	validation_0-auc:0.85362	validation_1-auc:0.83314
[6]	validation_0-auc:0.85620	validation_1-auc:0.83629
[7]	validation_0-auc:0.86025	validation_1-auc:0.83581
[8]	validation_0-auc:0.86252	validation_1-auc:0.83743
[9]	validation_0-auc:0.86649	validation_1-auc:0.83646
[10]	validation_0-auc:0.87101	validation_1-auc:0.83606
[11]	validation_0-auc:0.87345	validation_1-auc:0.83743
[12]	validation_0-auc:0.87701	validation_1-auc:0.83809
[13]	validation_0-auc:0.88044	validation_1-auc:0.83779
[14]	validation_0-auc:0.88136	validation_1-auc:0.83869
[15]	validation_0-auc:0.88292	validation_1-auc:0.83977
[16]	validation_0-auc:0.88460	validation_1-auc:0.83955
[17]	validation_0-auc:0.88560	validation_1-auc:0.83952
[18]	validation_0-auc:0.88737	validation_1-auc:0.83966
[19]	validation_0-auc:0.88791	validation_1-auc:0.83902
[20]	validation_0-auc:0.88921	validation_1-auc:0.83812
[21]	validation_0-auc:0.88990	validation_1-auc:0.83808
[22]	validation_0-auc:0.89119	validation_1-auc:0.83848
[23]	validation_0-auc:0.89132	validation_1-auc:0.83821
[24]	validation_0-auc:0.89151	validation_1-auc:0.83836
[25]	validation_0-auc:0.89218	validation_1-auc:0.83825
[26]	validation_0-auc:0.89259	validation_1-auc:0.83789
[27]	validation_0-auc:0.89286	validation_1-auc:0.83822
[28]	validation_0-auc:0.89339	validation_1-auc:0.83884
[29]	validation_0-auc:0.89368	validation_1-auc:0.83923
[30]	validation_0-auc:0.89400	validation_1-auc:0.83906
[31]	validation_0-auc:0.89461	validation_1-auc:0.83875
[32]	validation_0-auc:0.89599	validation_1-auc:0.83829
[33]	validation_0-auc:0.89637	validation_1-auc:0.83835
[34]	validation_0-auc:0.89658	validation_1-auc:0.83826
[35]	validation_0-auc:0.89678	validation_1-auc:0.83787
[36]	validation_0-auc:0.89722	validation_1-auc:0.83755
[37]	validation_0-auc:0.89733	validation_1-auc:0.83735
[38]	validation_0-auc:0.89809	validation_1-auc:0.83710
[39]	validation_0-auc:0.89978	validation_1-auc:0.83646
[40]	validation_0-auc:0.89994	validation_1-auc:0.83517
[41]	validation_0-auc:0.90029	validation_1-auc:0.83466
[42]	validation_0-auc:0.90106	validation_1-auc:0.83394
[43]	validation_0-auc:0.90121	validation_1-auc:0.83358
[44]	validation_0-auc:0.90189	validation_1-auc:0.83272
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.81642	validation_1-auc:0.81216
[1]	validation_0-auc:0.81467	validation_1-auc:0.81133
[2]	validation_0-auc:0.82902	validation_1-auc:0.82239
[3]	validation_0-auc:0.83775	validation_1-auc:0.82795
[4]	validation_0-auc:0.84354	validation_1-auc:0.83096
[5]	validation_0-auc:0.84790	validation_1-auc:0.83441
[6]	validation_0-auc:0.85080	validation_1-auc:0.83508
[7]	validation_0-auc:0.85454	validation_1-auc:0.83765
[8]	validation_0-auc:0.85680	validation_1-auc:0.83712
[9]	validation_0-auc:0.85991	validation_1-auc:0.83639
[10]	validation_0-auc:0.86257	validation_1-auc:0.83788
[11]	validation_0-auc:0.86486	validation_1-auc:0.83696
[12]	validation_0-auc:0.86742	validation_1-auc:0.83751
[13]	validation_0-auc:0.86908	validation_1-auc:0.83692
[14]	validation_0-auc:0.87015	validation_1-auc:0.83647
[15]	validation_0-auc:0.87203	validation_1-auc:0.83610
[16]	validation_0-auc:0.87312	validation_1-auc:0.83591
[17]	validation_0-auc:0.87401	validation_1-auc:0.83522
[18]	validation_0-auc:0.87530	validation_1-auc:0.83620
[19]	validation_0-auc:0.87557	validation_1-auc:0.83593
[20]	validation_0-auc:0.87615	validation_1-auc:0.83572
[21]	validation_0-auc:0.87654	validation_1-auc:0.83491
[22]	validation_0-auc:0.87686	validation_1-auc:0.83470
[23]	validation_0-auc:0.87802	validation_1-auc:0.83387
[24]	validation_0-auc:0.87833	validation_1-auc:0.83389
[25]	validation_0-auc:0.87844	validation_1-auc:0.83418
[26]	validation_0-auc:0.87823	validation_1-auc:0.83352
[27]	validation_0-auc:0.87835	validation_1-auc:0.83349
[28]	validation_0-auc:0.87917	validation_1-auc:0.83296
[29]	validation_0-auc:0.87943	validation_1-auc:0.83221
[30]	validation_0-auc:0.88058	validation_1-auc:0.83157
[31]	validation_0-auc:0.88095	validation_1-auc:0.83166
[32]	validation_0-auc:0.88121	validation_1-auc:0.83150
[33]	validation_0-auc:0.88151	validation_1-auc:0.83233
[34]	validation_0-auc:0.88173	validation_1-auc:0.83203
[35]	validation_0-auc:0.88230	validation_1-auc:0.83163
[36]	validation_0-auc:0.88239	validation_1-auc:0.83148
[37]	validation_0-auc:0.88300	validation_1-auc:0.83086
[38]	validation_0-auc:0.88390	validation_1-auc:0.83043
[39]	validation_0-auc:0.88482	validation_1-auc:0.83050
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.81195	validation_1-auc:0.80615
[1]	validation_0-auc:0.81510	validation_1-auc:0.81289
[2]	validation_0-auc:0.83475	validation_1-auc:0.82645
[3]	validation_0-auc:0.84423	validation_1-auc:0.83140
[4]	validation_0-auc:0.84952	validation_1-auc:0.83408
[5]	validation_0-auc:0.85317	validation_1-auc:0.83493
[6]	validation_0-auc:0.85713	validation_1-auc:0.83850
[7]	validation_0-auc:0.85924	validation_1-auc:0.83793
[8]	validation_0-auc:0.86016	validation_1-auc:0.83809
[9]	validation_0-auc:0.86307	validation_1-auc:0.83816
[10]	validation_0-auc:0.86572	validation_1-auc:0.83931
[11]	validation_0-auc:0.86748	validation_1-auc:0.83981
[12]	validation_0-auc:0.87020	validation_1-auc:0.83906
[13]	validation_0-auc:0.87270	validation_1-auc:0.84018
[14]	validation_0-auc:0.87371	validation_1-auc:0.84127
[15]	validation_0-auc:0.87558	validation_1-auc:0.84117
[16]	validation_0-auc:0.87630	validation_1-auc:0.84078
[17]	validation_0-auc:0.87673	validation_1-auc:0.84143
[18]	validation_0-auc:0.87773	validation_1-auc:0.84117
[19]	validation_0-auc:0.87853	validation_1-auc:0.84073
[20]	validation_0-auc:0.87944	validation_1-auc:0.84043
[21]	validation_0-auc:0.88031	validation_1-auc:0.84016
[22]	validation_0-auc:0.88152	validation_1-auc:0.84011
[23]	validation_0-auc:0.88229	validation_1-auc:0.84037
[24]	validation_0-auc:0.88302	validation_1-auc:0.84030
[25]	validation_0-auc:0.88319	validation_1-auc:0.84035
[26]	validation_0-auc:0.88331	validation_1-auc:0.84042
[27]	validation_0-auc:0.88374	validation_1-auc:0.83981
[28]	validation_0-auc:0.88437	validation_1-auc:0.83969
[29]	validation_0-auc:0.88430	validation_1-auc:0.83984
[30]	validation_0-auc:0.88448	validation_1-auc:0.83927
[31]	validation_0-auc:0.88478	validation_1-auc:0.83854
[32]	validation_0-auc:0.88527	validation_1-auc:0.83809
[33]	validation_0-auc:0.88527	validation_1-auc:0.83816
[34]	validation_0-auc:0.88573	validation_1-auc:0.83816
[35]	validation_0-auc:0.88579	validation_1-auc:0.83781
[36]	validation_0-auc:0.88615	validation_1-auc:0.83815
[37]	validation_0-auc:0.88632	validation_1-auc:0.83822
[38]	validation_0-auc:0.88677	validation_1-auc:0.83768
[39]	validation_0-auc:0.88687	validation_1-auc:0.83777
[40]	validation_0-auc:0.88806	validation_1-auc:0.83728
[41]	validation_0-auc:0.88826	validation_1-auc:0.83720
[42]	validation_0-auc:0.88844	validation_1-auc:0.83717
[43]	validation_0-auc:0.88903	validation_1-auc:0.83634
[44]	validation_0-auc:0.88944	validation_1-auc:0.83652
[45]	validation_0-auc:0.88957	validation_1-auc:0.83666
[46]	validation_0-auc:0.88969	validation_1-auc:0.83630
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.82218	validation_1-auc:0.81819
[1]	validation_0-auc:0.82120	validation_1-auc:0.81682
[2]	validation_0-auc:0.83459	validation_1-auc:0.82497
[3]	validation_0-auc:0.84312	validation_1-auc:0.82940
[4]	validation_0-auc:0.84793	validation_1-auc:0.83178
[5]	validation_0-auc:0.85339	validation_1-auc:0.83203
[6]	validation_0-auc:0.85638	validation_1-auc:0.83512
[7]	validation_0-auc:0.86082	validation_1-auc:0.83538
[8]	validation_0-auc:0.86250	validation_1-auc:0.83772
[9]	validation_0-auc:0.86569	validation_1-auc:0.83589
[10]	validation_0-auc:0.86855	validation_1-auc:0.83342
[11]	validation_0-auc:0.87103	validation_1-auc:0.83398
[12]	validation_0-auc:0.87268	validation_1-auc:0.83472
[13]	validation_0-auc:0.87475	validation_1-auc:0.83576
[14]	validation_0-auc:0.87519	validation_1-auc:0.83642
[15]	validation_0-auc:0.87568	validation_1-auc:0.83708
[16]	validation_0-auc:0.87705	validation_1-auc:0.83742
[17]	validation_0-auc:0.87816	validation_1-auc:0.83725
[18]	validation_0-auc:0.87960	validation_1-auc:0.83748
[19]	validation_0-auc:0.88066	validation_1-auc:0.83743
[20]	validation_0-auc:0.88106	validation_1-auc:0.83706
[21]	validation_0-auc:0.88130	validation_1-auc:0.83685
[22]	validation_0-auc:0.88181	validation_1-auc:0.83701
[23]	validation_0-auc:0.88268	validation_1-auc:0.83760
[24]	validation_0-auc:0.88287	validation_1-auc:0.83759
[25]	validation_0-auc:0.88349	validation_1-auc:0.83769
[26]	validation_0-auc:0.88356	validation_1-auc:0.83738
[27]	validation_0-auc:0.88422	validation_1-auc:0.83697
[28]	validation_0-auc:0.88470	validation_1-auc:0.83692
[29]	validation_0-auc:0.88499	validation_1-auc:0.83655
[30]	validation_0-auc:0.88605	validation_1-auc:0.83731
[31]	validation_0-auc:0.88616	validation_1-auc:0.83742
[32]	validation_0-auc:0.88634	validation_1-auc:0.83749
[33]	validation_0-auc:0.88638	validation_1-auc:0.83769
[34]	validation_0-auc:0.88647	validation_1-auc:0.83766
[35]	validation_0-auc:0.88742	validation_1-auc:0.83784
[36]	validation_0-auc:0.88772	validation_1-auc:0.83717
[37]	validation_0-auc:0.88800	validation_1-auc:0.83703
[38]	validation_0-auc:0.88804	validation_1-auc:0.83704
[39]	validation_0-auc:0.88806	validation_1-auc:0.83733
[40]	validation_0-auc:0.88820	validation_1-auc:0.83711
[41]	validation_0-auc:0.88864	validation_1-auc:0.83711
[42]	validation_0-auc:0.88884	validation_1-auc:0.83691
[43]	validation_0-auc:0.88959	validation_1-auc:0.83599
[44]	validation_0-auc:0.89049	validation_1-auc:0.83564
[45]	validation_0-auc:0.89064	validation_1-auc:0.83583
[46]	validation_0-auc:0.89090	validation_1-auc:0.83548
[47]	validation_0-auc:0.89094	validation_1-auc:0.83519
[48]	validation_0-auc:0.89103	validation_1-auc:0.83547
[49]	validation_0-auc:0.89242	validation_1-auc:0.83543
[50]	validation_0-auc:0.89263	validation_1-auc:0.83518
[51]	validation_0-auc:0.89269	validation_1-auc:0.83503
[52]	validation_0-auc:0.89305	validation_1-auc:0.83429
[53]	validation_0-auc:0.89313	validation_1-auc:0.83395
[54]	validation_0-auc:0.89387	validation_1-auc:0.83441
[55]	validation_0-auc:0.89434	validation_1-auc:0.83376
[56]	validation_0-auc:0.89461	validation_1-auc:0.83378
[57]	validation_0-auc:0.89464	validation_1-auc:0.83355
[58]	validation_0-auc:0.89499	validation_1-auc:0.83349
[59]	validation_0-auc:0.89506	validation_1-auc:0.83337
[60]	validation_0-auc:0.89596	validation_1-auc:0.83275
[61]	validation_0-auc:0.89625	validation_1-auc:0.83229
[62]	validation_0-auc:0.89658	validation_1-auc:0.83240
[63]	validation_0-auc:0.89643	validation_1-auc:0.83233
[64]	validation_0-auc:0.89645	validation_1-auc:0.83215
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.81270	validation_1-auc:0.81076
[1]	validation_0-auc:0.81820	validation_1-auc:0.81360
[2]	validation_0-auc:0.83353	validation_1-auc:0.83010
[3]	validation_0-auc:0.83823	validation_1-auc:0.83429
[4]	validation_0-auc:0.84125	validation_1-auc:0.83363
[5]	validation_0-auc:0.83979	validation_1-auc:0.83299
[6]	validation_0-auc:0.83796	validation_1-auc:0.83148
[7]	validation_0-auc:0.84384	validation_1-auc:0.83526
[8]	validation_0-auc:0.84676	validation_1-auc:0.83677
[9]	validation_0-auc:0.84731	validation_1-auc:0.83538
[10]	validation_0-auc:0.84726	validation_1-auc:0.83485
[11]	validation_0-auc:0.85253	validation_1-auc:0.84007
[12]	validation_0-auc:0.85678	validation_1-auc:0.84255
[13]	validation_0-auc:0.85821	validation_1-auc:0.84121
[14]	validation_0-auc:0.86100	validation_1-auc:0.84394
[15]	validation_0-auc:0.86250	validation_1-auc:0.84436
[16]	validation_0-auc:0.86371	validation_1-auc:0.84416
[17]	validation_0-auc:0.86531	validation_1-auc:0.84329
[18]	validation_0-auc:0.86661	validation_1-auc:0.84514
[19]	validation_0-auc:0.86843	validation_1-auc:0.84475
[20]	validation_0-auc:0.86982	validation_1-auc:0.84504
[21]	validation_0-auc:0.87086	validation_1-auc:0.84455
[22]	validation_0-auc:0.87217	validation_1-auc:0.84348
[23]	validation_0-auc:0.87245	validation_1-auc:0.84353
[24]	validation_0-auc:0.87288	validation_1-auc:0.84332
[25]	validation_0-auc:0.87357	validation_1-auc:0.84280
[26]	validation_0-auc:0.87415	validation_1-auc:0.84256
[27]	validation_0-auc:0.87457	validation_1-auc:0.84236
[28]	validation_0-auc:0.87480	validation_1-auc:0.84238
[29]	validation_0-auc:0.87526	validation_1-auc:0.84256
[30]	validation_0-auc:0.87542	validation_1-auc:0.84259
[31]	validation_0-auc:0.87579	validation_1-auc:0.84232
[32]	validation_0-auc:0.87651	validation_1-auc:0.84209
[33]	validation_0-auc:0.87710	validation_1-auc:0.84197
[34]	validation_0-auc:0.87786	validation_1-auc:0.84234
[35]	validation_0-auc:0.87852	validation_1-auc:0.84190
[36]	validation_0-auc:0.87900	validation_1-auc:0.84162
[37]	validation_0-auc:0.87939	validation_1-auc:0.84191
[38]	validation_0-auc:0.87975	validation_1-auc:0.84166
[39]	validation_0-auc:0.88029	validation_1-auc:0.84169
[40]	validation_0-auc:0.88142	validation_1-auc:0.84133
[41]	validation_0-auc:0.88153	validation_1-auc:0.84140
[42]	validation_0-auc:0.88231	validation_1-auc:0.84144
[43]	validation_0-auc:0.88254	validation_1-auc:0.84134
[44]	validation_0-auc:0.88291	validation_1-auc:0.84132
[45]	validation_0-auc:0.88334	validation_1-auc:0.84159
[46]	validation_0-auc:0.88343	validation_1-auc:0.84149
[47]	validation_0-auc:0.88391	validation_1-auc:0.84161
GridSearchCV 최적 파라미터: {'colsample_bytree': 0.5, 'max_depth': 5, 'min_child_weight': 3}
ROC AUC: 0.8451
</pre>
- 성능은 약 0.8451 정도



```python
### 하이퍼 파라미터 튜닝(2)
# n_estimators는 1000으로 증가시키고, learning_rate = 0.02로 감소, reg_alpha = 0.03으로 추가 

xgb_clf = XGBClassifier(n_estimators = 1000, random_state = 156, 
                        learning_rate = 0.02, max_depth = 7,\
                        min_child_weight = 1, colsample_bytree = 0.75, reg_alpha = 0.03)

# evaluation metric을 auc로, early_stopping은 200 으로 설정하고 학습 수행 
# 학습
xgb_clf.fit(X_train, y_train, early_stopping_rounds = 200, 
            eval_metric = "auc", eval_set = [(X_train, y_train), (X_test, y_test)])

# 예측 & 평가
xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1], average = 'macro')
print('ROC AUC: {0:.4f}'.format(xgb_roc_score))
```

<pre>
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre>
<pre>
[0]	validation_0-auc:0.82311	validation_1-auc:0.81793
[1]	validation_0-auc:0.82585	validation_1-auc:0.81766
[2]	validation_0-auc:0.82950	validation_1-auc:0.81846
[3]	validation_0-auc:0.83162	validation_1-auc:0.82051
[4]	validation_0-auc:0.83561	validation_1-auc:0.82587
[5]	validation_0-auc:0.83569	validation_1-auc:0.82566
[6]	validation_0-auc:0.83635	validation_1-auc:0.82582
[7]	validation_0-auc:0.83757	validation_1-auc:0.82763
[8]	validation_0-auc:0.83873	validation_1-auc:0.82945
[9]	validation_0-auc:0.83986	validation_1-auc:0.83072
[10]	validation_0-auc:0.84036	validation_1-auc:0.83039
[11]	validation_0-auc:0.84071	validation_1-auc:0.83051
[12]	validation_0-auc:0.84064	validation_1-auc:0.82997
[13]	validation_0-auc:0.84098	validation_1-auc:0.82958
[14]	validation_0-auc:0.84174	validation_1-auc:0.83016
[15]	validation_0-auc:0.84223	validation_1-auc:0.83103
[16]	validation_0-auc:0.84262	validation_1-auc:0.83055
[17]	validation_0-auc:0.84302	validation_1-auc:0.83020
[18]	validation_0-auc:0.84539	validation_1-auc:0.83365
[19]	validation_0-auc:0.84552	validation_1-auc:0.83365
[20]	validation_0-auc:0.84602	validation_1-auc:0.83425
[21]	validation_0-auc:0.84638	validation_1-auc:0.83417
[22]	validation_0-auc:0.84674	validation_1-auc:0.83410
[23]	validation_0-auc:0.84709	validation_1-auc:0.83411
[24]	validation_0-auc:0.84733	validation_1-auc:0.83414
[25]	validation_0-auc:0.84748	validation_1-auc:0.83433
[26]	validation_0-auc:0.84773	validation_1-auc:0.83412
[27]	validation_0-auc:0.84851	validation_1-auc:0.83440
[28]	validation_0-auc:0.84845	validation_1-auc:0.83438
[29]	validation_0-auc:0.84997	validation_1-auc:0.83507
[30]	validation_0-auc:0.84927	validation_1-auc:0.83379
[31]	validation_0-auc:0.84984	validation_1-auc:0.83457
[32]	validation_0-auc:0.85048	validation_1-auc:0.83473
[33]	validation_0-auc:0.85068	validation_1-auc:0.83501
[34]	validation_0-auc:0.85075	validation_1-auc:0.83495
[35]	validation_0-auc:0.85103	validation_1-auc:0.83530
[36]	validation_0-auc:0.85164	validation_1-auc:0.83564
[37]	validation_0-auc:0.85178	validation_1-auc:0.83554
[38]	validation_0-auc:0.85234	validation_1-auc:0.83545
[39]	validation_0-auc:0.85237	validation_1-auc:0.83567
[40]	validation_0-auc:0.85311	validation_1-auc:0.83620
[41]	validation_0-auc:0.85368	validation_1-auc:0.83621
[42]	validation_0-auc:0.85389	validation_1-auc:0.83596
[43]	validation_0-auc:0.85433	validation_1-auc:0.83682
[44]	validation_0-auc:0.85522	validation_1-auc:0.83704
[45]	validation_0-auc:0.85467	validation_1-auc:0.83725
[46]	validation_0-auc:0.85488	validation_1-auc:0.83704
[47]	validation_0-auc:0.85532	validation_1-auc:0.83738
[48]	validation_0-auc:0.85549	validation_1-auc:0.83757
[49]	validation_0-auc:0.85594	validation_1-auc:0.83784
[50]	validation_0-auc:0.85634	validation_1-auc:0.83812
[51]	validation_0-auc:0.85657	validation_1-auc:0.83801
[52]	validation_0-auc:0.85697	validation_1-auc:0.83844
[53]	validation_0-auc:0.85723	validation_1-auc:0.83852
[54]	validation_0-auc:0.85742	validation_1-auc:0.83858
[55]	validation_0-auc:0.85812	validation_1-auc:0.83872
[56]	validation_0-auc:0.85866	validation_1-auc:0.83871
[57]	validation_0-auc:0.85912	validation_1-auc:0.83880
[58]	validation_0-auc:0.85923	validation_1-auc:0.83909
[59]	validation_0-auc:0.85954	validation_1-auc:0.83934
[60]	validation_0-auc:0.85967	validation_1-auc:0.83949
[61]	validation_0-auc:0.86005	validation_1-auc:0.83945
[62]	validation_0-auc:0.86043	validation_1-auc:0.83996
[63]	validation_0-auc:0.86012	validation_1-auc:0.83966
[64]	validation_0-auc:0.86063	validation_1-auc:0.83984
[65]	validation_0-auc:0.86082	validation_1-auc:0.83975
[66]	validation_0-auc:0.86093	validation_1-auc:0.83895
[67]	validation_0-auc:0.86136	validation_1-auc:0.83965
[68]	validation_0-auc:0.86149	validation_1-auc:0.83962
[69]	validation_0-auc:0.86173	validation_1-auc:0.83958
[70]	validation_0-auc:0.86199	validation_1-auc:0.83980
[71]	validation_0-auc:0.86218	validation_1-auc:0.83973
[72]	validation_0-auc:0.86248	validation_1-auc:0.83983
[73]	validation_0-auc:0.86276	validation_1-auc:0.83996
[74]	validation_0-auc:0.86285	validation_1-auc:0.83998
[75]	validation_0-auc:0.86294	validation_1-auc:0.83973
[76]	validation_0-auc:0.86316	validation_1-auc:0.83976
[77]	validation_0-auc:0.86358	validation_1-auc:0.83968
[78]	validation_0-auc:0.86369	validation_1-auc:0.83982
[79]	validation_0-auc:0.86398	validation_1-auc:0.83987
[80]	validation_0-auc:0.86432	validation_1-auc:0.84005
[81]	validation_0-auc:0.86476	validation_1-auc:0.84042
[82]	validation_0-auc:0.86498	validation_1-auc:0.84035
[83]	validation_0-auc:0.86530	validation_1-auc:0.84019
[84]	validation_0-auc:0.86578	validation_1-auc:0.84093
[85]	validation_0-auc:0.86592	validation_1-auc:0.84102
[86]	validation_0-auc:0.86611	validation_1-auc:0.84108
[87]	validation_0-auc:0.86618	validation_1-auc:0.84116
[88]	validation_0-auc:0.86644	validation_1-auc:0.84116
[89]	validation_0-auc:0.86686	validation_1-auc:0.84144
[90]	validation_0-auc:0.86707	validation_1-auc:0.84125
[91]	validation_0-auc:0.86721	validation_1-auc:0.84144
[92]	validation_0-auc:0.86743	validation_1-auc:0.84143
[93]	validation_0-auc:0.86771	validation_1-auc:0.84160
[94]	validation_0-auc:0.86807	validation_1-auc:0.84154
[95]	validation_0-auc:0.86823	validation_1-auc:0.84149
[96]	validation_0-auc:0.86843	validation_1-auc:0.84156
[97]	validation_0-auc:0.86860	validation_1-auc:0.84159
[98]	validation_0-auc:0.86881	validation_1-auc:0.84167
[99]	validation_0-auc:0.86902	validation_1-auc:0.84168
[100]	validation_0-auc:0.86919	validation_1-auc:0.84163
[101]	validation_0-auc:0.86925	validation_1-auc:0.84163
[102]	validation_0-auc:0.86960	validation_1-auc:0.84177
[103]	validation_0-auc:0.86976	validation_1-auc:0.84180
[104]	validation_0-auc:0.86996	validation_1-auc:0.84189
[105]	validation_0-auc:0.87023	validation_1-auc:0.84202
[106]	validation_0-auc:0.87045	validation_1-auc:0.84195
[107]	validation_0-auc:0.87078	validation_1-auc:0.84188
[108]	validation_0-auc:0.87092	validation_1-auc:0.84199
[109]	validation_0-auc:0.87112	validation_1-auc:0.84217
[110]	validation_0-auc:0.87141	validation_1-auc:0.84213
[111]	validation_0-auc:0.87192	validation_1-auc:0.84244
[112]	validation_0-auc:0.87232	validation_1-auc:0.84243
[113]	validation_0-auc:0.87242	validation_1-auc:0.84232
[114]	validation_0-auc:0.87252	validation_1-auc:0.84229
[115]	validation_0-auc:0.87279	validation_1-auc:0.84238
[116]	validation_0-auc:0.87282	validation_1-auc:0.84228
[117]	validation_0-auc:0.87282	validation_1-auc:0.84234
[118]	validation_0-auc:0.87274	validation_1-auc:0.84222
[119]	validation_0-auc:0.87291	validation_1-auc:0.84231
[120]	validation_0-auc:0.87319	validation_1-auc:0.84241
[121]	validation_0-auc:0.87352	validation_1-auc:0.84235
[122]	validation_0-auc:0.87383	validation_1-auc:0.84233
[123]	validation_0-auc:0.87422	validation_1-auc:0.84236
[124]	validation_0-auc:0.87438	validation_1-auc:0.84269
[125]	validation_0-auc:0.87444	validation_1-auc:0.84250
[126]	validation_0-auc:0.87460	validation_1-auc:0.84279
[127]	validation_0-auc:0.87495	validation_1-auc:0.84275
[128]	validation_0-auc:0.87543	validation_1-auc:0.84248
[129]	validation_0-auc:0.87577	validation_1-auc:0.84236
[130]	validation_0-auc:0.87601	validation_1-auc:0.84235
[131]	validation_0-auc:0.87627	validation_1-auc:0.84224
[132]	validation_0-auc:0.87640	validation_1-auc:0.84255
[133]	validation_0-auc:0.87656	validation_1-auc:0.84265
[134]	validation_0-auc:0.87688	validation_1-auc:0.84274
[135]	validation_0-auc:0.87708	validation_1-auc:0.84283
[136]	validation_0-auc:0.87711	validation_1-auc:0.84300
[137]	validation_0-auc:0.87728	validation_1-auc:0.84307
[138]	validation_0-auc:0.87767	validation_1-auc:0.84305
[139]	validation_0-auc:0.87803	validation_1-auc:0.84299
[140]	validation_0-auc:0.87816	validation_1-auc:0.84308
[141]	validation_0-auc:0.87825	validation_1-auc:0.84306
[142]	validation_0-auc:0.87861	validation_1-auc:0.84288
[143]	validation_0-auc:0.87879	validation_1-auc:0.84282
[144]	validation_0-auc:0.87896	validation_1-auc:0.84296
[145]	validation_0-auc:0.87911	validation_1-auc:0.84314
[146]	validation_0-auc:0.87940	validation_1-auc:0.84316
[147]	validation_0-auc:0.87956	validation_1-auc:0.84323
[148]	validation_0-auc:0.87977	validation_1-auc:0.84337
[149]	validation_0-auc:0.88011	validation_1-auc:0.84347
[150]	validation_0-auc:0.88016	validation_1-auc:0.84351
[151]	validation_0-auc:0.88036	validation_1-auc:0.84368
[152]	validation_0-auc:0.88043	validation_1-auc:0.84369
[153]	validation_0-auc:0.88086	validation_1-auc:0.84372
[154]	validation_0-auc:0.88116	validation_1-auc:0.84389
[155]	validation_0-auc:0.88139	validation_1-auc:0.84393
[156]	validation_0-auc:0.88165	validation_1-auc:0.84387
[157]	validation_0-auc:0.88188	validation_1-auc:0.84389
[158]	validation_0-auc:0.88209	validation_1-auc:0.84390
[159]	validation_0-auc:0.88219	validation_1-auc:0.84396
[160]	validation_0-auc:0.88243	validation_1-auc:0.84418
[161]	validation_0-auc:0.88281	validation_1-auc:0.84436
[162]	validation_0-auc:0.88284	validation_1-auc:0.84432
[163]	validation_0-auc:0.88293	validation_1-auc:0.84461
[164]	validation_0-auc:0.88323	validation_1-auc:0.84463
[165]	validation_0-auc:0.88352	validation_1-auc:0.84467
[166]	validation_0-auc:0.88386	validation_1-auc:0.84495
[167]	validation_0-auc:0.88421	validation_1-auc:0.84493
[168]	validation_0-auc:0.88450	validation_1-auc:0.84497
[169]	validation_0-auc:0.88477	validation_1-auc:0.84497
[170]	validation_0-auc:0.88510	validation_1-auc:0.84503
[171]	validation_0-auc:0.88526	validation_1-auc:0.84505
[172]	validation_0-auc:0.88553	validation_1-auc:0.84502
[173]	validation_0-auc:0.88575	validation_1-auc:0.84502
[174]	validation_0-auc:0.88598	validation_1-auc:0.84505
[175]	validation_0-auc:0.88622	validation_1-auc:0.84508
[176]	validation_0-auc:0.88635	validation_1-auc:0.84517
[177]	validation_0-auc:0.88663	validation_1-auc:0.84514
[178]	validation_0-auc:0.88676	validation_1-auc:0.84510
[179]	validation_0-auc:0.88695	validation_1-auc:0.84513
[180]	validation_0-auc:0.88711	validation_1-auc:0.84525
[181]	validation_0-auc:0.88735	validation_1-auc:0.84534
[182]	validation_0-auc:0.88771	validation_1-auc:0.84527
[183]	validation_0-auc:0.88804	validation_1-auc:0.84529
[184]	validation_0-auc:0.88842	validation_1-auc:0.84538
[185]	validation_0-auc:0.88862	validation_1-auc:0.84526
[186]	validation_0-auc:0.88875	validation_1-auc:0.84521
[187]	validation_0-auc:0.88899	validation_1-auc:0.84531
[188]	validation_0-auc:0.88918	validation_1-auc:0.84538
[189]	validation_0-auc:0.88950	validation_1-auc:0.84530
[190]	validation_0-auc:0.88973	validation_1-auc:0.84513
[191]	validation_0-auc:0.88990	validation_1-auc:0.84525
[192]	validation_0-auc:0.89009	validation_1-auc:0.84528
[193]	validation_0-auc:0.89033	validation_1-auc:0.84525
[194]	validation_0-auc:0.89049	validation_1-auc:0.84522
[195]	validation_0-auc:0.89063	validation_1-auc:0.84529
[196]	validation_0-auc:0.89082	validation_1-auc:0.84541
[197]	validation_0-auc:0.89096	validation_1-auc:0.84531
[198]	validation_0-auc:0.89123	validation_1-auc:0.84544
[199]	validation_0-auc:0.89135	validation_1-auc:0.84557
[200]	validation_0-auc:0.89146	validation_1-auc:0.84557
[201]	validation_0-auc:0.89176	validation_1-auc:0.84560
[202]	validation_0-auc:0.89197	validation_1-auc:0.84568
[203]	validation_0-auc:0.89227	validation_1-auc:0.84576
[204]	validation_0-auc:0.89253	validation_1-auc:0.84571
[205]	validation_0-auc:0.89269	validation_1-auc:0.84576
[206]	validation_0-auc:0.89288	validation_1-auc:0.84578
[207]	validation_0-auc:0.89307	validation_1-auc:0.84584
[208]	validation_0-auc:0.89325	validation_1-auc:0.84590
[209]	validation_0-auc:0.89344	validation_1-auc:0.84598
[210]	validation_0-auc:0.89364	validation_1-auc:0.84598
[211]	validation_0-auc:0.89381	validation_1-auc:0.84591
[212]	validation_0-auc:0.89400	validation_1-auc:0.84591
[213]	validation_0-auc:0.89420	validation_1-auc:0.84590
[214]	validation_0-auc:0.89443	validation_1-auc:0.84589
[215]	validation_0-auc:0.89456	validation_1-auc:0.84585
[216]	validation_0-auc:0.89472	validation_1-auc:0.84582
[217]	validation_0-auc:0.89490	validation_1-auc:0.84577
[218]	validation_0-auc:0.89510	validation_1-auc:0.84579
[219]	validation_0-auc:0.89534	validation_1-auc:0.84582
[220]	validation_0-auc:0.89549	validation_1-auc:0.84580
[221]	validation_0-auc:0.89570	validation_1-auc:0.84588
[222]	validation_0-auc:0.89597	validation_1-auc:0.84581
[223]	validation_0-auc:0.89619	validation_1-auc:0.84583
[224]	validation_0-auc:0.89631	validation_1-auc:0.84582
[225]	validation_0-auc:0.89648	validation_1-auc:0.84574
[226]	validation_0-auc:0.89665	validation_1-auc:0.84569
[227]	validation_0-auc:0.89684	validation_1-auc:0.84571
[228]	validation_0-auc:0.89707	validation_1-auc:0.84562
[229]	validation_0-auc:0.89720	validation_1-auc:0.84559
[230]	validation_0-auc:0.89739	validation_1-auc:0.84546
[231]	validation_0-auc:0.89756	validation_1-auc:0.84540
[232]	validation_0-auc:0.89779	validation_1-auc:0.84534
[233]	validation_0-auc:0.89790	validation_1-auc:0.84528
[234]	validation_0-auc:0.89806	validation_1-auc:0.84528
[235]	validation_0-auc:0.89819	validation_1-auc:0.84530
[236]	validation_0-auc:0.89832	validation_1-auc:0.84528
[237]	validation_0-auc:0.89841	validation_1-auc:0.84526
[238]	validation_0-auc:0.89856	validation_1-auc:0.84523
[239]	validation_0-auc:0.89873	validation_1-auc:0.84516
[240]	validation_0-auc:0.89896	validation_1-auc:0.84512
[241]	validation_0-auc:0.89912	validation_1-auc:0.84505
[242]	validation_0-auc:0.89926	validation_1-auc:0.84501
[243]	validation_0-auc:0.89943	validation_1-auc:0.84494
[244]	validation_0-auc:0.89957	validation_1-auc:0.84486
[245]	validation_0-auc:0.89969	validation_1-auc:0.84489
[246]	validation_0-auc:0.89984	validation_1-auc:0.84491
[247]	validation_0-auc:0.89997	validation_1-auc:0.84499
[248]	validation_0-auc:0.90013	validation_1-auc:0.84494
[249]	validation_0-auc:0.90024	validation_1-auc:0.84497
[250]	validation_0-auc:0.90037	validation_1-auc:0.84501
[251]	validation_0-auc:0.90046	validation_1-auc:0.84497
[252]	validation_0-auc:0.90059	validation_1-auc:0.84494
[253]	validation_0-auc:0.90065	validation_1-auc:0.84493
[254]	validation_0-auc:0.90076	validation_1-auc:0.84495
[255]	validation_0-auc:0.90093	validation_1-auc:0.84500
[256]	validation_0-auc:0.90097	validation_1-auc:0.84491
[257]	validation_0-auc:0.90107	validation_1-auc:0.84487
[258]	validation_0-auc:0.90115	validation_1-auc:0.84484
[259]	validation_0-auc:0.90129	validation_1-auc:0.84478
[260]	validation_0-auc:0.90133	validation_1-auc:0.84473
[261]	validation_0-auc:0.90144	validation_1-auc:0.84468
[262]	validation_0-auc:0.90160	validation_1-auc:0.84472
[263]	validation_0-auc:0.90177	validation_1-auc:0.84465
[264]	validation_0-auc:0.90188	validation_1-auc:0.84466
[265]	validation_0-auc:0.90210	validation_1-auc:0.84468
[266]	validation_0-auc:0.90222	validation_1-auc:0.84467
[267]	validation_0-auc:0.90226	validation_1-auc:0.84469
[268]	validation_0-auc:0.90241	validation_1-auc:0.84464
[269]	validation_0-auc:0.90245	validation_1-auc:0.84456
[270]	validation_0-auc:0.90258	validation_1-auc:0.84463
[271]	validation_0-auc:0.90268	validation_1-auc:0.84464
[272]	validation_0-auc:0.90274	validation_1-auc:0.84459
[273]	validation_0-auc:0.90286	validation_1-auc:0.84461
[274]	validation_0-auc:0.90296	validation_1-auc:0.84468
[275]	validation_0-auc:0.90305	validation_1-auc:0.84475
[276]	validation_0-auc:0.90315	validation_1-auc:0.84471
[277]	validation_0-auc:0.90325	validation_1-auc:0.84471
[278]	validation_0-auc:0.90339	validation_1-auc:0.84465
[279]	validation_0-auc:0.90351	validation_1-auc:0.84459
[280]	validation_0-auc:0.90359	validation_1-auc:0.84464
[281]	validation_0-auc:0.90366	validation_1-auc:0.84465
[282]	validation_0-auc:0.90373	validation_1-auc:0.84465
[283]	validation_0-auc:0.90384	validation_1-auc:0.84461
[284]	validation_0-auc:0.90388	validation_1-auc:0.84460
[285]	validation_0-auc:0.90397	validation_1-auc:0.84455
[286]	validation_0-auc:0.90416	validation_1-auc:0.84450
[287]	validation_0-auc:0.90421	validation_1-auc:0.84450
[288]	validation_0-auc:0.90425	validation_1-auc:0.84454
[289]	validation_0-auc:0.90431	validation_1-auc:0.84450
[290]	validation_0-auc:0.90440	validation_1-auc:0.84443
[291]	validation_0-auc:0.90457	validation_1-auc:0.84440
[292]	validation_0-auc:0.90476	validation_1-auc:0.84436
[293]	validation_0-auc:0.90492	validation_1-auc:0.84442
[294]	validation_0-auc:0.90506	validation_1-auc:0.84443
[295]	validation_0-auc:0.90516	validation_1-auc:0.84450
[296]	validation_0-auc:0.90523	validation_1-auc:0.84449
[297]	validation_0-auc:0.90542	validation_1-auc:0.84444
[298]	validation_0-auc:0.90550	validation_1-auc:0.84440
[299]	validation_0-auc:0.90555	validation_1-auc:0.84439
[300]	validation_0-auc:0.90562	validation_1-auc:0.84433
[301]	validation_0-auc:0.90564	validation_1-auc:0.84436
[302]	validation_0-auc:0.90581	validation_1-auc:0.84440
[303]	validation_0-auc:0.90588	validation_1-auc:0.84434
[304]	validation_0-auc:0.90602	validation_1-auc:0.84429
[305]	validation_0-auc:0.90623	validation_1-auc:0.84427
[306]	validation_0-auc:0.90629	validation_1-auc:0.84428
[307]	validation_0-auc:0.90639	validation_1-auc:0.84432
[308]	validation_0-auc:0.90646	validation_1-auc:0.84432
[309]	validation_0-auc:0.90651	validation_1-auc:0.84438
[310]	validation_0-auc:0.90658	validation_1-auc:0.84431
[311]	validation_0-auc:0.90664	validation_1-auc:0.84432
[312]	validation_0-auc:0.90678	validation_1-auc:0.84433
[313]	validation_0-auc:0.90684	validation_1-auc:0.84428
[314]	validation_0-auc:0.90689	validation_1-auc:0.84438
[315]	validation_0-auc:0.90694	validation_1-auc:0.84442
[316]	validation_0-auc:0.90702	validation_1-auc:0.84433
[317]	validation_0-auc:0.90708	validation_1-auc:0.84431
[318]	validation_0-auc:0.90713	validation_1-auc:0.84428
[319]	validation_0-auc:0.90719	validation_1-auc:0.84424
[320]	validation_0-auc:0.90725	validation_1-auc:0.84423
[321]	validation_0-auc:0.90732	validation_1-auc:0.84424
[322]	validation_0-auc:0.90737	validation_1-auc:0.84423
[323]	validation_0-auc:0.90740	validation_1-auc:0.84429
[324]	validation_0-auc:0.90752	validation_1-auc:0.84426
[325]	validation_0-auc:0.90755	validation_1-auc:0.84429
[326]	validation_0-auc:0.90759	validation_1-auc:0.84429
[327]	validation_0-auc:0.90774	validation_1-auc:0.84434
[328]	validation_0-auc:0.90791	validation_1-auc:0.84434
[329]	validation_0-auc:0.90800	validation_1-auc:0.84430
[330]	validation_0-auc:0.90802	validation_1-auc:0.84432
[331]	validation_0-auc:0.90809	validation_1-auc:0.84429
[332]	validation_0-auc:0.90819	validation_1-auc:0.84426
[333]	validation_0-auc:0.90823	validation_1-auc:0.84427
[334]	validation_0-auc:0.90825	validation_1-auc:0.84428
[335]	validation_0-auc:0.90841	validation_1-auc:0.84425
[336]	validation_0-auc:0.90848	validation_1-auc:0.84424
[337]	validation_0-auc:0.90858	validation_1-auc:0.84417
[338]	validation_0-auc:0.90870	validation_1-auc:0.84422
[339]	validation_0-auc:0.90882	validation_1-auc:0.84424
[340]	validation_0-auc:0.90899	validation_1-auc:0.84431
[341]	validation_0-auc:0.90905	validation_1-auc:0.84430
[342]	validation_0-auc:0.90907	validation_1-auc:0.84432
[343]	validation_0-auc:0.90919	validation_1-auc:0.84439
[344]	validation_0-auc:0.90926	validation_1-auc:0.84442
[345]	validation_0-auc:0.90928	validation_1-auc:0.84443
[346]	validation_0-auc:0.90943	validation_1-auc:0.84443
[347]	validation_0-auc:0.90947	validation_1-auc:0.84442
[348]	validation_0-auc:0.90955	validation_1-auc:0.84441
[349]	validation_0-auc:0.90957	validation_1-auc:0.84443
[350]	validation_0-auc:0.90962	validation_1-auc:0.84442
[351]	validation_0-auc:0.90977	validation_1-auc:0.84441
[352]	validation_0-auc:0.90982	validation_1-auc:0.84439
[353]	validation_0-auc:0.90995	validation_1-auc:0.84440
[354]	validation_0-auc:0.90998	validation_1-auc:0.84440
[355]	validation_0-auc:0.91000	validation_1-auc:0.84436
[356]	validation_0-auc:0.91002	validation_1-auc:0.84436
[357]	validation_0-auc:0.91009	validation_1-auc:0.84436
[358]	validation_0-auc:0.91021	validation_1-auc:0.84434
[359]	validation_0-auc:0.91025	validation_1-auc:0.84433
[360]	validation_0-auc:0.91035	validation_1-auc:0.84437
[361]	validation_0-auc:0.91045	validation_1-auc:0.84431
[362]	validation_0-auc:0.91048	validation_1-auc:0.84435
[363]	validation_0-auc:0.91064	validation_1-auc:0.84437
[364]	validation_0-auc:0.91065	validation_1-auc:0.84436
[365]	validation_0-auc:0.91076	validation_1-auc:0.84433
[366]	validation_0-auc:0.91087	validation_1-auc:0.84428
[367]	validation_0-auc:0.91091	validation_1-auc:0.84427
[368]	validation_0-auc:0.91094	validation_1-auc:0.84428
[369]	validation_0-auc:0.91095	validation_1-auc:0.84427
[370]	validation_0-auc:0.91097	validation_1-auc:0.84430
[371]	validation_0-auc:0.91103	validation_1-auc:0.84433
[372]	validation_0-auc:0.91112	validation_1-auc:0.84426
[373]	validation_0-auc:0.91125	validation_1-auc:0.84426
[374]	validation_0-auc:0.91138	validation_1-auc:0.84424
[375]	validation_0-auc:0.91141	validation_1-auc:0.84422
[376]	validation_0-auc:0.91145	validation_1-auc:0.84418
[377]	validation_0-auc:0.91156	validation_1-auc:0.84416
[378]	validation_0-auc:0.91166	validation_1-auc:0.84420
[379]	validation_0-auc:0.91170	validation_1-auc:0.84417
[380]	validation_0-auc:0.91181	validation_1-auc:0.84414
[381]	validation_0-auc:0.91184	validation_1-auc:0.84416
[382]	validation_0-auc:0.91188	validation_1-auc:0.84414
[383]	validation_0-auc:0.91200	validation_1-auc:0.84408
[384]	validation_0-auc:0.91207	validation_1-auc:0.84407
[385]	validation_0-auc:0.91218	validation_1-auc:0.84403
[386]	validation_0-auc:0.91221	validation_1-auc:0.84401
[387]	validation_0-auc:0.91223	validation_1-auc:0.84400
[388]	validation_0-auc:0.91229	validation_1-auc:0.84398
[389]	validation_0-auc:0.91233	validation_1-auc:0.84402
[390]	validation_0-auc:0.91236	validation_1-auc:0.84405
[391]	validation_0-auc:0.91239	validation_1-auc:0.84404
[392]	validation_0-auc:0.91243	validation_1-auc:0.84404
[393]	validation_0-auc:0.91246	validation_1-auc:0.84405
[394]	validation_0-auc:0.91250	validation_1-auc:0.84404
[395]	validation_0-auc:0.91250	validation_1-auc:0.84402
[396]	validation_0-auc:0.91257	validation_1-auc:0.84401
[397]	validation_0-auc:0.91260	validation_1-auc:0.84400
[398]	validation_0-auc:0.91261	validation_1-auc:0.84399
[399]	validation_0-auc:0.91269	validation_1-auc:0.84398
[400]	validation_0-auc:0.91269	validation_1-auc:0.84398
[401]	validation_0-auc:0.91273	validation_1-auc:0.84396
[402]	validation_0-auc:0.91276	validation_1-auc:0.84394
[403]	validation_0-auc:0.91276	validation_1-auc:0.84396
[404]	validation_0-auc:0.91280	validation_1-auc:0.84394
[405]	validation_0-auc:0.91289	validation_1-auc:0.84396
[406]	validation_0-auc:0.91290	validation_1-auc:0.84396
[407]	validation_0-auc:0.91292	validation_1-auc:0.84395
[408]	validation_0-auc:0.91293	validation_1-auc:0.84396
[409]	validation_0-auc:0.91295	validation_1-auc:0.84395
[410]	validation_0-auc:0.91296	validation_1-auc:0.84398
ROC AUC: 0.8460
</pre>
- ROC-AUC가 0.8460으로 이전보다 성능이 더 향상됨



```python
### 피처 중요도 시각화

from xgboost import plot_importance
import matplotlib.pyplot as plt
%matplotlib inline

fig, ax = plt.subplots(1, 1, figsize = (10,8))
plot_importance(xgb_clf, ax = ax , max_num_features = 20, height = 0.4)
```

<pre>
<Axes: title={'center': 'Feature importance'}, xlabel='F score', ylabel='Features'>
</pre>
<img src="data:image/png;base64,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"/>

## **2-2. LightGBM**


### **a) 기본 모델 생성/학습/예측**



```python
from lightgbm import LGBMClassifier

### 모델 객체 생성
lgbm_clf = LGBMClassifier(n_estimators = 500)

evals = [(X_test, y_test)]

### 학습
lgbm_clf.fit(X_train, y_train, early_stopping_rounds = 100, 
             eval_metric = "auc", eval_set = evals, verbose = True)

### 평가
lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:,1],average = 'macro')
print('ROC AUC: {0:.4f}'.format(lgbm_roc_score))
```

<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.
  _log_warning("'verbose' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.817384	valid_0's binary_logloss: 0.165046
[2]	valid_0's auc: 0.818903	valid_0's binary_logloss: 0.160006
[3]	valid_0's auc: 0.827707	valid_0's binary_logloss: 0.156323
[4]	valid_0's auc: 0.832155	valid_0's binary_logloss: 0.153463
[5]	valid_0's auc: 0.834677	valid_0's binary_logloss: 0.151256
[6]	valid_0's auc: 0.834093	valid_0's binary_logloss: 0.149427
[7]	valid_0's auc: 0.837046	valid_0's binary_logloss: 0.147961
[8]	valid_0's auc: 0.837838	valid_0's binary_logloss: 0.146591
[9]	valid_0's auc: 0.839435	valid_0's binary_logloss: 0.145455
[10]	valid_0's auc: 0.83973	valid_0's binary_logloss: 0.144486
[11]	valid_0's auc: 0.839799	valid_0's binary_logloss: 0.143769
[12]	valid_0's auc: 0.840034	valid_0's binary_logloss: 0.143146
[13]	valid_0's auc: 0.840271	valid_0's binary_logloss: 0.142533
[14]	valid_0's auc: 0.840342	valid_0's binary_logloss: 0.142036
[15]	valid_0's auc: 0.840928	valid_0's binary_logloss: 0.14161
[16]	valid_0's auc: 0.840337	valid_0's binary_logloss: 0.141307
[17]	valid_0's auc: 0.839901	valid_0's binary_logloss: 0.141152
[18]	valid_0's auc: 0.839742	valid_0's binary_logloss: 0.141018
[19]	valid_0's auc: 0.839818	valid_0's binary_logloss: 0.14068
[20]	valid_0's auc: 0.839307	valid_0's binary_logloss: 0.140562
[21]	valid_0's auc: 0.839662	valid_0's binary_logloss: 0.140353
[22]	valid_0's auc: 0.840411	valid_0's binary_logloss: 0.140144
[23]	valid_0's auc: 0.840522	valid_0's binary_logloss: 0.139983
[24]	valid_0's auc: 0.840208	valid_0's binary_logloss: 0.139943
[25]	valid_0's auc: 0.839578	valid_0's binary_logloss: 0.139898
[26]	valid_0's auc: 0.83975	valid_0's binary_logloss: 0.139814
[27]	valid_0's auc: 0.83988	valid_0's binary_logloss: 0.139711
[28]	valid_0's auc: 0.839704	valid_0's binary_logloss: 0.139681
[29]	valid_0's auc: 0.839432	valid_0's binary_logloss: 0.139662
[30]	valid_0's auc: 0.839196	valid_0's binary_logloss: 0.139641
[31]	valid_0's auc: 0.838891	valid_0's binary_logloss: 0.139654
[32]	valid_0's auc: 0.838943	valid_0's binary_logloss: 0.1396
[33]	valid_0's auc: 0.838632	valid_0's binary_logloss: 0.139642
[34]	valid_0's auc: 0.838314	valid_0's binary_logloss: 0.139687
[35]	valid_0's auc: 0.83844	valid_0's binary_logloss: 0.139668
[36]	valid_0's auc: 0.839074	valid_0's binary_logloss: 0.139562
[37]	valid_0's auc: 0.838806	valid_0's binary_logloss: 0.139594
[38]	valid_0's auc: 0.839041	valid_0's binary_logloss: 0.139574
[39]	valid_0's auc: 0.839081	valid_0's binary_logloss: 0.139587
[40]	valid_0's auc: 0.839276	valid_0's binary_logloss: 0.139504
[41]	valid_0's auc: 0.83951	valid_0's binary_logloss: 0.139481
[42]	valid_0's auc: 0.839544	valid_0's binary_logloss: 0.139487
[43]	valid_0's auc: 0.839673	valid_0's binary_logloss: 0.139478
[44]	valid_0's auc: 0.839677	valid_0's binary_logloss: 0.139453
[45]	valid_0's auc: 0.839703	valid_0's binary_logloss: 0.139445
[46]	valid_0's auc: 0.839601	valid_0's binary_logloss: 0.139468
[47]	valid_0's auc: 0.839318	valid_0's binary_logloss: 0.139529
[48]	valid_0's auc: 0.839462	valid_0's binary_logloss: 0.139486
[49]	valid_0's auc: 0.839288	valid_0's binary_logloss: 0.139492
[50]	valid_0's auc: 0.838987	valid_0's binary_logloss: 0.139572
[51]	valid_0's auc: 0.838845	valid_0's binary_logloss: 0.139603
[52]	valid_0's auc: 0.838655	valid_0's binary_logloss: 0.139623
[53]	valid_0's auc: 0.838783	valid_0's binary_logloss: 0.139609
[54]	valid_0's auc: 0.838695	valid_0's binary_logloss: 0.139638
[55]	valid_0's auc: 0.838868	valid_0's binary_logloss: 0.139625
[56]	valid_0's auc: 0.838653	valid_0's binary_logloss: 0.139645
[57]	valid_0's auc: 0.83856	valid_0's binary_logloss: 0.139688
[58]	valid_0's auc: 0.838475	valid_0's binary_logloss: 0.139694
[59]	valid_0's auc: 0.8384	valid_0's binary_logloss: 0.139682
[60]	valid_0's auc: 0.838319	valid_0's binary_logloss: 0.13969
[61]	valid_0's auc: 0.838209	valid_0's binary_logloss: 0.13973
[62]	valid_0's auc: 0.83806	valid_0's binary_logloss: 0.139765
[63]	valid_0's auc: 0.838096	valid_0's binary_logloss: 0.139749
[64]	valid_0's auc: 0.838163	valid_0's binary_logloss: 0.139746
[65]	valid_0's auc: 0.838183	valid_0's binary_logloss: 0.139805
[66]	valid_0's auc: 0.838215	valid_0's binary_logloss: 0.139815
[67]	valid_0's auc: 0.838268	valid_0's binary_logloss: 0.139822
[68]	valid_0's auc: 0.83836	valid_0's binary_logloss: 0.139816
[69]	valid_0's auc: 0.838114	valid_0's binary_logloss: 0.139874
[70]	valid_0's auc: 0.83832	valid_0's binary_logloss: 0.139816
[71]	valid_0's auc: 0.838256	valid_0's binary_logloss: 0.139818
[72]	valid_0's auc: 0.838231	valid_0's binary_logloss: 0.139845
[73]	valid_0's auc: 0.838028	valid_0's binary_logloss: 0.139888
[74]	valid_0's auc: 0.837912	valid_0's binary_logloss: 0.139905
[75]	valid_0's auc: 0.83772	valid_0's binary_logloss: 0.13992
[76]	valid_0's auc: 0.837606	valid_0's binary_logloss: 0.139899
[77]	valid_0's auc: 0.837521	valid_0's binary_logloss: 0.139925
[78]	valid_0's auc: 0.837462	valid_0's binary_logloss: 0.139957
[79]	valid_0's auc: 0.837541	valid_0's binary_logloss: 0.139944
[80]	valid_0's auc: 0.838013	valid_0's binary_logloss: 0.13983
[81]	valid_0's auc: 0.83789	valid_0's binary_logloss: 0.139874
[82]	valid_0's auc: 0.837671	valid_0's binary_logloss: 0.139975
[83]	valid_0's auc: 0.837707	valid_0's binary_logloss: 0.139972
[84]	valid_0's auc: 0.837631	valid_0's binary_logloss: 0.140011
[85]	valid_0's auc: 0.837496	valid_0's binary_logloss: 0.140023
[86]	valid_0's auc: 0.83757	valid_0's binary_logloss: 0.140021
[87]	valid_0's auc: 0.837284	valid_0's binary_logloss: 0.140099
[88]	valid_0's auc: 0.837228	valid_0's binary_logloss: 0.140115
[89]	valid_0's auc: 0.836964	valid_0's binary_logloss: 0.140172
[90]	valid_0's auc: 0.836752	valid_0's binary_logloss: 0.140225
[91]	valid_0's auc: 0.836833	valid_0's binary_logloss: 0.140221
[92]	valid_0's auc: 0.836648	valid_0's binary_logloss: 0.140277
[93]	valid_0's auc: 0.836648	valid_0's binary_logloss: 0.140315
[94]	valid_0's auc: 0.836677	valid_0's binary_logloss: 0.140321
[95]	valid_0's auc: 0.836729	valid_0's binary_logloss: 0.140307
[96]	valid_0's auc: 0.8368	valid_0's binary_logloss: 0.140313
[97]	valid_0's auc: 0.836797	valid_0's binary_logloss: 0.140331
[98]	valid_0's auc: 0.836675	valid_0's binary_logloss: 0.140361
[99]	valid_0's auc: 0.83655	valid_0's binary_logloss: 0.14039
[100]	valid_0's auc: 0.836518	valid_0's binary_logloss: 0.1404
[101]	valid_0's auc: 0.836998	valid_0's binary_logloss: 0.140294
[102]	valid_0's auc: 0.836778	valid_0's binary_logloss: 0.140366
[103]	valid_0's auc: 0.83694	valid_0's binary_logloss: 0.140333
[104]	valid_0's auc: 0.836749	valid_0's binary_logloss: 0.14039
[105]	valid_0's auc: 0.836752	valid_0's binary_logloss: 0.140391
[106]	valid_0's auc: 0.837197	valid_0's binary_logloss: 0.140305
[107]	valid_0's auc: 0.837141	valid_0's binary_logloss: 0.140329
[108]	valid_0's auc: 0.8371	valid_0's binary_logloss: 0.140344
[109]	valid_0's auc: 0.837136	valid_0's binary_logloss: 0.14033
[110]	valid_0's auc: 0.837102	valid_0's binary_logloss: 0.140388
[111]	valid_0's auc: 0.836957	valid_0's binary_logloss: 0.140426
[112]	valid_0's auc: 0.836779	valid_0's binary_logloss: 0.14051
[113]	valid_0's auc: 0.836831	valid_0's binary_logloss: 0.140526
[114]	valid_0's auc: 0.836783	valid_0's binary_logloss: 0.14055
[115]	valid_0's auc: 0.836672	valid_0's binary_logloss: 0.140585
ROC AUC: 0.8409
</pre>
- ROC AUC: 0.8409

- LightGBM이 XGBoost에 비해 학습에 걸리는 시간이 좀 더 단축됨


### **b) Hyper Parameter Tuning**

- GridSearchCV 활용

- 튜닝 대상: ```num_leaves```, ```max_depth```, ```min_child_samples```, ```subsample```



```python
from sklearn.model_selection import GridSearchCV

# 하이퍼 파라미터 테스트의 수행 속도를 향상시키기 위해 n_estimators를 200으로 감소
lgbm_clf = LGBMClassifier(n_estimators = 200)

# tuning 할 파라미터 목록
params = {'num_leaves': [32, 64 ],
          'max_depth':[128, 160],
          'min_child_samples':[60, 100],
          'subsample':[0.8, 1]}

gridcv = GridSearchCV(lgbm_clf, param_grid = params, cv = 3)
gridcv.fit(X_train, y_train, early_stopping_rounds = 30, 
           eval_metric = "auc", eval_set = [(X_train, y_train), (X_test, y_test)])

print('GridSearchCV 최적 파라미터:', gridcv.best_params_)
lgbm_roc_score = roc_auc_score(y_test, gridcv.predict_proba(X_test)[:,1], average = 'macro')
print('ROC AUC: {0:.4f}'.format(lgbm_roc_score))
```

<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.820235	valid_0's binary_logloss: 0.156085	valid_1's auc: 0.81613	valid_1's binary_logloss: 0.164992
[2]	valid_0's auc: 0.825778	valid_0's binary_logloss: 0.150951	valid_1's auc: 0.821835	valid_1's binary_logloss: 0.159874
[3]	valid_0's auc: 0.832262	valid_0's binary_logloss: 0.147158	valid_1's auc: 0.826533	valid_1's binary_logloss: 0.156346
[4]	valid_0's auc: 0.83865	valid_0's binary_logloss: 0.144126	valid_1's auc: 0.833166	valid_1's binary_logloss: 0.1534
[5]	valid_0's auc: 0.842822	valid_0's binary_logloss: 0.141725	valid_1's auc: 0.836448	valid_1's binary_logloss: 0.151167
[6]	valid_0's auc: 0.844702	valid_0's binary_logloss: 0.139642	valid_1's auc: 0.837094	valid_1's binary_logloss: 0.149356
[7]	valid_0's auc: 0.847144	valid_0's binary_logloss: 0.13794	valid_1's auc: 0.837965	valid_1's binary_logloss: 0.147853
[8]	valid_0's auc: 0.848277	valid_0's binary_logloss: 0.136499	valid_1's auc: 0.837663	valid_1's binary_logloss: 0.146543
[9]	valid_0's auc: 0.849328	valid_0's binary_logloss: 0.135326	valid_1's auc: 0.837413	valid_1's binary_logloss: 0.145528
[10]	valid_0's auc: 0.851112	valid_0's binary_logloss: 0.134188	valid_1's auc: 0.836954	valid_1's binary_logloss: 0.14466
[11]	valid_0's auc: 0.852613	valid_0's binary_logloss: 0.133257	valid_1's auc: 0.837393	valid_1's binary_logloss: 0.143843
[12]	valid_0's auc: 0.854906	valid_0's binary_logloss: 0.132346	valid_1's auc: 0.837459	valid_1's binary_logloss: 0.143285
[13]	valid_0's auc: 0.855656	valid_0's binary_logloss: 0.131601	valid_1's auc: 0.837612	valid_1's binary_logloss: 0.142732
[14]	valid_0's auc: 0.857076	valid_0's binary_logloss: 0.130884	valid_1's auc: 0.837055	valid_1's binary_logloss: 0.142403
[15]	valid_0's auc: 0.857961	valid_0's binary_logloss: 0.130252	valid_1's auc: 0.837198	valid_1's binary_logloss: 0.142031
[16]	valid_0's auc: 0.860191	valid_0's binary_logloss: 0.129596	valid_1's auc: 0.836016	valid_1's binary_logloss: 0.141822
[17]	valid_0's auc: 0.860941	valid_0's binary_logloss: 0.129064	valid_1's auc: 0.836076	valid_1's binary_logloss: 0.141551
[18]	valid_0's auc: 0.862201	valid_0's binary_logloss: 0.128565	valid_1's auc: 0.835929	valid_1's binary_logloss: 0.141326
[19]	valid_0's auc: 0.863581	valid_0's binary_logloss: 0.128105	valid_1's auc: 0.835256	valid_1's binary_logloss: 0.141243
[20]	valid_0's auc: 0.864799	valid_0's binary_logloss: 0.127654	valid_1's auc: 0.83435	valid_1's binary_logloss: 0.141148
[21]	valid_0's auc: 0.866472	valid_0's binary_logloss: 0.127165	valid_1's auc: 0.834176	valid_1's binary_logloss: 0.141041
[22]	valid_0's auc: 0.867055	valid_0's binary_logloss: 0.126777	valid_1's auc: 0.834173	valid_1's binary_logloss: 0.140887
[23]	valid_0's auc: 0.867726	valid_0's binary_logloss: 0.12643	valid_1's auc: 0.833577	valid_1's binary_logloss: 0.140909
[24]	valid_0's auc: 0.868612	valid_0's binary_logloss: 0.126061	valid_1's auc: 0.833336	valid_1's binary_logloss: 0.140824
[25]	valid_0's auc: 0.869224	valid_0's binary_logloss: 0.125753	valid_1's auc: 0.833428	valid_1's binary_logloss: 0.140793
[26]	valid_0's auc: 0.870183	valid_0's binary_logloss: 0.125414	valid_1's auc: 0.83333	valid_1's binary_logloss: 0.140724
[27]	valid_0's auc: 0.870926	valid_0's binary_logloss: 0.125123	valid_1's auc: 0.832503	valid_1's binary_logloss: 0.140772
[28]	valid_0's auc: 0.872431	valid_0's binary_logloss: 0.124766	valid_1's auc: 0.832826	valid_1's binary_logloss: 0.140685
[29]	valid_0's auc: 0.873397	valid_0's binary_logloss: 0.124495	valid_1's auc: 0.833175	valid_1's binary_logloss: 0.140604
[30]	valid_0's auc: 0.87475	valid_0's binary_logloss: 0.12417	valid_1's auc: 0.833614	valid_1's binary_logloss: 0.140497
[31]	valid_0's auc: 0.875407	valid_0's binary_logloss: 0.12389	valid_1's auc: 0.833706	valid_1's binary_logloss: 0.140428
[32]	valid_0's auc: 0.876136	valid_0's binary_logloss: 0.123637	valid_1's auc: 0.833458	valid_1's binary_logloss: 0.140448
[33]	valid_0's auc: 0.876575	valid_0's binary_logloss: 0.123421	valid_1's auc: 0.832965	valid_1's binary_logloss: 0.140498
[34]	valid_0's auc: 0.877224	valid_0's binary_logloss: 0.123219	valid_1's auc: 0.832659	valid_1's binary_logloss: 0.140537
[35]	valid_0's auc: 0.877898	valid_0's binary_logloss: 0.122947	valid_1's auc: 0.832787	valid_1's binary_logloss: 0.140536
[36]	valid_0's auc: 0.878334	valid_0's binary_logloss: 0.122724	valid_1's auc: 0.832724	valid_1's binary_logloss: 0.14053
[37]	valid_0's auc: 0.878762	valid_0's binary_logloss: 0.122514	valid_1's auc: 0.832581	valid_1's binary_logloss: 0.140533
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.814371	valid_0's binary_logloss: 0.156452	valid_1's auc: 0.813175	valid_1's binary_logloss: 0.165418
[2]	valid_0's auc: 0.827277	valid_0's binary_logloss: 0.151084	valid_1's auc: 0.819635	valid_1's binary_logloss: 0.160159
[3]	valid_0's auc: 0.837033	valid_0's binary_logloss: 0.14722	valid_1's auc: 0.828221	valid_1's binary_logloss: 0.156492
[4]	valid_0's auc: 0.840167	valid_0's binary_logloss: 0.14423	valid_1's auc: 0.830942	valid_1's binary_logloss: 0.153586
[5]	valid_0's auc: 0.842499	valid_0's binary_logloss: 0.141721	valid_1's auc: 0.833301	valid_1's binary_logloss: 0.151219
[6]	valid_0's auc: 0.845403	valid_0's binary_logloss: 0.139708	valid_1's auc: 0.836412	valid_1's binary_logloss: 0.149312
[7]	valid_0's auc: 0.848049	valid_0's binary_logloss: 0.138024	valid_1's auc: 0.836054	valid_1's binary_logloss: 0.14779
[8]	valid_0's auc: 0.849694	valid_0's binary_logloss: 0.136542	valid_1's auc: 0.837537	valid_1's binary_logloss: 0.146417
[9]	valid_0's auc: 0.851646	valid_0's binary_logloss: 0.135289	valid_1's auc: 0.838418	valid_1's binary_logloss: 0.145329
[10]	valid_0's auc: 0.853642	valid_0's binary_logloss: 0.134189	valid_1's auc: 0.839342	valid_1's binary_logloss: 0.144374
[11]	valid_0's auc: 0.855647	valid_0's binary_logloss: 0.133227	valid_1's auc: 0.840035	valid_1's binary_logloss: 0.143552
[12]	valid_0's auc: 0.856768	valid_0's binary_logloss: 0.132399	valid_1's auc: 0.839294	valid_1's binary_logloss: 0.143047
[13]	valid_0's auc: 0.85763	valid_0's binary_logloss: 0.13165	valid_1's auc: 0.838911	valid_1's binary_logloss: 0.142469
[14]	valid_0's auc: 0.859243	valid_0's binary_logloss: 0.130936	valid_1's auc: 0.838705	valid_1's binary_logloss: 0.141913
[15]	valid_0's auc: 0.860124	valid_0's binary_logloss: 0.130312	valid_1's auc: 0.838608	valid_1's binary_logloss: 0.141547
[16]	valid_0's auc: 0.861358	valid_0's binary_logloss: 0.129687	valid_1's auc: 0.838422	valid_1's binary_logloss: 0.141134
[17]	valid_0's auc: 0.862159	valid_0's binary_logloss: 0.129139	valid_1's auc: 0.838636	valid_1's binary_logloss: 0.140786
[18]	valid_0's auc: 0.862729	valid_0's binary_logloss: 0.128664	valid_1's auc: 0.838342	valid_1's binary_logloss: 0.140538
[19]	valid_0's auc: 0.863842	valid_0's binary_logloss: 0.128137	valid_1's auc: 0.838464	valid_1's binary_logloss: 0.140331
[20]	valid_0's auc: 0.864859	valid_0's binary_logloss: 0.127657	valid_1's auc: 0.837832	valid_1's binary_logloss: 0.140179
[21]	valid_0's auc: 0.866227	valid_0's binary_logloss: 0.127137	valid_1's auc: 0.837735	valid_1's binary_logloss: 0.140043
[22]	valid_0's auc: 0.866925	valid_0's binary_logloss: 0.126772	valid_1's auc: 0.838268	valid_1's binary_logloss: 0.139927
[23]	valid_0's auc: 0.867727	valid_0's binary_logloss: 0.126369	valid_1's auc: 0.838482	valid_1's binary_logloss: 0.139787
[24]	valid_0's auc: 0.868239	valid_0's binary_logloss: 0.126013	valid_1's auc: 0.838767	valid_1's binary_logloss: 0.13964
[25]	valid_0's auc: 0.869304	valid_0's binary_logloss: 0.125622	valid_1's auc: 0.838562	valid_1's binary_logloss: 0.139648
[26]	valid_0's auc: 0.870347	valid_0's binary_logloss: 0.125288	valid_1's auc: 0.838228	valid_1's binary_logloss: 0.139618
[27]	valid_0's auc: 0.871198	valid_0's binary_logloss: 0.124953	valid_1's auc: 0.838403	valid_1's binary_logloss: 0.139594
[28]	valid_0's auc: 0.872024	valid_0's binary_logloss: 0.124672	valid_1's auc: 0.838405	valid_1's binary_logloss: 0.139526
[29]	valid_0's auc: 0.873184	valid_0's binary_logloss: 0.124303	valid_1's auc: 0.838211	valid_1's binary_logloss: 0.139531
[30]	valid_0's auc: 0.874076	valid_0's binary_logloss: 0.12403	valid_1's auc: 0.838983	valid_1's binary_logloss: 0.139411
[31]	valid_0's auc: 0.874768	valid_0's binary_logloss: 0.123745	valid_1's auc: 0.839314	valid_1's binary_logloss: 0.139314
[32]	valid_0's auc: 0.875593	valid_0's binary_logloss: 0.123486	valid_1's auc: 0.838875	valid_1's binary_logloss: 0.139322
[33]	valid_0's auc: 0.8767	valid_0's binary_logloss: 0.123182	valid_1's auc: 0.838809	valid_1's binary_logloss: 0.139329
[34]	valid_0's auc: 0.87774	valid_0's binary_logloss: 0.122892	valid_1's auc: 0.838376	valid_1's binary_logloss: 0.139342
[35]	valid_0's auc: 0.878372	valid_0's binary_logloss: 0.122634	valid_1's auc: 0.838454	valid_1's binary_logloss: 0.13931
[36]	valid_0's auc: 0.879098	valid_0's binary_logloss: 0.122414	valid_1's auc: 0.838895	valid_1's binary_logloss: 0.13925
[37]	valid_0's auc: 0.879502	valid_0's binary_logloss: 0.122216	valid_1's auc: 0.838441	valid_1's binary_logloss: 0.139302
[38]	valid_0's auc: 0.880036	valid_0's binary_logloss: 0.121998	valid_1's auc: 0.838582	valid_1's binary_logloss: 0.139306
[39]	valid_0's auc: 0.880641	valid_0's binary_logloss: 0.121716	valid_1's auc: 0.838787	valid_1's binary_logloss: 0.139269
[40]	valid_0's auc: 0.881249	valid_0's binary_logloss: 0.121482	valid_1's auc: 0.838906	valid_1's binary_logloss: 0.139223
[41]	valid_0's auc: 0.881919	valid_0's binary_logloss: 0.121223	valid_1's auc: 0.838567	valid_1's binary_logloss: 0.13926
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.821645	valid_0's binary_logloss: 0.156528	valid_1's auc: 0.81857	valid_1's binary_logloss: 0.165101
[2]	valid_0's auc: 0.827488	valid_0's binary_logloss: 0.151189	valid_1's auc: 0.822299	valid_1's binary_logloss: 0.160072
[3]	valid_0's auc: 0.837855	valid_0's binary_logloss: 0.147263	valid_1's auc: 0.829855	valid_1's binary_logloss: 0.156527
[4]	valid_0's auc: 0.840063	valid_0's binary_logloss: 0.144261	valid_1's auc: 0.833088	valid_1's binary_logloss: 0.153446
[5]	valid_0's auc: 0.842802	valid_0's binary_logloss: 0.141691	valid_1's auc: 0.834541	valid_1's binary_logloss: 0.151144
[6]	valid_0's auc: 0.844	valid_0's binary_logloss: 0.139654	valid_1's auc: 0.834542	valid_1's binary_logloss: 0.149333
[7]	valid_0's auc: 0.845838	valid_0's binary_logloss: 0.138002	valid_1's auc: 0.835645	valid_1's binary_logloss: 0.147676
[8]	valid_0's auc: 0.846869	valid_0's binary_logloss: 0.136628	valid_1's auc: 0.836118	valid_1's binary_logloss: 0.146491
[9]	valid_0's auc: 0.849282	valid_0's binary_logloss: 0.135382	valid_1's auc: 0.837542	valid_1's binary_logloss: 0.14539
[10]	valid_0's auc: 0.851021	valid_0's binary_logloss: 0.134282	valid_1's auc: 0.836942	valid_1's binary_logloss: 0.144584
[11]	valid_0's auc: 0.852037	valid_0's binary_logloss: 0.133358	valid_1's auc: 0.8374	valid_1's binary_logloss: 0.143836
[12]	valid_0's auc: 0.854496	valid_0's binary_logloss: 0.132505	valid_1's auc: 0.838593	valid_1's binary_logloss: 0.143171
[13]	valid_0's auc: 0.857514	valid_0's binary_logloss: 0.131695	valid_1's auc: 0.838558	valid_1's binary_logloss: 0.142646
[14]	valid_0's auc: 0.858827	valid_0's binary_logloss: 0.131006	valid_1's auc: 0.838498	valid_1's binary_logloss: 0.142158
[15]	valid_0's auc: 0.860574	valid_0's binary_logloss: 0.130352	valid_1's auc: 0.837435	valid_1's binary_logloss: 0.141868
[16]	valid_0's auc: 0.861239	valid_0's binary_logloss: 0.129765	valid_1's auc: 0.837374	valid_1's binary_logloss: 0.141537
[17]	valid_0's auc: 0.86217	valid_0's binary_logloss: 0.129164	valid_1's auc: 0.837703	valid_1's binary_logloss: 0.141192
[18]	valid_0's auc: 0.863228	valid_0's binary_logloss: 0.128615	valid_1's auc: 0.837526	valid_1's binary_logloss: 0.140917
[19]	valid_0's auc: 0.86473	valid_0's binary_logloss: 0.128113	valid_1's auc: 0.838235	valid_1's binary_logloss: 0.140572
[20]	valid_0's auc: 0.865797	valid_0's binary_logloss: 0.127679	valid_1's auc: 0.838788	valid_1's binary_logloss: 0.140332
[21]	valid_0's auc: 0.866561	valid_0's binary_logloss: 0.127235	valid_1's auc: 0.839171	valid_1's binary_logloss: 0.140108
[22]	valid_0's auc: 0.867237	valid_0's binary_logloss: 0.12688	valid_1's auc: 0.839213	valid_1's binary_logloss: 0.13991
[23]	valid_0's auc: 0.867894	valid_0's binary_logloss: 0.126519	valid_1's auc: 0.839641	valid_1's binary_logloss: 0.139745
[24]	valid_0's auc: 0.868501	valid_0's binary_logloss: 0.126192	valid_1's auc: 0.840025	valid_1's binary_logloss: 0.139593
[25]	valid_0's auc: 0.869311	valid_0's binary_logloss: 0.125838	valid_1's auc: 0.839961	valid_1's binary_logloss: 0.139531
[26]	valid_0's auc: 0.870325	valid_0's binary_logloss: 0.125518	valid_1's auc: 0.839261	valid_1's binary_logloss: 0.139524
[27]	valid_0's auc: 0.871488	valid_0's binary_logloss: 0.125147	valid_1's auc: 0.839671	valid_1's binary_logloss: 0.139365
[28]	valid_0's auc: 0.87235	valid_0's binary_logloss: 0.12484	valid_1's auc: 0.840114	valid_1's binary_logloss: 0.139236
[29]	valid_0's auc: 0.872991	valid_0's binary_logloss: 0.124593	valid_1's auc: 0.839491	valid_1's binary_logloss: 0.139271
[30]	valid_0's auc: 0.874129	valid_0's binary_logloss: 0.124312	valid_1's auc: 0.839589	valid_1's binary_logloss: 0.13918
[31]	valid_0's auc: 0.875305	valid_0's binary_logloss: 0.123988	valid_1's auc: 0.839441	valid_1's binary_logloss: 0.139184
[32]	valid_0's auc: 0.875943	valid_0's binary_logloss: 0.123748	valid_1's auc: 0.839268	valid_1's binary_logloss: 0.13919
[33]	valid_0's auc: 0.876575	valid_0's binary_logloss: 0.123484	valid_1's auc: 0.839549	valid_1's binary_logloss: 0.139075
[34]	valid_0's auc: 0.877426	valid_0's binary_logloss: 0.123156	valid_1's auc: 0.839087	valid_1's binary_logloss: 0.139148
[35]	valid_0's auc: 0.87822	valid_0's binary_logloss: 0.122873	valid_1's auc: 0.8389	valid_1's binary_logloss: 0.139187
[36]	valid_0's auc: 0.878932	valid_0's binary_logloss: 0.12259	valid_1's auc: 0.838921	valid_1's binary_logloss: 0.139194
[37]	valid_0's auc: 0.879842	valid_0's binary_logloss: 0.12233	valid_1's auc: 0.839133	valid_1's binary_logloss: 0.139161
[38]	valid_0's auc: 0.880497	valid_0's binary_logloss: 0.12208	valid_1's auc: 0.838975	valid_1's binary_logloss: 0.139143
[39]	valid_0's auc: 0.881056	valid_0's binary_logloss: 0.121827	valid_1's auc: 0.839037	valid_1's binary_logloss: 0.139138
[40]	valid_0's auc: 0.881604	valid_0's binary_logloss: 0.121603	valid_1's auc: 0.839204	valid_1's binary_logloss: 0.139119
[41]	valid_0's auc: 0.882159	valid_0's binary_logloss: 0.121355	valid_1's auc: 0.839277	valid_1's binary_logloss: 0.139091
[42]	valid_0's auc: 0.882757	valid_0's binary_logloss: 0.121116	valid_1's auc: 0.838964	valid_1's binary_logloss: 0.139133
[43]	valid_0's auc: 0.883143	valid_0's binary_logloss: 0.120918	valid_1's auc: 0.839024	valid_1's binary_logloss: 0.139124
[44]	valid_0's auc: 0.883697	valid_0's binary_logloss: 0.12072	valid_1's auc: 0.838652	valid_1's binary_logloss: 0.139203
[45]	valid_0's auc: 0.884292	valid_0's binary_logloss: 0.120482	valid_1's auc: 0.839016	valid_1's binary_logloss: 0.139124
[46]	valid_0's auc: 0.884969	valid_0's binary_logloss: 0.120266	valid_1's auc: 0.838683	valid_1's binary_logloss: 0.139184
[47]	valid_0's auc: 0.8853	valid_0's binary_logloss: 0.120089	valid_1's auc: 0.838624	valid_1's binary_logloss: 0.139193
[48]	valid_0's auc: 0.885876	valid_0's binary_logloss: 0.11993	valid_1's auc: 0.838569	valid_1's binary_logloss: 0.139212
[49]	valid_0's auc: 0.886141	valid_0's binary_logloss: 0.119757	valid_1's auc: 0.838345	valid_1's binary_logloss: 0.139288
[50]	valid_0's auc: 0.886433	valid_0's binary_logloss: 0.119595	valid_1's auc: 0.838342	valid_1's binary_logloss: 0.139332
[51]	valid_0's auc: 0.886975	valid_0's binary_logloss: 0.119377	valid_1's auc: 0.838335	valid_1's binary_logloss: 0.139331
[52]	valid_0's auc: 0.887568	valid_0's binary_logloss: 0.119161	valid_1's auc: 0.838204	valid_1's binary_logloss: 0.139331
[53]	valid_0's auc: 0.887867	valid_0's binary_logloss: 0.118974	valid_1's auc: 0.838044	valid_1's binary_logloss: 0.13936
[54]	valid_0's auc: 0.888093	valid_0's binary_logloss: 0.118834	valid_1's auc: 0.838137	valid_1's binary_logloss: 0.13935
[55]	valid_0's auc: 0.888289	valid_0's binary_logloss: 0.118675	valid_1's auc: 0.837878	valid_1's binary_logloss: 0.139392
[56]	valid_0's auc: 0.888615	valid_0's binary_logloss: 0.118561	valid_1's auc: 0.837776	valid_1's binary_logloss: 0.139418
[57]	valid_0's auc: 0.889157	valid_0's binary_logloss: 0.118369	valid_1's auc: 0.837585	valid_1's binary_logloss: 0.139447
[58]	valid_0's auc: 0.889659	valid_0's binary_logloss: 0.11819	valid_1's auc: 0.837789	valid_1's binary_logloss: 0.139431
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.820235	valid_0's binary_logloss: 0.156085	valid_1's auc: 0.81613	valid_1's binary_logloss: 0.164992
[2]	valid_0's auc: 0.825778	valid_0's binary_logloss: 0.150951	valid_1's auc: 0.821835	valid_1's binary_logloss: 0.159874
[3]	valid_0's auc: 0.832262	valid_0's binary_logloss: 0.147158	valid_1's auc: 0.826533	valid_1's binary_logloss: 0.156346
[4]	valid_0's auc: 0.83865	valid_0's binary_logloss: 0.144126	valid_1's auc: 0.833166	valid_1's binary_logloss: 0.1534
[5]	valid_0's auc: 0.842822	valid_0's binary_logloss: 0.141725	valid_1's auc: 0.836448	valid_1's binary_logloss: 0.151167
[6]	valid_0's auc: 0.844702	valid_0's binary_logloss: 0.139642	valid_1's auc: 0.837094	valid_1's binary_logloss: 0.149356
[7]	valid_0's auc: 0.847144	valid_0's binary_logloss: 0.13794	valid_1's auc: 0.837965	valid_1's binary_logloss: 0.147853
[8]	valid_0's auc: 0.848277	valid_0's binary_logloss: 0.136499	valid_1's auc: 0.837663	valid_1's binary_logloss: 0.146543
[9]	valid_0's auc: 0.849328	valid_0's binary_logloss: 0.135326	valid_1's auc: 0.837413	valid_1's binary_logloss: 0.145528
[10]	valid_0's auc: 0.851112	valid_0's binary_logloss: 0.134188	valid_1's auc: 0.836954	valid_1's binary_logloss: 0.14466
[11]	valid_0's auc: 0.852613	valid_0's binary_logloss: 0.133257	valid_1's auc: 0.837393	valid_1's binary_logloss: 0.143843
[12]	valid_0's auc: 0.854906	valid_0's binary_logloss: 0.132346	valid_1's auc: 0.837459	valid_1's binary_logloss: 0.143285
[13]	valid_0's auc: 0.855656	valid_0's binary_logloss: 0.131601	valid_1's auc: 0.837612	valid_1's binary_logloss: 0.142732
[14]	valid_0's auc: 0.857076	valid_0's binary_logloss: 0.130884	valid_1's auc: 0.837055	valid_1's binary_logloss: 0.142403
[15]	valid_0's auc: 0.857961	valid_0's binary_logloss: 0.130252	valid_1's auc: 0.837198	valid_1's binary_logloss: 0.142031
[16]	valid_0's auc: 0.860191	valid_0's binary_logloss: 0.129596	valid_1's auc: 0.836016	valid_1's binary_logloss: 0.141822
[17]	valid_0's auc: 0.860941	valid_0's binary_logloss: 0.129064	valid_1's auc: 0.836076	valid_1's binary_logloss: 0.141551
[18]	valid_0's auc: 0.862201	valid_0's binary_logloss: 0.128565	valid_1's auc: 0.835929	valid_1's binary_logloss: 0.141326
[19]	valid_0's auc: 0.863581	valid_0's binary_logloss: 0.128105	valid_1's auc: 0.835256	valid_1's binary_logloss: 0.141243
[20]	valid_0's auc: 0.864799	valid_0's binary_logloss: 0.127654	valid_1's auc: 0.83435	valid_1's binary_logloss: 0.141148
[21]	valid_0's auc: 0.866472	valid_0's binary_logloss: 0.127165	valid_1's auc: 0.834176	valid_1's binary_logloss: 0.141041
[22]	valid_0's auc: 0.867055	valid_0's binary_logloss: 0.126777	valid_1's auc: 0.834173	valid_1's binary_logloss: 0.140887
[23]	valid_0's auc: 0.867726	valid_0's binary_logloss: 0.12643	valid_1's auc: 0.833577	valid_1's binary_logloss: 0.140909
[24]	valid_0's auc: 0.868612	valid_0's binary_logloss: 0.126061	valid_1's auc: 0.833336	valid_1's binary_logloss: 0.140824
[25]	valid_0's auc: 0.869224	valid_0's binary_logloss: 0.125753	valid_1's auc: 0.833428	valid_1's binary_logloss: 0.140793
[26]	valid_0's auc: 0.870183	valid_0's binary_logloss: 0.125414	valid_1's auc: 0.83333	valid_1's binary_logloss: 0.140724
[27]	valid_0's auc: 0.870926	valid_0's binary_logloss: 0.125123	valid_1's auc: 0.832503	valid_1's binary_logloss: 0.140772
[28]	valid_0's auc: 0.872431	valid_0's binary_logloss: 0.124766	valid_1's auc: 0.832826	valid_1's binary_logloss: 0.140685
[29]	valid_0's auc: 0.873397	valid_0's binary_logloss: 0.124495	valid_1's auc: 0.833175	valid_1's binary_logloss: 0.140604
[30]	valid_0's auc: 0.87475	valid_0's binary_logloss: 0.12417	valid_1's auc: 0.833614	valid_1's binary_logloss: 0.140497
[31]	valid_0's auc: 0.875407	valid_0's binary_logloss: 0.12389	valid_1's auc: 0.833706	valid_1's binary_logloss: 0.140428
[32]	valid_0's auc: 0.876136	valid_0's binary_logloss: 0.123637	valid_1's auc: 0.833458	valid_1's binary_logloss: 0.140448
[33]	valid_0's auc: 0.876575	valid_0's binary_logloss: 0.123421	valid_1's auc: 0.832965	valid_1's binary_logloss: 0.140498
[34]	valid_0's auc: 0.877224	valid_0's binary_logloss: 0.123219	valid_1's auc: 0.832659	valid_1's binary_logloss: 0.140537
[35]	valid_0's auc: 0.877898	valid_0's binary_logloss: 0.122947	valid_1's auc: 0.832787	valid_1's binary_logloss: 0.140536
[36]	valid_0's auc: 0.878334	valid_0's binary_logloss: 0.122724	valid_1's auc: 0.832724	valid_1's binary_logloss: 0.14053
[37]	valid_0's auc: 0.878762	valid_0's binary_logloss: 0.122514	valid_1's auc: 0.832581	valid_1's binary_logloss: 0.140533
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.814371	valid_0's binary_logloss: 0.156452	valid_1's auc: 0.813175	valid_1's binary_logloss: 0.165418
[2]	valid_0's auc: 0.827277	valid_0's binary_logloss: 0.151084	valid_1's auc: 0.819635	valid_1's binary_logloss: 0.160159
[3]	valid_0's auc: 0.837033	valid_0's binary_logloss: 0.14722	valid_1's auc: 0.828221	valid_1's binary_logloss: 0.156492
[4]	valid_0's auc: 0.840167	valid_0's binary_logloss: 0.14423	valid_1's auc: 0.830942	valid_1's binary_logloss: 0.153586
[5]	valid_0's auc: 0.842499	valid_0's binary_logloss: 0.141721	valid_1's auc: 0.833301	valid_1's binary_logloss: 0.151219
[6]	valid_0's auc: 0.845403	valid_0's binary_logloss: 0.139708	valid_1's auc: 0.836412	valid_1's binary_logloss: 0.149312
[7]	valid_0's auc: 0.848049	valid_0's binary_logloss: 0.138024	valid_1's auc: 0.836054	valid_1's binary_logloss: 0.14779
[8]	valid_0's auc: 0.849694	valid_0's binary_logloss: 0.136542	valid_1's auc: 0.837537	valid_1's binary_logloss: 0.146417
[9]	valid_0's auc: 0.851646	valid_0's binary_logloss: 0.135289	valid_1's auc: 0.838418	valid_1's binary_logloss: 0.145329
[10]	valid_0's auc: 0.853642	valid_0's binary_logloss: 0.134189	valid_1's auc: 0.839342	valid_1's binary_logloss: 0.144374
[11]	valid_0's auc: 0.855647	valid_0's binary_logloss: 0.133227	valid_1's auc: 0.840035	valid_1's binary_logloss: 0.143552
[12]	valid_0's auc: 0.856768	valid_0's binary_logloss: 0.132399	valid_1's auc: 0.839294	valid_1's binary_logloss: 0.143047
[13]	valid_0's auc: 0.85763	valid_0's binary_logloss: 0.13165	valid_1's auc: 0.838911	valid_1's binary_logloss: 0.142469
[14]	valid_0's auc: 0.859243	valid_0's binary_logloss: 0.130936	valid_1's auc: 0.838705	valid_1's binary_logloss: 0.141913
[15]	valid_0's auc: 0.860124	valid_0's binary_logloss: 0.130312	valid_1's auc: 0.838608	valid_1's binary_logloss: 0.141547
[16]	valid_0's auc: 0.861358	valid_0's binary_logloss: 0.129687	valid_1's auc: 0.838422	valid_1's binary_logloss: 0.141134
[17]	valid_0's auc: 0.862159	valid_0's binary_logloss: 0.129139	valid_1's auc: 0.838636	valid_1's binary_logloss: 0.140786
[18]	valid_0's auc: 0.862729	valid_0's binary_logloss: 0.128664	valid_1's auc: 0.838342	valid_1's binary_logloss: 0.140538
[19]	valid_0's auc: 0.863842	valid_0's binary_logloss: 0.128137	valid_1's auc: 0.838464	valid_1's binary_logloss: 0.140331
[20]	valid_0's auc: 0.864859	valid_0's binary_logloss: 0.127657	valid_1's auc: 0.837832	valid_1's binary_logloss: 0.140179
[21]	valid_0's auc: 0.866227	valid_0's binary_logloss: 0.127137	valid_1's auc: 0.837735	valid_1's binary_logloss: 0.140043
[22]	valid_0's auc: 0.866925	valid_0's binary_logloss: 0.126772	valid_1's auc: 0.838268	valid_1's binary_logloss: 0.139927
[23]	valid_0's auc: 0.867727	valid_0's binary_logloss: 0.126369	valid_1's auc: 0.838482	valid_1's binary_logloss: 0.139787
[24]	valid_0's auc: 0.868239	valid_0's binary_logloss: 0.126013	valid_1's auc: 0.838767	valid_1's binary_logloss: 0.13964
[25]	valid_0's auc: 0.869304	valid_0's binary_logloss: 0.125622	valid_1's auc: 0.838562	valid_1's binary_logloss: 0.139648
[26]	valid_0's auc: 0.870347	valid_0's binary_logloss: 0.125288	valid_1's auc: 0.838228	valid_1's binary_logloss: 0.139618
[27]	valid_0's auc: 0.871198	valid_0's binary_logloss: 0.124953	valid_1's auc: 0.838403	valid_1's binary_logloss: 0.139594
[28]	valid_0's auc: 0.872024	valid_0's binary_logloss: 0.124672	valid_1's auc: 0.838405	valid_1's binary_logloss: 0.139526
[29]	valid_0's auc: 0.873184	valid_0's binary_logloss: 0.124303	valid_1's auc: 0.838211	valid_1's binary_logloss: 0.139531
[30]	valid_0's auc: 0.874076	valid_0's binary_logloss: 0.12403	valid_1's auc: 0.838983	valid_1's binary_logloss: 0.139411
[31]	valid_0's auc: 0.874768	valid_0's binary_logloss: 0.123745	valid_1's auc: 0.839314	valid_1's binary_logloss: 0.139314
[32]	valid_0's auc: 0.875593	valid_0's binary_logloss: 0.123486	valid_1's auc: 0.838875	valid_1's binary_logloss: 0.139322
[33]	valid_0's auc: 0.8767	valid_0's binary_logloss: 0.123182	valid_1's auc: 0.838809	valid_1's binary_logloss: 0.139329
[34]	valid_0's auc: 0.87774	valid_0's binary_logloss: 0.122892	valid_1's auc: 0.838376	valid_1's binary_logloss: 0.139342
[35]	valid_0's auc: 0.878372	valid_0's binary_logloss: 0.122634	valid_1's auc: 0.838454	valid_1's binary_logloss: 0.13931
[36]	valid_0's auc: 0.879098	valid_0's binary_logloss: 0.122414	valid_1's auc: 0.838895	valid_1's binary_logloss: 0.13925
[37]	valid_0's auc: 0.879502	valid_0's binary_logloss: 0.122216	valid_1's auc: 0.838441	valid_1's binary_logloss: 0.139302
[38]	valid_0's auc: 0.880036	valid_0's binary_logloss: 0.121998	valid_1's auc: 0.838582	valid_1's binary_logloss: 0.139306
[39]	valid_0's auc: 0.880641	valid_0's binary_logloss: 0.121716	valid_1's auc: 0.838787	valid_1's binary_logloss: 0.139269
[40]	valid_0's auc: 0.881249	valid_0's binary_logloss: 0.121482	valid_1's auc: 0.838906	valid_1's binary_logloss: 0.139223
[41]	valid_0's auc: 0.881919	valid_0's binary_logloss: 0.121223	valid_1's auc: 0.838567	valid_1's binary_logloss: 0.13926
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.821645	valid_0's binary_logloss: 0.156528	valid_1's auc: 0.81857	valid_1's binary_logloss: 0.165101
[2]	valid_0's auc: 0.827488	valid_0's binary_logloss: 0.151189	valid_1's auc: 0.822299	valid_1's binary_logloss: 0.160072
[3]	valid_0's auc: 0.837855	valid_0's binary_logloss: 0.147263	valid_1's auc: 0.829855	valid_1's binary_logloss: 0.156527
[4]	valid_0's auc: 0.840063	valid_0's binary_logloss: 0.144261	valid_1's auc: 0.833088	valid_1's binary_logloss: 0.153446
[5]	valid_0's auc: 0.842802	valid_0's binary_logloss: 0.141691	valid_1's auc: 0.834541	valid_1's binary_logloss: 0.151144
[6]	valid_0's auc: 0.844	valid_0's binary_logloss: 0.139654	valid_1's auc: 0.834542	valid_1's binary_logloss: 0.149333
[7]	valid_0's auc: 0.845838	valid_0's binary_logloss: 0.138002	valid_1's auc: 0.835645	valid_1's binary_logloss: 0.147676
[8]	valid_0's auc: 0.846869	valid_0's binary_logloss: 0.136628	valid_1's auc: 0.836118	valid_1's binary_logloss: 0.146491
[9]	valid_0's auc: 0.849282	valid_0's binary_logloss: 0.135382	valid_1's auc: 0.837542	valid_1's binary_logloss: 0.14539
[10]	valid_0's auc: 0.851021	valid_0's binary_logloss: 0.134282	valid_1's auc: 0.836942	valid_1's binary_logloss: 0.144584
[11]	valid_0's auc: 0.852037	valid_0's binary_logloss: 0.133358	valid_1's auc: 0.8374	valid_1's binary_logloss: 0.143836
[12]	valid_0's auc: 0.854496	valid_0's binary_logloss: 0.132505	valid_1's auc: 0.838593	valid_1's binary_logloss: 0.143171
[13]	valid_0's auc: 0.857514	valid_0's binary_logloss: 0.131695	valid_1's auc: 0.838558	valid_1's binary_logloss: 0.142646
[14]	valid_0's auc: 0.858827	valid_0's binary_logloss: 0.131006	valid_1's auc: 0.838498	valid_1's binary_logloss: 0.142158
[15]	valid_0's auc: 0.860574	valid_0's binary_logloss: 0.130352	valid_1's auc: 0.837435	valid_1's binary_logloss: 0.141868
[16]	valid_0's auc: 0.861239	valid_0's binary_logloss: 0.129765	valid_1's auc: 0.837374	valid_1's binary_logloss: 0.141537
[17]	valid_0's auc: 0.86217	valid_0's binary_logloss: 0.129164	valid_1's auc: 0.837703	valid_1's binary_logloss: 0.141192
[18]	valid_0's auc: 0.863228	valid_0's binary_logloss: 0.128615	valid_1's auc: 0.837526	valid_1's binary_logloss: 0.140917
[19]	valid_0's auc: 0.86473	valid_0's binary_logloss: 0.128113	valid_1's auc: 0.838235	valid_1's binary_logloss: 0.140572
[20]	valid_0's auc: 0.865797	valid_0's binary_logloss: 0.127679	valid_1's auc: 0.838788	valid_1's binary_logloss: 0.140332
[21]	valid_0's auc: 0.866561	valid_0's binary_logloss: 0.127235	valid_1's auc: 0.839171	valid_1's binary_logloss: 0.140108
[22]	valid_0's auc: 0.867237	valid_0's binary_logloss: 0.12688	valid_1's auc: 0.839213	valid_1's binary_logloss: 0.13991
[23]	valid_0's auc: 0.867894	valid_0's binary_logloss: 0.126519	valid_1's auc: 0.839641	valid_1's binary_logloss: 0.139745
[24]	valid_0's auc: 0.868501	valid_0's binary_logloss: 0.126192	valid_1's auc: 0.840025	valid_1's binary_logloss: 0.139593
[25]	valid_0's auc: 0.869311	valid_0's binary_logloss: 0.125838	valid_1's auc: 0.839961	valid_1's binary_logloss: 0.139531
[26]	valid_0's auc: 0.870325	valid_0's binary_logloss: 0.125518	valid_1's auc: 0.839261	valid_1's binary_logloss: 0.139524
[27]	valid_0's auc: 0.871488	valid_0's binary_logloss: 0.125147	valid_1's auc: 0.839671	valid_1's binary_logloss: 0.139365
[28]	valid_0's auc: 0.87235	valid_0's binary_logloss: 0.12484	valid_1's auc: 0.840114	valid_1's binary_logloss: 0.139236
[29]	valid_0's auc: 0.872991	valid_0's binary_logloss: 0.124593	valid_1's auc: 0.839491	valid_1's binary_logloss: 0.139271
[30]	valid_0's auc: 0.874129	valid_0's binary_logloss: 0.124312	valid_1's auc: 0.839589	valid_1's binary_logloss: 0.13918
[31]	valid_0's auc: 0.875305	valid_0's binary_logloss: 0.123988	valid_1's auc: 0.839441	valid_1's binary_logloss: 0.139184
[32]	valid_0's auc: 0.875943	valid_0's binary_logloss: 0.123748	valid_1's auc: 0.839268	valid_1's binary_logloss: 0.13919
[33]	valid_0's auc: 0.876575	valid_0's binary_logloss: 0.123484	valid_1's auc: 0.839549	valid_1's binary_logloss: 0.139075
[34]	valid_0's auc: 0.877426	valid_0's binary_logloss: 0.123156	valid_1's auc: 0.839087	valid_1's binary_logloss: 0.139148
[35]	valid_0's auc: 0.87822	valid_0's binary_logloss: 0.122873	valid_1's auc: 0.8389	valid_1's binary_logloss: 0.139187
[36]	valid_0's auc: 0.878932	valid_0's binary_logloss: 0.12259	valid_1's auc: 0.838921	valid_1's binary_logloss: 0.139194
[37]	valid_0's auc: 0.879842	valid_0's binary_logloss: 0.12233	valid_1's auc: 0.839133	valid_1's binary_logloss: 0.139161
[38]	valid_0's auc: 0.880497	valid_0's binary_logloss: 0.12208	valid_1's auc: 0.838975	valid_1's binary_logloss: 0.139143
[39]	valid_0's auc: 0.881056	valid_0's binary_logloss: 0.121827	valid_1's auc: 0.839037	valid_1's binary_logloss: 0.139138
[40]	valid_0's auc: 0.881604	valid_0's binary_logloss: 0.121603	valid_1's auc: 0.839204	valid_1's binary_logloss: 0.139119
[41]	valid_0's auc: 0.882159	valid_0's binary_logloss: 0.121355	valid_1's auc: 0.839277	valid_1's binary_logloss: 0.139091
[42]	valid_0's auc: 0.882757	valid_0's binary_logloss: 0.121116	valid_1's auc: 0.838964	valid_1's binary_logloss: 0.139133
[43]	valid_0's auc: 0.883143	valid_0's binary_logloss: 0.120918	valid_1's auc: 0.839024	valid_1's binary_logloss: 0.139124
[44]	valid_0's auc: 0.883697	valid_0's binary_logloss: 0.12072	valid_1's auc: 0.838652	valid_1's binary_logloss: 0.139203
[45]	valid_0's auc: 0.884292	valid_0's binary_logloss: 0.120482	valid_1's auc: 0.839016	valid_1's binary_logloss: 0.139124
[46]	valid_0's auc: 0.884969	valid_0's binary_logloss: 0.120266	valid_1's auc: 0.838683	valid_1's binary_logloss: 0.139184
[47]	valid_0's auc: 0.8853	valid_0's binary_logloss: 0.120089	valid_1's auc: 0.838624	valid_1's binary_logloss: 0.139193
[48]	valid_0's auc: 0.885876	valid_0's binary_logloss: 0.11993	valid_1's auc: 0.838569	valid_1's binary_logloss: 0.139212
[49]	valid_0's auc: 0.886141	valid_0's binary_logloss: 0.119757	valid_1's auc: 0.838345	valid_1's binary_logloss: 0.139288
[50]	valid_0's auc: 0.886433	valid_0's binary_logloss: 0.119595	valid_1's auc: 0.838342	valid_1's binary_logloss: 0.139332
[51]	valid_0's auc: 0.886975	valid_0's binary_logloss: 0.119377	valid_1's auc: 0.838335	valid_1's binary_logloss: 0.139331
[52]	valid_0's auc: 0.887568	valid_0's binary_logloss: 0.119161	valid_1's auc: 0.838204	valid_1's binary_logloss: 0.139331
[53]	valid_0's auc: 0.887867	valid_0's binary_logloss: 0.118974	valid_1's auc: 0.838044	valid_1's binary_logloss: 0.13936
[54]	valid_0's auc: 0.888093	valid_0's binary_logloss: 0.118834	valid_1's auc: 0.838137	valid_1's binary_logloss: 0.13935
[55]	valid_0's auc: 0.888289	valid_0's binary_logloss: 0.118675	valid_1's auc: 0.837878	valid_1's binary_logloss: 0.139392
[56]	valid_0's auc: 0.888615	valid_0's binary_logloss: 0.118561	valid_1's auc: 0.837776	valid_1's binary_logloss: 0.139418
[57]	valid_0's auc: 0.889157	valid_0's binary_logloss: 0.118369	valid_1's auc: 0.837585	valid_1's binary_logloss: 0.139447
[58]	valid_0's auc: 0.889659	valid_0's binary_logloss: 0.11819	valid_1's auc: 0.837789	valid_1's binary_logloss: 0.139431
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.832891	valid_0's binary_logloss: 0.155302	valid_1's auc: 0.818851	valid_1's binary_logloss: 0.164826
[2]	valid_0's auc: 0.84519	valid_0's binary_logloss: 0.149727	valid_1's auc: 0.827144	valid_1's binary_logloss: 0.159879
[3]	valid_0's auc: 0.848018	valid_0's binary_logloss: 0.145627	valid_1's auc: 0.826851	valid_1's binary_logloss: 0.15631
[4]	valid_0's auc: 0.851096	valid_0's binary_logloss: 0.142423	valid_1's auc: 0.83073	valid_1's binary_logloss: 0.1534
[5]	valid_0's auc: 0.854735	valid_0's binary_logloss: 0.139746	valid_1's auc: 0.832753	valid_1's binary_logloss: 0.151136
[6]	valid_0's auc: 0.856928	valid_0's binary_logloss: 0.137509	valid_1's auc: 0.835605	valid_1's binary_logloss: 0.14924
[7]	valid_0's auc: 0.859448	valid_0's binary_logloss: 0.135575	valid_1's auc: 0.835612	valid_1's binary_logloss: 0.147799
[8]	valid_0's auc: 0.861685	valid_0's binary_logloss: 0.133953	valid_1's auc: 0.834408	valid_1's binary_logloss: 0.146634
[9]	valid_0's auc: 0.863391	valid_0's binary_logloss: 0.132468	valid_1's auc: 0.835623	valid_1's binary_logloss: 0.145549
[10]	valid_0's auc: 0.865858	valid_0's binary_logloss: 0.131185	valid_1's auc: 0.83487	valid_1's binary_logloss: 0.144745
[11]	valid_0's auc: 0.867134	valid_0's binary_logloss: 0.130116	valid_1's auc: 0.834692	valid_1's binary_logloss: 0.14411
[12]	valid_0's auc: 0.868217	valid_0's binary_logloss: 0.129097	valid_1's auc: 0.834746	valid_1's binary_logloss: 0.143527
[13]	valid_0's auc: 0.87073	valid_0's binary_logloss: 0.128129	valid_1's auc: 0.833582	valid_1's binary_logloss: 0.143122
[14]	valid_0's auc: 0.872621	valid_0's binary_logloss: 0.12721	valid_1's auc: 0.833205	valid_1's binary_logloss: 0.142745
[15]	valid_0's auc: 0.874007	valid_0's binary_logloss: 0.126363	valid_1's auc: 0.83246	valid_1's binary_logloss: 0.142489
[16]	valid_0's auc: 0.875141	valid_0's binary_logloss: 0.125606	valid_1's auc: 0.831958	valid_1's binary_logloss: 0.142275
[17]	valid_0's auc: 0.876061	valid_0's binary_logloss: 0.124928	valid_1's auc: 0.831586	valid_1's binary_logloss: 0.142141
[18]	valid_0's auc: 0.876982	valid_0's binary_logloss: 0.124313	valid_1's auc: 0.830954	valid_1's binary_logloss: 0.142066
[19]	valid_0's auc: 0.877885	valid_0's binary_logloss: 0.123709	valid_1's auc: 0.830572	valid_1's binary_logloss: 0.14196
[20]	valid_0's auc: 0.879378	valid_0's binary_logloss: 0.123088	valid_1's auc: 0.830076	valid_1's binary_logloss: 0.14196
[21]	valid_0's auc: 0.880647	valid_0's binary_logloss: 0.122488	valid_1's auc: 0.830109	valid_1's binary_logloss: 0.141858
[22]	valid_0's auc: 0.881614	valid_0's binary_logloss: 0.121973	valid_1's auc: 0.829735	valid_1's binary_logloss: 0.141822
[23]	valid_0's auc: 0.882402	valid_0's binary_logloss: 0.121554	valid_1's auc: 0.829254	valid_1's binary_logloss: 0.141805
[24]	valid_0's auc: 0.883011	valid_0's binary_logloss: 0.121078	valid_1's auc: 0.829054	valid_1's binary_logloss: 0.14178
[25]	valid_0's auc: 0.884627	valid_0's binary_logloss: 0.120587	valid_1's auc: 0.82942	valid_1's binary_logloss: 0.141653
[26]	valid_0's auc: 0.885304	valid_0's binary_logloss: 0.120169	valid_1's auc: 0.828716	valid_1's binary_logloss: 0.141755
[27]	valid_0's auc: 0.88664	valid_0's binary_logloss: 0.119673	valid_1's auc: 0.828869	valid_1's binary_logloss: 0.141682
[28]	valid_0's auc: 0.887143	valid_0's binary_logloss: 0.119308	valid_1's auc: 0.828987	valid_1's binary_logloss: 0.141649
[29]	valid_0's auc: 0.88825	valid_0's binary_logloss: 0.1189	valid_1's auc: 0.829075	valid_1's binary_logloss: 0.141601
[30]	valid_0's auc: 0.889081	valid_0's binary_logloss: 0.118531	valid_1's auc: 0.828871	valid_1's binary_logloss: 0.141605
[31]	valid_0's auc: 0.890195	valid_0's binary_logloss: 0.118117	valid_1's auc: 0.828972	valid_1's binary_logloss: 0.141605
[32]	valid_0's auc: 0.890928	valid_0's binary_logloss: 0.117735	valid_1's auc: 0.827969	valid_1's binary_logloss: 0.141796
[33]	valid_0's auc: 0.891505	valid_0's binary_logloss: 0.117389	valid_1's auc: 0.827611	valid_1's binary_logloss: 0.141916
[34]	valid_0's auc: 0.892223	valid_0's binary_logloss: 0.11707	valid_1's auc: 0.827019	valid_1's binary_logloss: 0.142051
[35]	valid_0's auc: 0.892825	valid_0's binary_logloss: 0.116751	valid_1's auc: 0.826865	valid_1's binary_logloss: 0.142116
[36]	valid_0's auc: 0.893984	valid_0's binary_logloss: 0.116353	valid_1's auc: 0.827203	valid_1's binary_logloss: 0.14207
[37]	valid_0's auc: 0.89456	valid_0's binary_logloss: 0.11603	valid_1's auc: 0.827292	valid_1's binary_logloss: 0.142005
[38]	valid_0's auc: 0.89511	valid_0's binary_logloss: 0.115713	valid_1's auc: 0.827214	valid_1's binary_logloss: 0.14206
[39]	valid_0's auc: 0.895738	valid_0's binary_logloss: 0.115415	valid_1's auc: 0.82695	valid_1's binary_logloss: 0.142162
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.833054	valid_0's binary_logloss: 0.15572	valid_1's auc: 0.817048	valid_1's binary_logloss: 0.165036
[2]	valid_0's auc: 0.841397	valid_0's binary_logloss: 0.149862	valid_1's auc: 0.82157	valid_1's binary_logloss: 0.159575
[3]	valid_0's auc: 0.849058	valid_0's binary_logloss: 0.145662	valid_1's auc: 0.829866	valid_1's binary_logloss: 0.155774
[4]	valid_0's auc: 0.854301	valid_0's binary_logloss: 0.142356	valid_1's auc: 0.832415	valid_1's binary_logloss: 0.152936
[5]	valid_0's auc: 0.858045	valid_0's binary_logloss: 0.139697	valid_1's auc: 0.834554	valid_1's binary_logloss: 0.150635
[6]	valid_0's auc: 0.860767	valid_0's binary_logloss: 0.137458	valid_1's auc: 0.834885	valid_1's binary_logloss: 0.148761
[7]	valid_0's auc: 0.863011	valid_0's binary_logloss: 0.135522	valid_1's auc: 0.835812	valid_1's binary_logloss: 0.147245
[8]	valid_0's auc: 0.864923	valid_0's binary_logloss: 0.133792	valid_1's auc: 0.836656	valid_1's binary_logloss: 0.145923
[9]	valid_0's auc: 0.865706	valid_0's binary_logloss: 0.13236	valid_1's auc: 0.836912	valid_1's binary_logloss: 0.144867
[10]	valid_0's auc: 0.867693	valid_0's binary_logloss: 0.131066	valid_1's auc: 0.837266	valid_1's binary_logloss: 0.143895
[11]	valid_0's auc: 0.868596	valid_0's binary_logloss: 0.129937	valid_1's auc: 0.836466	valid_1's binary_logloss: 0.143255
[12]	valid_0's auc: 0.87012	valid_0's binary_logloss: 0.128904	valid_1's auc: 0.836589	valid_1's binary_logloss: 0.142728
[13]	valid_0's auc: 0.871703	valid_0's binary_logloss: 0.127913	valid_1's auc: 0.836567	valid_1's binary_logloss: 0.142105
[14]	valid_0's auc: 0.873468	valid_0's binary_logloss: 0.126983	valid_1's auc: 0.835538	valid_1's binary_logloss: 0.141771
[15]	valid_0's auc: 0.874839	valid_0's binary_logloss: 0.126147	valid_1's auc: 0.835363	valid_1's binary_logloss: 0.141464
[16]	valid_0's auc: 0.876399	valid_0's binary_logloss: 0.125331	valid_1's auc: 0.83478	valid_1's binary_logloss: 0.141245
[17]	valid_0's auc: 0.877465	valid_0's binary_logloss: 0.124655	valid_1's auc: 0.834621	valid_1's binary_logloss: 0.141028
[18]	valid_0's auc: 0.878935	valid_0's binary_logloss: 0.123944	valid_1's auc: 0.834165	valid_1's binary_logloss: 0.140935
[19]	valid_0's auc: 0.88046	valid_0's binary_logloss: 0.123313	valid_1's auc: 0.834629	valid_1's binary_logloss: 0.140738
[20]	valid_0's auc: 0.881517	valid_0's binary_logloss: 0.12269	valid_1's auc: 0.8347	valid_1's binary_logloss: 0.140611
[21]	valid_0's auc: 0.882464	valid_0's binary_logloss: 0.122095	valid_1's auc: 0.834656	valid_1's binary_logloss: 0.140487
[22]	valid_0's auc: 0.883744	valid_0's binary_logloss: 0.121504	valid_1's auc: 0.834562	valid_1's binary_logloss: 0.140328
[23]	valid_0's auc: 0.885301	valid_0's binary_logloss: 0.12091	valid_1's auc: 0.835278	valid_1's binary_logloss: 0.140199
[24]	valid_0's auc: 0.886266	valid_0's binary_logloss: 0.120437	valid_1's auc: 0.835728	valid_1's binary_logloss: 0.140094
[25]	valid_0's auc: 0.88755	valid_0's binary_logloss: 0.119931	valid_1's auc: 0.836199	valid_1's binary_logloss: 0.140076
[26]	valid_0's auc: 0.888525	valid_0's binary_logloss: 0.119473	valid_1's auc: 0.836708	valid_1's binary_logloss: 0.139945
[27]	valid_0's auc: 0.889589	valid_0's binary_logloss: 0.119012	valid_1's auc: 0.836951	valid_1's binary_logloss: 0.139843
[28]	valid_0's auc: 0.890552	valid_0's binary_logloss: 0.118602	valid_1's auc: 0.836524	valid_1's binary_logloss: 0.139871
[29]	valid_0's auc: 0.891402	valid_0's binary_logloss: 0.118166	valid_1's auc: 0.836264	valid_1's binary_logloss: 0.139884
[30]	valid_0's auc: 0.891982	valid_0's binary_logloss: 0.117805	valid_1's auc: 0.835959	valid_1's binary_logloss: 0.139937
[31]	valid_0's auc: 0.893185	valid_0's binary_logloss: 0.117392	valid_1's auc: 0.836384	valid_1's binary_logloss: 0.13992
[32]	valid_0's auc: 0.894065	valid_0's binary_logloss: 0.117017	valid_1's auc: 0.836341	valid_1's binary_logloss: 0.139888
[33]	valid_0's auc: 0.894791	valid_0's binary_logloss: 0.116671	valid_1's auc: 0.836753	valid_1's binary_logloss: 0.139812
[34]	valid_0's auc: 0.895313	valid_0's binary_logloss: 0.116321	valid_1's auc: 0.836733	valid_1's binary_logloss: 0.139826
[35]	valid_0's auc: 0.895876	valid_0's binary_logloss: 0.116039	valid_1's auc: 0.836245	valid_1's binary_logloss: 0.139883
[36]	valid_0's auc: 0.896909	valid_0's binary_logloss: 0.115684	valid_1's auc: 0.836079	valid_1's binary_logloss: 0.139912
[37]	valid_0's auc: 0.897427	valid_0's binary_logloss: 0.115388	valid_1's auc: 0.835564	valid_1's binary_logloss: 0.140024
[38]	valid_0's auc: 0.898442	valid_0's binary_logloss: 0.115006	valid_1's auc: 0.835612	valid_1's binary_logloss: 0.140075
[39]	valid_0's auc: 0.899304	valid_0's binary_logloss: 0.114592	valid_1's auc: 0.836273	valid_1's binary_logloss: 0.139974
[40]	valid_0's auc: 0.89974	valid_0's binary_logloss: 0.11432	valid_1's auc: 0.836096	valid_1's binary_logloss: 0.140042
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.830643	valid_0's binary_logloss: 0.155759	valid_1's auc: 0.816734	valid_1's binary_logloss: 0.164985
[2]	valid_0's auc: 0.839353	valid_0's binary_logloss: 0.149977	valid_1's auc: 0.822571	valid_1's binary_logloss: 0.159808
[3]	valid_0's auc: 0.847366	valid_0's binary_logloss: 0.145866	valid_1's auc: 0.829312	valid_1's binary_logloss: 0.156171
[4]	valid_0's auc: 0.850911	valid_0's binary_logloss: 0.14247	valid_1's auc: 0.830848	valid_1's binary_logloss: 0.153328
[5]	valid_0's auc: 0.854674	valid_0's binary_logloss: 0.139764	valid_1's auc: 0.833041	valid_1's binary_logloss: 0.151023
[6]	valid_0's auc: 0.856722	valid_0's binary_logloss: 0.1375	valid_1's auc: 0.834264	valid_1's binary_logloss: 0.149166
[7]	valid_0's auc: 0.858253	valid_0's binary_logloss: 0.135713	valid_1's auc: 0.834998	valid_1's binary_logloss: 0.147631
[8]	valid_0's auc: 0.859768	valid_0's binary_logloss: 0.134063	valid_1's auc: 0.835678	valid_1's binary_logloss: 0.146384
[9]	valid_0's auc: 0.86262	valid_0's binary_logloss: 0.132622	valid_1's auc: 0.836272	valid_1's binary_logloss: 0.145313
[10]	valid_0's auc: 0.864631	valid_0's binary_logloss: 0.131324	valid_1's auc: 0.835827	valid_1's binary_logloss: 0.144553
[11]	valid_0's auc: 0.866805	valid_0's binary_logloss: 0.130172	valid_1's auc: 0.835375	valid_1's binary_logloss: 0.143933
[12]	valid_0's auc: 0.868266	valid_0's binary_logloss: 0.129101	valid_1's auc: 0.835951	valid_1's binary_logloss: 0.143342
[13]	valid_0's auc: 0.870762	valid_0's binary_logloss: 0.128144	valid_1's auc: 0.83626	valid_1's binary_logloss: 0.142813
[14]	valid_0's auc: 0.872747	valid_0's binary_logloss: 0.127222	valid_1's auc: 0.835864	valid_1's binary_logloss: 0.142466
[15]	valid_0's auc: 0.874158	valid_0's binary_logloss: 0.126428	valid_1's auc: 0.83548	valid_1's binary_logloss: 0.142108
[16]	valid_0's auc: 0.875931	valid_0's binary_logloss: 0.125651	valid_1's auc: 0.836367	valid_1's binary_logloss: 0.141684
[17]	valid_0's auc: 0.876854	valid_0's binary_logloss: 0.124918	valid_1's auc: 0.835689	valid_1's binary_logloss: 0.141524
[18]	valid_0's auc: 0.878211	valid_0's binary_logloss: 0.124197	valid_1's auc: 0.835893	valid_1's binary_logloss: 0.141285
[19]	valid_0's auc: 0.879125	valid_0's binary_logloss: 0.123553	valid_1's auc: 0.835877	valid_1's binary_logloss: 0.141128
[20]	valid_0's auc: 0.880489	valid_0's binary_logloss: 0.122856	valid_1's auc: 0.835385	valid_1's binary_logloss: 0.141032
[21]	valid_0's auc: 0.881696	valid_0's binary_logloss: 0.122219	valid_1's auc: 0.835822	valid_1's binary_logloss: 0.140843
[22]	valid_0's auc: 0.882257	valid_0's binary_logloss: 0.121726	valid_1's auc: 0.835849	valid_1's binary_logloss: 0.140761
[23]	valid_0's auc: 0.883635	valid_0's binary_logloss: 0.121206	valid_1's auc: 0.836223	valid_1's binary_logloss: 0.140607
[24]	valid_0's auc: 0.884533	valid_0's binary_logloss: 0.120734	valid_1's auc: 0.836473	valid_1's binary_logloss: 0.14049
[25]	valid_0's auc: 0.885234	valid_0's binary_logloss: 0.120268	valid_1's auc: 0.836722	valid_1's binary_logloss: 0.140403
[26]	valid_0's auc: 0.886292	valid_0's binary_logloss: 0.119794	valid_1's auc: 0.836549	valid_1's binary_logloss: 0.140423
[27]	valid_0's auc: 0.887064	valid_0's binary_logloss: 0.119366	valid_1's auc: 0.836155	valid_1's binary_logloss: 0.140447
[28]	valid_0's auc: 0.887621	valid_0's binary_logloss: 0.119008	valid_1's auc: 0.835594	valid_1's binary_logloss: 0.140532
[29]	valid_0's auc: 0.888965	valid_0's binary_logloss: 0.118547	valid_1's auc: 0.835464	valid_1's binary_logloss: 0.140508
[30]	valid_0's auc: 0.889898	valid_0's binary_logloss: 0.118139	valid_1's auc: 0.83577	valid_1's binary_logloss: 0.140461
[31]	valid_0's auc: 0.890896	valid_0's binary_logloss: 0.117734	valid_1's auc: 0.835475	valid_1's binary_logloss: 0.140463
[32]	valid_0's auc: 0.892374	valid_0's binary_logloss: 0.1173	valid_1's auc: 0.835364	valid_1's binary_logloss: 0.140506
[33]	valid_0's auc: 0.893164	valid_0's binary_logloss: 0.116978	valid_1's auc: 0.835865	valid_1's binary_logloss: 0.14041
[34]	valid_0's auc: 0.893848	valid_0's binary_logloss: 0.11662	valid_1's auc: 0.836021	valid_1's binary_logloss: 0.140353
[35]	valid_0's auc: 0.894232	valid_0's binary_logloss: 0.116323	valid_1's auc: 0.8359	valid_1's binary_logloss: 0.140396
[36]	valid_0's auc: 0.895003	valid_0's binary_logloss: 0.115986	valid_1's auc: 0.835855	valid_1's binary_logloss: 0.140416
[37]	valid_0's auc: 0.895898	valid_0's binary_logloss: 0.115609	valid_1's auc: 0.836185	valid_1's binary_logloss: 0.140369
[38]	valid_0's auc: 0.896459	valid_0's binary_logloss: 0.11527	valid_1's auc: 0.835754	valid_1's binary_logloss: 0.140443
[39]	valid_0's auc: 0.897377	valid_0's binary_logloss: 0.114873	valid_1's auc: 0.835638	valid_1's binary_logloss: 0.140474
[40]	valid_0's auc: 0.89776	valid_0's binary_logloss: 0.114588	valid_1's auc: 0.835639	valid_1's binary_logloss: 0.140491
[41]	valid_0's auc: 0.898583	valid_0's binary_logloss: 0.114302	valid_1's auc: 0.835705	valid_1's binary_logloss: 0.140506
[42]	valid_0's auc: 0.899197	valid_0's binary_logloss: 0.113975	valid_1's auc: 0.835052	valid_1's binary_logloss: 0.14064
[43]	valid_0's auc: 0.899803	valid_0's binary_logloss: 0.113654	valid_1's auc: 0.835035	valid_1's binary_logloss: 0.140691
[44]	valid_0's auc: 0.900641	valid_0's binary_logloss: 0.113388	valid_1's auc: 0.835214	valid_1's binary_logloss: 0.140703
[45]	valid_0's auc: 0.900962	valid_0's binary_logloss: 0.113098	valid_1's auc: 0.835276	valid_1's binary_logloss: 0.140695
[46]	valid_0's auc: 0.901584	valid_0's binary_logloss: 0.112771	valid_1's auc: 0.83495	valid_1's binary_logloss: 0.140754
[47]	valid_0's auc: 0.902256	valid_0's binary_logloss: 0.112493	valid_1's auc: 0.835639	valid_1's binary_logloss: 0.14064
[48]	valid_0's auc: 0.902688	valid_0's binary_logloss: 0.112198	valid_1's auc: 0.835495	valid_1's binary_logloss: 0.140691
[49]	valid_0's auc: 0.902922	valid_0's binary_logloss: 0.111944	valid_1's auc: 0.835281	valid_1's binary_logloss: 0.140819
[50]	valid_0's auc: 0.903747	valid_0's binary_logloss: 0.111595	valid_1's auc: 0.835359	valid_1's binary_logloss: 0.140811
[51]	valid_0's auc: 0.904427	valid_0's binary_logloss: 0.111354	valid_1's auc: 0.835245	valid_1's binary_logloss: 0.140873
[52]	valid_0's auc: 0.90467	valid_0's binary_logloss: 0.111111	valid_1's auc: 0.835057	valid_1's binary_logloss: 0.140993
[53]	valid_0's auc: 0.904868	valid_0's binary_logloss: 0.110853	valid_1's auc: 0.834751	valid_1's binary_logloss: 0.14108
[54]	valid_0's auc: 0.905166	valid_0's binary_logloss: 0.110627	valid_1's auc: 0.83411	valid_1's binary_logloss: 0.141282
[55]	valid_0's auc: 0.905665	valid_0's binary_logloss: 0.110375	valid_1's auc: 0.833739	valid_1's binary_logloss: 0.141413
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.832891	valid_0's binary_logloss: 0.155302	valid_1's auc: 0.818851	valid_1's binary_logloss: 0.164826
[2]	valid_0's auc: 0.84519	valid_0's binary_logloss: 0.149727	valid_1's auc: 0.827144	valid_1's binary_logloss: 0.159879
[3]	valid_0's auc: 0.848018	valid_0's binary_logloss: 0.145627	valid_1's auc: 0.826851	valid_1's binary_logloss: 0.15631
[4]	valid_0's auc: 0.851096	valid_0's binary_logloss: 0.142423	valid_1's auc: 0.83073	valid_1's binary_logloss: 0.1534
[5]	valid_0's auc: 0.854735	valid_0's binary_logloss: 0.139746	valid_1's auc: 0.832753	valid_1's binary_logloss: 0.151136
[6]	valid_0's auc: 0.856928	valid_0's binary_logloss: 0.137509	valid_1's auc: 0.835605	valid_1's binary_logloss: 0.14924
[7]	valid_0's auc: 0.859448	valid_0's binary_logloss: 0.135575	valid_1's auc: 0.835612	valid_1's binary_logloss: 0.147799
[8]	valid_0's auc: 0.861685	valid_0's binary_logloss: 0.133953	valid_1's auc: 0.834408	valid_1's binary_logloss: 0.146634
[9]	valid_0's auc: 0.863391	valid_0's binary_logloss: 0.132468	valid_1's auc: 0.835623	valid_1's binary_logloss: 0.145549
[10]	valid_0's auc: 0.865858	valid_0's binary_logloss: 0.131185	valid_1's auc: 0.83487	valid_1's binary_logloss: 0.144745
[11]	valid_0's auc: 0.867134	valid_0's binary_logloss: 0.130116	valid_1's auc: 0.834692	valid_1's binary_logloss: 0.14411
[12]	valid_0's auc: 0.868217	valid_0's binary_logloss: 0.129097	valid_1's auc: 0.834746	valid_1's binary_logloss: 0.143527
[13]	valid_0's auc: 0.87073	valid_0's binary_logloss: 0.128129	valid_1's auc: 0.833582	valid_1's binary_logloss: 0.143122
[14]	valid_0's auc: 0.872621	valid_0's binary_logloss: 0.12721	valid_1's auc: 0.833205	valid_1's binary_logloss: 0.142745
[15]	valid_0's auc: 0.874007	valid_0's binary_logloss: 0.126363	valid_1's auc: 0.83246	valid_1's binary_logloss: 0.142489
[16]	valid_0's auc: 0.875141	valid_0's binary_logloss: 0.125606	valid_1's auc: 0.831958	valid_1's binary_logloss: 0.142275
[17]	valid_0's auc: 0.876061	valid_0's binary_logloss: 0.124928	valid_1's auc: 0.831586	valid_1's binary_logloss: 0.142141
[18]	valid_0's auc: 0.876982	valid_0's binary_logloss: 0.124313	valid_1's auc: 0.830954	valid_1's binary_logloss: 0.142066
[19]	valid_0's auc: 0.877885	valid_0's binary_logloss: 0.123709	valid_1's auc: 0.830572	valid_1's binary_logloss: 0.14196
[20]	valid_0's auc: 0.879378	valid_0's binary_logloss: 0.123088	valid_1's auc: 0.830076	valid_1's binary_logloss: 0.14196
[21]	valid_0's auc: 0.880647	valid_0's binary_logloss: 0.122488	valid_1's auc: 0.830109	valid_1's binary_logloss: 0.141858
[22]	valid_0's auc: 0.881614	valid_0's binary_logloss: 0.121973	valid_1's auc: 0.829735	valid_1's binary_logloss: 0.141822
[23]	valid_0's auc: 0.882402	valid_0's binary_logloss: 0.121554	valid_1's auc: 0.829254	valid_1's binary_logloss: 0.141805
[24]	valid_0's auc: 0.883011	valid_0's binary_logloss: 0.121078	valid_1's auc: 0.829054	valid_1's binary_logloss: 0.14178
[25]	valid_0's auc: 0.884627	valid_0's binary_logloss: 0.120587	valid_1's auc: 0.82942	valid_1's binary_logloss: 0.141653
[26]	valid_0's auc: 0.885304	valid_0's binary_logloss: 0.120169	valid_1's auc: 0.828716	valid_1's binary_logloss: 0.141755
[27]	valid_0's auc: 0.88664	valid_0's binary_logloss: 0.119673	valid_1's auc: 0.828869	valid_1's binary_logloss: 0.141682
[28]	valid_0's auc: 0.887143	valid_0's binary_logloss: 0.119308	valid_1's auc: 0.828987	valid_1's binary_logloss: 0.141649
[29]	valid_0's auc: 0.88825	valid_0's binary_logloss: 0.1189	valid_1's auc: 0.829075	valid_1's binary_logloss: 0.141601
[30]	valid_0's auc: 0.889081	valid_0's binary_logloss: 0.118531	valid_1's auc: 0.828871	valid_1's binary_logloss: 0.141605
[31]	valid_0's auc: 0.890195	valid_0's binary_logloss: 0.118117	valid_1's auc: 0.828972	valid_1's binary_logloss: 0.141605
[32]	valid_0's auc: 0.890928	valid_0's binary_logloss: 0.117735	valid_1's auc: 0.827969	valid_1's binary_logloss: 0.141796
[33]	valid_0's auc: 0.891505	valid_0's binary_logloss: 0.117389	valid_1's auc: 0.827611	valid_1's binary_logloss: 0.141916
[34]	valid_0's auc: 0.892223	valid_0's binary_logloss: 0.11707	valid_1's auc: 0.827019	valid_1's binary_logloss: 0.142051
[35]	valid_0's auc: 0.892825	valid_0's binary_logloss: 0.116751	valid_1's auc: 0.826865	valid_1's binary_logloss: 0.142116
[36]	valid_0's auc: 0.893984	valid_0's binary_logloss: 0.116353	valid_1's auc: 0.827203	valid_1's binary_logloss: 0.14207
[37]	valid_0's auc: 0.89456	valid_0's binary_logloss: 0.11603	valid_1's auc: 0.827292	valid_1's binary_logloss: 0.142005
[38]	valid_0's auc: 0.89511	valid_0's binary_logloss: 0.115713	valid_1's auc: 0.827214	valid_1's binary_logloss: 0.14206
[39]	valid_0's auc: 0.895738	valid_0's binary_logloss: 0.115415	valid_1's auc: 0.82695	valid_1's binary_logloss: 0.142162
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.833054	valid_0's binary_logloss: 0.15572	valid_1's auc: 0.817048	valid_1's binary_logloss: 0.165036
[2]	valid_0's auc: 0.841397	valid_0's binary_logloss: 0.149862	valid_1's auc: 0.82157	valid_1's binary_logloss: 0.159575
[3]	valid_0's auc: 0.849058	valid_0's binary_logloss: 0.145662	valid_1's auc: 0.829866	valid_1's binary_logloss: 0.155774
[4]	valid_0's auc: 0.854301	valid_0's binary_logloss: 0.142356	valid_1's auc: 0.832415	valid_1's binary_logloss: 0.152936
[5]	valid_0's auc: 0.858045	valid_0's binary_logloss: 0.139697	valid_1's auc: 0.834554	valid_1's binary_logloss: 0.150635
[6]	valid_0's auc: 0.860767	valid_0's binary_logloss: 0.137458	valid_1's auc: 0.834885	valid_1's binary_logloss: 0.148761
[7]	valid_0's auc: 0.863011	valid_0's binary_logloss: 0.135522	valid_1's auc: 0.835812	valid_1's binary_logloss: 0.147245
[8]	valid_0's auc: 0.864923	valid_0's binary_logloss: 0.133792	valid_1's auc: 0.836656	valid_1's binary_logloss: 0.145923
[9]	valid_0's auc: 0.865706	valid_0's binary_logloss: 0.13236	valid_1's auc: 0.836912	valid_1's binary_logloss: 0.144867
[10]	valid_0's auc: 0.867693	valid_0's binary_logloss: 0.131066	valid_1's auc: 0.837266	valid_1's binary_logloss: 0.143895
[11]	valid_0's auc: 0.868596	valid_0's binary_logloss: 0.129937	valid_1's auc: 0.836466	valid_1's binary_logloss: 0.143255
[12]	valid_0's auc: 0.87012	valid_0's binary_logloss: 0.128904	valid_1's auc: 0.836589	valid_1's binary_logloss: 0.142728
[13]	valid_0's auc: 0.871703	valid_0's binary_logloss: 0.127913	valid_1's auc: 0.836567	valid_1's binary_logloss: 0.142105
[14]	valid_0's auc: 0.873468	valid_0's binary_logloss: 0.126983	valid_1's auc: 0.835538	valid_1's binary_logloss: 0.141771
[15]	valid_0's auc: 0.874839	valid_0's binary_logloss: 0.126147	valid_1's auc: 0.835363	valid_1's binary_logloss: 0.141464
[16]	valid_0's auc: 0.876399	valid_0's binary_logloss: 0.125331	valid_1's auc: 0.83478	valid_1's binary_logloss: 0.141245
[17]	valid_0's auc: 0.877465	valid_0's binary_logloss: 0.124655	valid_1's auc: 0.834621	valid_1's binary_logloss: 0.141028
[18]	valid_0's auc: 0.878935	valid_0's binary_logloss: 0.123944	valid_1's auc: 0.834165	valid_1's binary_logloss: 0.140935
[19]	valid_0's auc: 0.88046	valid_0's binary_logloss: 0.123313	valid_1's auc: 0.834629	valid_1's binary_logloss: 0.140738
[20]	valid_0's auc: 0.881517	valid_0's binary_logloss: 0.12269	valid_1's auc: 0.8347	valid_1's binary_logloss: 0.140611
[21]	valid_0's auc: 0.882464	valid_0's binary_logloss: 0.122095	valid_1's auc: 0.834656	valid_1's binary_logloss: 0.140487
[22]	valid_0's auc: 0.883744	valid_0's binary_logloss: 0.121504	valid_1's auc: 0.834562	valid_1's binary_logloss: 0.140328
[23]	valid_0's auc: 0.885301	valid_0's binary_logloss: 0.12091	valid_1's auc: 0.835278	valid_1's binary_logloss: 0.140199
[24]	valid_0's auc: 0.886266	valid_0's binary_logloss: 0.120437	valid_1's auc: 0.835728	valid_1's binary_logloss: 0.140094
[25]	valid_0's auc: 0.88755	valid_0's binary_logloss: 0.119931	valid_1's auc: 0.836199	valid_1's binary_logloss: 0.140076
[26]	valid_0's auc: 0.888525	valid_0's binary_logloss: 0.119473	valid_1's auc: 0.836708	valid_1's binary_logloss: 0.139945
[27]	valid_0's auc: 0.889589	valid_0's binary_logloss: 0.119012	valid_1's auc: 0.836951	valid_1's binary_logloss: 0.139843
[28]	valid_0's auc: 0.890552	valid_0's binary_logloss: 0.118602	valid_1's auc: 0.836524	valid_1's binary_logloss: 0.139871
[29]	valid_0's auc: 0.891402	valid_0's binary_logloss: 0.118166	valid_1's auc: 0.836264	valid_1's binary_logloss: 0.139884
[30]	valid_0's auc: 0.891982	valid_0's binary_logloss: 0.117805	valid_1's auc: 0.835959	valid_1's binary_logloss: 0.139937
[31]	valid_0's auc: 0.893185	valid_0's binary_logloss: 0.117392	valid_1's auc: 0.836384	valid_1's binary_logloss: 0.13992
[32]	valid_0's auc: 0.894065	valid_0's binary_logloss: 0.117017	valid_1's auc: 0.836341	valid_1's binary_logloss: 0.139888
[33]	valid_0's auc: 0.894791	valid_0's binary_logloss: 0.116671	valid_1's auc: 0.836753	valid_1's binary_logloss: 0.139812
[34]	valid_0's auc: 0.895313	valid_0's binary_logloss: 0.116321	valid_1's auc: 0.836733	valid_1's binary_logloss: 0.139826
[35]	valid_0's auc: 0.895876	valid_0's binary_logloss: 0.116039	valid_1's auc: 0.836245	valid_1's binary_logloss: 0.139883
[36]	valid_0's auc: 0.896909	valid_0's binary_logloss: 0.115684	valid_1's auc: 0.836079	valid_1's binary_logloss: 0.139912
[37]	valid_0's auc: 0.897427	valid_0's binary_logloss: 0.115388	valid_1's auc: 0.835564	valid_1's binary_logloss: 0.140024
[38]	valid_0's auc: 0.898442	valid_0's binary_logloss: 0.115006	valid_1's auc: 0.835612	valid_1's binary_logloss: 0.140075
[39]	valid_0's auc: 0.899304	valid_0's binary_logloss: 0.114592	valid_1's auc: 0.836273	valid_1's binary_logloss: 0.139974
[40]	valid_0's auc: 0.89974	valid_0's binary_logloss: 0.11432	valid_1's auc: 0.836096	valid_1's binary_logloss: 0.140042
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.830643	valid_0's binary_logloss: 0.155759	valid_1's auc: 0.816734	valid_1's binary_logloss: 0.164985
[2]	valid_0's auc: 0.839353	valid_0's binary_logloss: 0.149977	valid_1's auc: 0.822571	valid_1's binary_logloss: 0.159808
[3]	valid_0's auc: 0.847366	valid_0's binary_logloss: 0.145866	valid_1's auc: 0.829312	valid_1's binary_logloss: 0.156171
[4]	valid_0's auc: 0.850911	valid_0's binary_logloss: 0.14247	valid_1's auc: 0.830848	valid_1's binary_logloss: 0.153328
[5]	valid_0's auc: 0.854674	valid_0's binary_logloss: 0.139764	valid_1's auc: 0.833041	valid_1's binary_logloss: 0.151023
[6]	valid_0's auc: 0.856722	valid_0's binary_logloss: 0.1375	valid_1's auc: 0.834264	valid_1's binary_logloss: 0.149166
[7]	valid_0's auc: 0.858253	valid_0's binary_logloss: 0.135713	valid_1's auc: 0.834998	valid_1's binary_logloss: 0.147631
[8]	valid_0's auc: 0.859768	valid_0's binary_logloss: 0.134063	valid_1's auc: 0.835678	valid_1's binary_logloss: 0.146384
[9]	valid_0's auc: 0.86262	valid_0's binary_logloss: 0.132622	valid_1's auc: 0.836272	valid_1's binary_logloss: 0.145313
[10]	valid_0's auc: 0.864631	valid_0's binary_logloss: 0.131324	valid_1's auc: 0.835827	valid_1's binary_logloss: 0.144553
[11]	valid_0's auc: 0.866805	valid_0's binary_logloss: 0.130172	valid_1's auc: 0.835375	valid_1's binary_logloss: 0.143933
[12]	valid_0's auc: 0.868266	valid_0's binary_logloss: 0.129101	valid_1's auc: 0.835951	valid_1's binary_logloss: 0.143342
[13]	valid_0's auc: 0.870762	valid_0's binary_logloss: 0.128144	valid_1's auc: 0.83626	valid_1's binary_logloss: 0.142813
[14]	valid_0's auc: 0.872747	valid_0's binary_logloss: 0.127222	valid_1's auc: 0.835864	valid_1's binary_logloss: 0.142466
[15]	valid_0's auc: 0.874158	valid_0's binary_logloss: 0.126428	valid_1's auc: 0.83548	valid_1's binary_logloss: 0.142108
[16]	valid_0's auc: 0.875931	valid_0's binary_logloss: 0.125651	valid_1's auc: 0.836367	valid_1's binary_logloss: 0.141684
[17]	valid_0's auc: 0.876854	valid_0's binary_logloss: 0.124918	valid_1's auc: 0.835689	valid_1's binary_logloss: 0.141524
[18]	valid_0's auc: 0.878211	valid_0's binary_logloss: 0.124197	valid_1's auc: 0.835893	valid_1's binary_logloss: 0.141285
[19]	valid_0's auc: 0.879125	valid_0's binary_logloss: 0.123553	valid_1's auc: 0.835877	valid_1's binary_logloss: 0.141128
[20]	valid_0's auc: 0.880489	valid_0's binary_logloss: 0.122856	valid_1's auc: 0.835385	valid_1's binary_logloss: 0.141032
[21]	valid_0's auc: 0.881696	valid_0's binary_logloss: 0.122219	valid_1's auc: 0.835822	valid_1's binary_logloss: 0.140843
[22]	valid_0's auc: 0.882257	valid_0's binary_logloss: 0.121726	valid_1's auc: 0.835849	valid_1's binary_logloss: 0.140761
[23]	valid_0's auc: 0.883635	valid_0's binary_logloss: 0.121206	valid_1's auc: 0.836223	valid_1's binary_logloss: 0.140607
[24]	valid_0's auc: 0.884533	valid_0's binary_logloss: 0.120734	valid_1's auc: 0.836473	valid_1's binary_logloss: 0.14049
[25]	valid_0's auc: 0.885234	valid_0's binary_logloss: 0.120268	valid_1's auc: 0.836722	valid_1's binary_logloss: 0.140403
[26]	valid_0's auc: 0.886292	valid_0's binary_logloss: 0.119794	valid_1's auc: 0.836549	valid_1's binary_logloss: 0.140423
[27]	valid_0's auc: 0.887064	valid_0's binary_logloss: 0.119366	valid_1's auc: 0.836155	valid_1's binary_logloss: 0.140447
[28]	valid_0's auc: 0.887621	valid_0's binary_logloss: 0.119008	valid_1's auc: 0.835594	valid_1's binary_logloss: 0.140532
[29]	valid_0's auc: 0.888965	valid_0's binary_logloss: 0.118547	valid_1's auc: 0.835464	valid_1's binary_logloss: 0.140508
[30]	valid_0's auc: 0.889898	valid_0's binary_logloss: 0.118139	valid_1's auc: 0.83577	valid_1's binary_logloss: 0.140461
[31]	valid_0's auc: 0.890896	valid_0's binary_logloss: 0.117734	valid_1's auc: 0.835475	valid_1's binary_logloss: 0.140463
[32]	valid_0's auc: 0.892374	valid_0's binary_logloss: 0.1173	valid_1's auc: 0.835364	valid_1's binary_logloss: 0.140506
[33]	valid_0's auc: 0.893164	valid_0's binary_logloss: 0.116978	valid_1's auc: 0.835865	valid_1's binary_logloss: 0.14041
[34]	valid_0's auc: 0.893848	valid_0's binary_logloss: 0.11662	valid_1's auc: 0.836021	valid_1's binary_logloss: 0.140353
[35]	valid_0's auc: 0.894232	valid_0's binary_logloss: 0.116323	valid_1's auc: 0.8359	valid_1's binary_logloss: 0.140396
[36]	valid_0's auc: 0.895003	valid_0's binary_logloss: 0.115986	valid_1's auc: 0.835855	valid_1's binary_logloss: 0.140416
[37]	valid_0's auc: 0.895898	valid_0's binary_logloss: 0.115609	valid_1's auc: 0.836185	valid_1's binary_logloss: 0.140369
[38]	valid_0's auc: 0.896459	valid_0's binary_logloss: 0.11527	valid_1's auc: 0.835754	valid_1's binary_logloss: 0.140443
[39]	valid_0's auc: 0.897377	valid_0's binary_logloss: 0.114873	valid_1's auc: 0.835638	valid_1's binary_logloss: 0.140474
[40]	valid_0's auc: 0.89776	valid_0's binary_logloss: 0.114588	valid_1's auc: 0.835639	valid_1's binary_logloss: 0.140491
[41]	valid_0's auc: 0.898583	valid_0's binary_logloss: 0.114302	valid_1's auc: 0.835705	valid_1's binary_logloss: 0.140506
[42]	valid_0's auc: 0.899197	valid_0's binary_logloss: 0.113975	valid_1's auc: 0.835052	valid_1's binary_logloss: 0.14064
[43]	valid_0's auc: 0.899803	valid_0's binary_logloss: 0.113654	valid_1's auc: 0.835035	valid_1's binary_logloss: 0.140691
[44]	valid_0's auc: 0.900641	valid_0's binary_logloss: 0.113388	valid_1's auc: 0.835214	valid_1's binary_logloss: 0.140703
[45]	valid_0's auc: 0.900962	valid_0's binary_logloss: 0.113098	valid_1's auc: 0.835276	valid_1's binary_logloss: 0.140695
[46]	valid_0's auc: 0.901584	valid_0's binary_logloss: 0.112771	valid_1's auc: 0.83495	valid_1's binary_logloss: 0.140754
[47]	valid_0's auc: 0.902256	valid_0's binary_logloss: 0.112493	valid_1's auc: 0.835639	valid_1's binary_logloss: 0.14064
[48]	valid_0's auc: 0.902688	valid_0's binary_logloss: 0.112198	valid_1's auc: 0.835495	valid_1's binary_logloss: 0.140691
[49]	valid_0's auc: 0.902922	valid_0's binary_logloss: 0.111944	valid_1's auc: 0.835281	valid_1's binary_logloss: 0.140819
[50]	valid_0's auc: 0.903747	valid_0's binary_logloss: 0.111595	valid_1's auc: 0.835359	valid_1's binary_logloss: 0.140811
[51]	valid_0's auc: 0.904427	valid_0's binary_logloss: 0.111354	valid_1's auc: 0.835245	valid_1's binary_logloss: 0.140873
[52]	valid_0's auc: 0.90467	valid_0's binary_logloss: 0.111111	valid_1's auc: 0.835057	valid_1's binary_logloss: 0.140993
[53]	valid_0's auc: 0.904868	valid_0's binary_logloss: 0.110853	valid_1's auc: 0.834751	valid_1's binary_logloss: 0.14108
[54]	valid_0's auc: 0.905166	valid_0's binary_logloss: 0.110627	valid_1's auc: 0.83411	valid_1's binary_logloss: 0.141282
[55]	valid_0's auc: 0.905665	valid_0's binary_logloss: 0.110375	valid_1's auc: 0.833739	valid_1's binary_logloss: 0.141413
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.824873	valid_0's binary_logloss: 0.156222	valid_1's auc: 0.817791	valid_1's binary_logloss: 0.165072
[2]	valid_0's auc: 0.828725	valid_0's binary_logloss: 0.151244	valid_1's auc: 0.822586	valid_1's binary_logloss: 0.160253
[3]	valid_0's auc: 0.83594	valid_0's binary_logloss: 0.147423	valid_1's auc: 0.828474	valid_1's binary_logloss: 0.156542
[4]	valid_0's auc: 0.839489	valid_0's binary_logloss: 0.144426	valid_1's auc: 0.831396	valid_1's binary_logloss: 0.153706
[5]	valid_0's auc: 0.843358	valid_0's binary_logloss: 0.142067	valid_1's auc: 0.833466	valid_1's binary_logloss: 0.151399
[6]	valid_0's auc: 0.845601	valid_0's binary_logloss: 0.14009	valid_1's auc: 0.833857	valid_1's binary_logloss: 0.149488
[7]	valid_0's auc: 0.846477	valid_0's binary_logloss: 0.138491	valid_1's auc: 0.833143	valid_1's binary_logloss: 0.148023
[8]	valid_0's auc: 0.847725	valid_0's binary_logloss: 0.137129	valid_1's auc: 0.833971	valid_1's binary_logloss: 0.146757
[9]	valid_0's auc: 0.848442	valid_0's binary_logloss: 0.135908	valid_1's auc: 0.835976	valid_1's binary_logloss: 0.145685
[10]	valid_0's auc: 0.849759	valid_0's binary_logloss: 0.134781	valid_1's auc: 0.836214	valid_1's binary_logloss: 0.144769
[11]	valid_0's auc: 0.852238	valid_0's binary_logloss: 0.133835	valid_1's auc: 0.837243	valid_1's binary_logloss: 0.143925
[12]	valid_0's auc: 0.853743	valid_0's binary_logloss: 0.132972	valid_1's auc: 0.836647	valid_1's binary_logloss: 0.143391
[13]	valid_0's auc: 0.854568	valid_0's binary_logloss: 0.132256	valid_1's auc: 0.837182	valid_1's binary_logloss: 0.142849
[14]	valid_0's auc: 0.855928	valid_0's binary_logloss: 0.131554	valid_1's auc: 0.835941	valid_1's binary_logloss: 0.142474
[15]	valid_0's auc: 0.85712	valid_0's binary_logloss: 0.130984	valid_1's auc: 0.834938	valid_1's binary_logloss: 0.142198
[16]	valid_0's auc: 0.858721	valid_0's binary_logloss: 0.130371	valid_1's auc: 0.83561	valid_1's binary_logloss: 0.141802
[17]	valid_0's auc: 0.859281	valid_0's binary_logloss: 0.129877	valid_1's auc: 0.835146	valid_1's binary_logloss: 0.141605
[18]	valid_0's auc: 0.859881	valid_0's binary_logloss: 0.129417	valid_1's auc: 0.835386	valid_1's binary_logloss: 0.14132
[19]	valid_0's auc: 0.861409	valid_0's binary_logloss: 0.128929	valid_1's auc: 0.834974	valid_1's binary_logloss: 0.141151
[20]	valid_0's auc: 0.862574	valid_0's binary_logloss: 0.128458	valid_1's auc: 0.834949	valid_1's binary_logloss: 0.140968
[21]	valid_0's auc: 0.863262	valid_0's binary_logloss: 0.128069	valid_1's auc: 0.834616	valid_1's binary_logloss: 0.14086
[22]	valid_0's auc: 0.864655	valid_0's binary_logloss: 0.127684	valid_1's auc: 0.834363	valid_1's binary_logloss: 0.140766
[23]	valid_0's auc: 0.865247	valid_0's binary_logloss: 0.127349	valid_1's auc: 0.834317	valid_1's binary_logloss: 0.140688
[24]	valid_0's auc: 0.865882	valid_0's binary_logloss: 0.12704	valid_1's auc: 0.833543	valid_1's binary_logloss: 0.14068
[25]	valid_0's auc: 0.867496	valid_0's binary_logloss: 0.126629	valid_1's auc: 0.834195	valid_1's binary_logloss: 0.140539
[26]	valid_0's auc: 0.867923	valid_0's binary_logloss: 0.126353	valid_1's auc: 0.834028	valid_1's binary_logloss: 0.140506
[27]	valid_0's auc: 0.868685	valid_0's binary_logloss: 0.126058	valid_1's auc: 0.834718	valid_1's binary_logloss: 0.140359
[28]	valid_0's auc: 0.869304	valid_0's binary_logloss: 0.125764	valid_1's auc: 0.834935	valid_1's binary_logloss: 0.140287
[29]	valid_0's auc: 0.870037	valid_0's binary_logloss: 0.125514	valid_1's auc: 0.834481	valid_1's binary_logloss: 0.140258
[30]	valid_0's auc: 0.870785	valid_0's binary_logloss: 0.125254	valid_1's auc: 0.834179	valid_1's binary_logloss: 0.140275
[31]	valid_0's auc: 0.871706	valid_0's binary_logloss: 0.124992	valid_1's auc: 0.834475	valid_1's binary_logloss: 0.140205
[32]	valid_0's auc: 0.872582	valid_0's binary_logloss: 0.124728	valid_1's auc: 0.834353	valid_1's binary_logloss: 0.140189
[33]	valid_0's auc: 0.873445	valid_0's binary_logloss: 0.124481	valid_1's auc: 0.834592	valid_1's binary_logloss: 0.140082
[34]	valid_0's auc: 0.874095	valid_0's binary_logloss: 0.12426	valid_1's auc: 0.83436	valid_1's binary_logloss: 0.140101
[35]	valid_0's auc: 0.874869	valid_0's binary_logloss: 0.123982	valid_1's auc: 0.834045	valid_1's binary_logloss: 0.140151
[36]	valid_0's auc: 0.875446	valid_0's binary_logloss: 0.123753	valid_1's auc: 0.834073	valid_1's binary_logloss: 0.140125
[37]	valid_0's auc: 0.875763	valid_0's binary_logloss: 0.123587	valid_1's auc: 0.833611	valid_1's binary_logloss: 0.140201
[38]	valid_0's auc: 0.876603	valid_0's binary_logloss: 0.123335	valid_1's auc: 0.833805	valid_1's binary_logloss: 0.140159
[39]	valid_0's auc: 0.877126	valid_0's binary_logloss: 0.123134	valid_1's auc: 0.834422	valid_1's binary_logloss: 0.140048
[40]	valid_0's auc: 0.877575	valid_0's binary_logloss: 0.123013	valid_1's auc: 0.834343	valid_1's binary_logloss: 0.140069
[41]	valid_0's auc: 0.87809	valid_0's binary_logloss: 0.122813	valid_1's auc: 0.834199	valid_1's binary_logloss: 0.140085
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.821831	valid_0's binary_logloss: 0.156466	valid_1's auc: 0.817525	valid_1's binary_logloss: 0.165186
[2]	valid_0's auc: 0.831974	valid_0's binary_logloss: 0.151137	valid_1's auc: 0.82532	valid_1's binary_logloss: 0.159691
[3]	valid_0's auc: 0.839496	valid_0's binary_logloss: 0.14733	valid_1's auc: 0.831946	valid_1's binary_logloss: 0.156
[4]	valid_0's auc: 0.843984	valid_0's binary_logloss: 0.144371	valid_1's auc: 0.834064	valid_1's binary_logloss: 0.153082
[5]	valid_0's auc: 0.845854	valid_0's binary_logloss: 0.142024	valid_1's auc: 0.836918	valid_1's binary_logloss: 0.150735
[6]	valid_0's auc: 0.848041	valid_0's binary_logloss: 0.140009	valid_1's auc: 0.838831	valid_1's binary_logloss: 0.148771
[7]	valid_0's auc: 0.849655	valid_0's binary_logloss: 0.138307	valid_1's auc: 0.839111	valid_1's binary_logloss: 0.147373
[8]	valid_0's auc: 0.85185	valid_0's binary_logloss: 0.136891	valid_1's auc: 0.838955	valid_1's binary_logloss: 0.146094
[9]	valid_0's auc: 0.853067	valid_0's binary_logloss: 0.135655	valid_1's auc: 0.838081	valid_1's binary_logloss: 0.14516
[10]	valid_0's auc: 0.853922	valid_0's binary_logloss: 0.134622	valid_1's auc: 0.837333	valid_1's binary_logloss: 0.144318
[11]	valid_0's auc: 0.854729	valid_0's binary_logloss: 0.133702	valid_1's auc: 0.83725	valid_1's binary_logloss: 0.143512
[12]	valid_0's auc: 0.856303	valid_0's binary_logloss: 0.132789	valid_1's auc: 0.837602	valid_1's binary_logloss: 0.142833
[13]	valid_0's auc: 0.857206	valid_0's binary_logloss: 0.132038	valid_1's auc: 0.837364	valid_1's binary_logloss: 0.142245
[14]	valid_0's auc: 0.858161	valid_0's binary_logloss: 0.131391	valid_1's auc: 0.83777	valid_1's binary_logloss: 0.141759
[15]	valid_0's auc: 0.858975	valid_0's binary_logloss: 0.130772	valid_1's auc: 0.837831	valid_1's binary_logloss: 0.14139
[16]	valid_0's auc: 0.859623	valid_0's binary_logloss: 0.130219	valid_1's auc: 0.837953	valid_1's binary_logloss: 0.141016
[17]	valid_0's auc: 0.860576	valid_0's binary_logloss: 0.129684	valid_1's auc: 0.837985	valid_1's binary_logloss: 0.140713
[18]	valid_0's auc: 0.861311	valid_0's binary_logloss: 0.129202	valid_1's auc: 0.83796	valid_1's binary_logloss: 0.140452
[19]	valid_0's auc: 0.862347	valid_0's binary_logloss: 0.128715	valid_1's auc: 0.838506	valid_1's binary_logloss: 0.140189
[20]	valid_0's auc: 0.86305	valid_0's binary_logloss: 0.128312	valid_1's auc: 0.837702	valid_1's binary_logloss: 0.140094
[21]	valid_0's auc: 0.863758	valid_0's binary_logloss: 0.127907	valid_1's auc: 0.838127	valid_1's binary_logloss: 0.139858
[22]	valid_0's auc: 0.864635	valid_0's binary_logloss: 0.127525	valid_1's auc: 0.838331	valid_1's binary_logloss: 0.139696
[23]	valid_0's auc: 0.865866	valid_0's binary_logloss: 0.127143	valid_1's auc: 0.837841	valid_1's binary_logloss: 0.139625
[24]	valid_0's auc: 0.867054	valid_0's binary_logloss: 0.126749	valid_1's auc: 0.838187	valid_1's binary_logloss: 0.139526
[25]	valid_0's auc: 0.867553	valid_0's binary_logloss: 0.126476	valid_1's auc: 0.838308	valid_1's binary_logloss: 0.13949
[26]	valid_0's auc: 0.868108	valid_0's binary_logloss: 0.126164	valid_1's auc: 0.838035	valid_1's binary_logloss: 0.139426
[27]	valid_0's auc: 0.869014	valid_0's binary_logloss: 0.125868	valid_1's auc: 0.837545	valid_1's binary_logloss: 0.139445
[28]	valid_0's auc: 0.869797	valid_0's binary_logloss: 0.12559	valid_1's auc: 0.837894	valid_1's binary_logloss: 0.139419
[29]	valid_0's auc: 0.870435	valid_0's binary_logloss: 0.1253	valid_1's auc: 0.838103	valid_1's binary_logloss: 0.139321
[30]	valid_0's auc: 0.87141	valid_0's binary_logloss: 0.125025	valid_1's auc: 0.838164	valid_1's binary_logloss: 0.139275
[31]	valid_0's auc: 0.872143	valid_0's binary_logloss: 0.124769	valid_1's auc: 0.837843	valid_1's binary_logloss: 0.139285
[32]	valid_0's auc: 0.872606	valid_0's binary_logloss: 0.124561	valid_1's auc: 0.837662	valid_1's binary_logloss: 0.139274
[33]	valid_0's auc: 0.873337	valid_0's binary_logloss: 0.124346	valid_1's auc: 0.837661	valid_1's binary_logloss: 0.139284
[34]	valid_0's auc: 0.873965	valid_0's binary_logloss: 0.124108	valid_1's auc: 0.837639	valid_1's binary_logloss: 0.139263
[35]	valid_0's auc: 0.87457	valid_0's binary_logloss: 0.123857	valid_1's auc: 0.838159	valid_1's binary_logloss: 0.139137
[36]	valid_0's auc: 0.874973	valid_0's binary_logloss: 0.123651	valid_1's auc: 0.838114	valid_1's binary_logloss: 0.139148
[37]	valid_0's auc: 0.875657	valid_0's binary_logloss: 0.123447	valid_1's auc: 0.838519	valid_1's binary_logloss: 0.139109
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.821427	valid_0's binary_logloss: 0.156592	valid_1's auc: 0.81711	valid_1's binary_logloss: 0.165273
[2]	valid_0's auc: 0.827893	valid_0's binary_logloss: 0.151336	valid_1's auc: 0.820533	valid_1's binary_logloss: 0.160243
[3]	valid_0's auc: 0.83753	valid_0's binary_logloss: 0.147487	valid_1's auc: 0.82841	valid_1's binary_logloss: 0.156547
[4]	valid_0's auc: 0.84038	valid_0's binary_logloss: 0.144428	valid_1's auc: 0.8313	valid_1's binary_logloss: 0.153575
[5]	valid_0's auc: 0.842945	valid_0's binary_logloss: 0.142089	valid_1's auc: 0.833579	valid_1's binary_logloss: 0.151354
[6]	valid_0's auc: 0.843246	valid_0's binary_logloss: 0.140186	valid_1's auc: 0.833781	valid_1's binary_logloss: 0.14953
[7]	valid_0's auc: 0.844301	valid_0's binary_logloss: 0.138471	valid_1's auc: 0.834317	valid_1's binary_logloss: 0.147954
[8]	valid_0's auc: 0.846945	valid_0's binary_logloss: 0.137078	valid_1's auc: 0.834895	valid_1's binary_logloss: 0.146786
[9]	valid_0's auc: 0.849381	valid_0's binary_logloss: 0.135906	valid_1's auc: 0.834922	valid_1's binary_logloss: 0.145762
[10]	valid_0's auc: 0.850944	valid_0's binary_logloss: 0.134855	valid_1's auc: 0.835441	valid_1's binary_logloss: 0.144958
[11]	valid_0's auc: 0.852557	valid_0's binary_logloss: 0.133895	valid_1's auc: 0.835103	valid_1's binary_logloss: 0.144293
[12]	valid_0's auc: 0.854609	valid_0's binary_logloss: 0.133013	valid_1's auc: 0.835686	valid_1's binary_logloss: 0.143793
[13]	valid_0's auc: 0.855817	valid_0's binary_logloss: 0.132247	valid_1's auc: 0.835296	valid_1's binary_logloss: 0.143302
[14]	valid_0's auc: 0.857501	valid_0's binary_logloss: 0.131545	valid_1's auc: 0.836432	valid_1's binary_logloss: 0.142761
[15]	valid_0's auc: 0.858907	valid_0's binary_logloss: 0.130878	valid_1's auc: 0.836329	valid_1's binary_logloss: 0.142383
[16]	valid_0's auc: 0.859887	valid_0's binary_logloss: 0.130287	valid_1's auc: 0.836611	valid_1's binary_logloss: 0.141883
[17]	valid_0's auc: 0.860889	valid_0's binary_logloss: 0.129757	valid_1's auc: 0.836848	valid_1's binary_logloss: 0.141535
[18]	valid_0's auc: 0.861827	valid_0's binary_logloss: 0.129301	valid_1's auc: 0.837106	valid_1's binary_logloss: 0.141257
[19]	valid_0's auc: 0.862972	valid_0's binary_logloss: 0.128826	valid_1's auc: 0.837185	valid_1's binary_logloss: 0.141043
[20]	valid_0's auc: 0.864083	valid_0's binary_logloss: 0.128369	valid_1's auc: 0.837509	valid_1's binary_logloss: 0.140794
[21]	valid_0's auc: 0.864747	valid_0's binary_logloss: 0.127959	valid_1's auc: 0.837888	valid_1's binary_logloss: 0.140626
[22]	valid_0's auc: 0.865769	valid_0's binary_logloss: 0.127562	valid_1's auc: 0.837811	valid_1's binary_logloss: 0.140487
[23]	valid_0's auc: 0.866657	valid_0's binary_logloss: 0.127217	valid_1's auc: 0.837884	valid_1's binary_logloss: 0.140328
[24]	valid_0's auc: 0.867293	valid_0's binary_logloss: 0.126875	valid_1's auc: 0.838481	valid_1's binary_logloss: 0.140215
[25]	valid_0's auc: 0.867983	valid_0's binary_logloss: 0.126562	valid_1's auc: 0.838239	valid_1's binary_logloss: 0.140124
[26]	valid_0's auc: 0.868559	valid_0's binary_logloss: 0.126248	valid_1's auc: 0.837903	valid_1's binary_logloss: 0.140092
[27]	valid_0's auc: 0.869394	valid_0's binary_logloss: 0.125936	valid_1's auc: 0.837493	valid_1's binary_logloss: 0.14006
[28]	valid_0's auc: 0.87048	valid_0's binary_logloss: 0.125677	valid_1's auc: 0.837623	valid_1's binary_logloss: 0.140007
[29]	valid_0's auc: 0.87105	valid_0's binary_logloss: 0.125405	valid_1's auc: 0.838216	valid_1's binary_logloss: 0.13986
[30]	valid_0's auc: 0.871749	valid_0's binary_logloss: 0.125147	valid_1's auc: 0.838898	valid_1's binary_logloss: 0.139742
[31]	valid_0's auc: 0.87247	valid_0's binary_logloss: 0.124907	valid_1's auc: 0.838959	valid_1's binary_logloss: 0.139727
[32]	valid_0's auc: 0.87282	valid_0's binary_logloss: 0.124724	valid_1's auc: 0.838675	valid_1's binary_logloss: 0.139761
[33]	valid_0's auc: 0.874106	valid_0's binary_logloss: 0.124412	valid_1's auc: 0.838893	valid_1's binary_logloss: 0.139687
[34]	valid_0's auc: 0.874887	valid_0's binary_logloss: 0.124169	valid_1's auc: 0.838801	valid_1's binary_logloss: 0.139672
[35]	valid_0's auc: 0.875447	valid_0's binary_logloss: 0.123934	valid_1's auc: 0.838835	valid_1's binary_logloss: 0.139667
[36]	valid_0's auc: 0.87617	valid_0's binary_logloss: 0.123693	valid_1's auc: 0.838505	valid_1's binary_logloss: 0.139699
[37]	valid_0's auc: 0.876793	valid_0's binary_logloss: 0.12346	valid_1's auc: 0.838104	valid_1's binary_logloss: 0.139783
[38]	valid_0's auc: 0.877265	valid_0's binary_logloss: 0.123251	valid_1's auc: 0.838267	valid_1's binary_logloss: 0.139787
[39]	valid_0's auc: 0.877869	valid_0's binary_logloss: 0.123018	valid_1's auc: 0.838004	valid_1's binary_logloss: 0.139806
[40]	valid_0's auc: 0.878509	valid_0's binary_logloss: 0.122803	valid_1's auc: 0.838086	valid_1's binary_logloss: 0.139745
[41]	valid_0's auc: 0.879077	valid_0's binary_logloss: 0.122585	valid_1's auc: 0.838538	valid_1's binary_logloss: 0.139694
[42]	valid_0's auc: 0.879515	valid_0's binary_logloss: 0.122368	valid_1's auc: 0.838647	valid_1's binary_logloss: 0.139655
[43]	valid_0's auc: 0.879985	valid_0's binary_logloss: 0.122166	valid_1's auc: 0.838495	valid_1's binary_logloss: 0.139653
[44]	valid_0's auc: 0.88041	valid_0's binary_logloss: 0.121985	valid_1's auc: 0.838221	valid_1's binary_logloss: 0.139755
[45]	valid_0's auc: 0.880907	valid_0's binary_logloss: 0.121777	valid_1's auc: 0.837981	valid_1's binary_logloss: 0.139769
[46]	valid_0's auc: 0.881216	valid_0's binary_logloss: 0.121594	valid_1's auc: 0.838471	valid_1's binary_logloss: 0.139693
[47]	valid_0's auc: 0.881591	valid_0's binary_logloss: 0.121422	valid_1's auc: 0.83861	valid_1's binary_logloss: 0.139687
[48]	valid_0's auc: 0.881867	valid_0's binary_logloss: 0.121266	valid_1's auc: 0.838593	valid_1's binary_logloss: 0.139682
[49]	valid_0's auc: 0.882285	valid_0's binary_logloss: 0.121041	valid_1's auc: 0.838317	valid_1's binary_logloss: 0.139741
[50]	valid_0's auc: 0.882828	valid_0's binary_logloss: 0.120853	valid_1's auc: 0.838244	valid_1's binary_logloss: 0.139759
[51]	valid_0's auc: 0.883154	valid_0's binary_logloss: 0.120688	valid_1's auc: 0.838222	valid_1's binary_logloss: 0.139803
[52]	valid_0's auc: 0.883348	valid_0's binary_logloss: 0.120567	valid_1's auc: 0.838064	valid_1's binary_logloss: 0.139824
[53]	valid_0's auc: 0.883583	valid_0's binary_logloss: 0.120424	valid_1's auc: 0.83788	valid_1's binary_logloss: 0.139844
[54]	valid_0's auc: 0.884106	valid_0's binary_logloss: 0.120208	valid_1's auc: 0.837625	valid_1's binary_logloss: 0.139886
[55]	valid_0's auc: 0.884777	valid_0's binary_logloss: 0.120039	valid_1's auc: 0.837585	valid_1's binary_logloss: 0.139902
[56]	valid_0's auc: 0.88511	valid_0's binary_logloss: 0.11989	valid_1's auc: 0.837646	valid_1's binary_logloss: 0.139926
[57]	valid_0's auc: 0.885365	valid_0's binary_logloss: 0.11975	valid_1's auc: 0.837639	valid_1's binary_logloss: 0.139934
[58]	valid_0's auc: 0.885606	valid_0's binary_logloss: 0.119595	valid_1's auc: 0.837726	valid_1's binary_logloss: 0.139938
[59]	valid_0's auc: 0.885965	valid_0's binary_logloss: 0.119403	valid_1's auc: 0.837558	valid_1's binary_logloss: 0.140007
[60]	valid_0's auc: 0.886208	valid_0's binary_logloss: 0.119263	valid_1's auc: 0.83744	valid_1's binary_logloss: 0.140079
[61]	valid_0's auc: 0.886458	valid_0's binary_logloss: 0.119118	valid_1's auc: 0.837349	valid_1's binary_logloss: 0.140059
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.824873	valid_0's binary_logloss: 0.156222	valid_1's auc: 0.817791	valid_1's binary_logloss: 0.165072
[2]	valid_0's auc: 0.828725	valid_0's binary_logloss: 0.151244	valid_1's auc: 0.822586	valid_1's binary_logloss: 0.160253
[3]	valid_0's auc: 0.83594	valid_0's binary_logloss: 0.147423	valid_1's auc: 0.828474	valid_1's binary_logloss: 0.156542
[4]	valid_0's auc: 0.839489	valid_0's binary_logloss: 0.144426	valid_1's auc: 0.831396	valid_1's binary_logloss: 0.153706
[5]	valid_0's auc: 0.843358	valid_0's binary_logloss: 0.142067	valid_1's auc: 0.833466	valid_1's binary_logloss: 0.151399
[6]	valid_0's auc: 0.845601	valid_0's binary_logloss: 0.14009	valid_1's auc: 0.833857	valid_1's binary_logloss: 0.149488
[7]	valid_0's auc: 0.846477	valid_0's binary_logloss: 0.138491	valid_1's auc: 0.833143	valid_1's binary_logloss: 0.148023
[8]	valid_0's auc: 0.847725	valid_0's binary_logloss: 0.137129	valid_1's auc: 0.833971	valid_1's binary_logloss: 0.146757
[9]	valid_0's auc: 0.848442	valid_0's binary_logloss: 0.135908	valid_1's auc: 0.835976	valid_1's binary_logloss: 0.145685
[10]	valid_0's auc: 0.849759	valid_0's binary_logloss: 0.134781	valid_1's auc: 0.836214	valid_1's binary_logloss: 0.144769
[11]	valid_0's auc: 0.852238	valid_0's binary_logloss: 0.133835	valid_1's auc: 0.837243	valid_1's binary_logloss: 0.143925
[12]	valid_0's auc: 0.853743	valid_0's binary_logloss: 0.132972	valid_1's auc: 0.836647	valid_1's binary_logloss: 0.143391
[13]	valid_0's auc: 0.854568	valid_0's binary_logloss: 0.132256	valid_1's auc: 0.837182	valid_1's binary_logloss: 0.142849
[14]	valid_0's auc: 0.855928	valid_0's binary_logloss: 0.131554	valid_1's auc: 0.835941	valid_1's binary_logloss: 0.142474
[15]	valid_0's auc: 0.85712	valid_0's binary_logloss: 0.130984	valid_1's auc: 0.834938	valid_1's binary_logloss: 0.142198
[16]	valid_0's auc: 0.858721	valid_0's binary_logloss: 0.130371	valid_1's auc: 0.83561	valid_1's binary_logloss: 0.141802
[17]	valid_0's auc: 0.859281	valid_0's binary_logloss: 0.129877	valid_1's auc: 0.835146	valid_1's binary_logloss: 0.141605
[18]	valid_0's auc: 0.859881	valid_0's binary_logloss: 0.129417	valid_1's auc: 0.835386	valid_1's binary_logloss: 0.14132
[19]	valid_0's auc: 0.861409	valid_0's binary_logloss: 0.128929	valid_1's auc: 0.834974	valid_1's binary_logloss: 0.141151
[20]	valid_0's auc: 0.862574	valid_0's binary_logloss: 0.128458	valid_1's auc: 0.834949	valid_1's binary_logloss: 0.140968
[21]	valid_0's auc: 0.863262	valid_0's binary_logloss: 0.128069	valid_1's auc: 0.834616	valid_1's binary_logloss: 0.14086
[22]	valid_0's auc: 0.864655	valid_0's binary_logloss: 0.127684	valid_1's auc: 0.834363	valid_1's binary_logloss: 0.140766
[23]	valid_0's auc: 0.865247	valid_0's binary_logloss: 0.127349	valid_1's auc: 0.834317	valid_1's binary_logloss: 0.140688
[24]	valid_0's auc: 0.865882	valid_0's binary_logloss: 0.12704	valid_1's auc: 0.833543	valid_1's binary_logloss: 0.14068
[25]	valid_0's auc: 0.867496	valid_0's binary_logloss: 0.126629	valid_1's auc: 0.834195	valid_1's binary_logloss: 0.140539
[26]	valid_0's auc: 0.867923	valid_0's binary_logloss: 0.126353	valid_1's auc: 0.834028	valid_1's binary_logloss: 0.140506
[27]	valid_0's auc: 0.868685	valid_0's binary_logloss: 0.126058	valid_1's auc: 0.834718	valid_1's binary_logloss: 0.140359
[28]	valid_0's auc: 0.869304	valid_0's binary_logloss: 0.125764	valid_1's auc: 0.834935	valid_1's binary_logloss: 0.140287
[29]	valid_0's auc: 0.870037	valid_0's binary_logloss: 0.125514	valid_1's auc: 0.834481	valid_1's binary_logloss: 0.140258
[30]	valid_0's auc: 0.870785	valid_0's binary_logloss: 0.125254	valid_1's auc: 0.834179	valid_1's binary_logloss: 0.140275
[31]	valid_0's auc: 0.871706	valid_0's binary_logloss: 0.124992	valid_1's auc: 0.834475	valid_1's binary_logloss: 0.140205
[32]	valid_0's auc: 0.872582	valid_0's binary_logloss: 0.124728	valid_1's auc: 0.834353	valid_1's binary_logloss: 0.140189
[33]	valid_0's auc: 0.873445	valid_0's binary_logloss: 0.124481	valid_1's auc: 0.834592	valid_1's binary_logloss: 0.140082
[34]	valid_0's auc: 0.874095	valid_0's binary_logloss: 0.12426	valid_1's auc: 0.83436	valid_1's binary_logloss: 0.140101
[35]	valid_0's auc: 0.874869	valid_0's binary_logloss: 0.123982	valid_1's auc: 0.834045	valid_1's binary_logloss: 0.140151
[36]	valid_0's auc: 0.875446	valid_0's binary_logloss: 0.123753	valid_1's auc: 0.834073	valid_1's binary_logloss: 0.140125
[37]	valid_0's auc: 0.875763	valid_0's binary_logloss: 0.123587	valid_1's auc: 0.833611	valid_1's binary_logloss: 0.140201
[38]	valid_0's auc: 0.876603	valid_0's binary_logloss: 0.123335	valid_1's auc: 0.833805	valid_1's binary_logloss: 0.140159
[39]	valid_0's auc: 0.877126	valid_0's binary_logloss: 0.123134	valid_1's auc: 0.834422	valid_1's binary_logloss: 0.140048
[40]	valid_0's auc: 0.877575	valid_0's binary_logloss: 0.123013	valid_1's auc: 0.834343	valid_1's binary_logloss: 0.140069
[41]	valid_0's auc: 0.87809	valid_0's binary_logloss: 0.122813	valid_1's auc: 0.834199	valid_1's binary_logloss: 0.140085
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.821831	valid_0's binary_logloss: 0.156466	valid_1's auc: 0.817525	valid_1's binary_logloss: 0.165186
[2]	valid_0's auc: 0.831974	valid_0's binary_logloss: 0.151137	valid_1's auc: 0.82532	valid_1's binary_logloss: 0.159691
[3]	valid_0's auc: 0.839496	valid_0's binary_logloss: 0.14733	valid_1's auc: 0.831946	valid_1's binary_logloss: 0.156
[4]	valid_0's auc: 0.843984	valid_0's binary_logloss: 0.144371	valid_1's auc: 0.834064	valid_1's binary_logloss: 0.153082
[5]	valid_0's auc: 0.845854	valid_0's binary_logloss: 0.142024	valid_1's auc: 0.836918	valid_1's binary_logloss: 0.150735
[6]	valid_0's auc: 0.848041	valid_0's binary_logloss: 0.140009	valid_1's auc: 0.838831	valid_1's binary_logloss: 0.148771
[7]	valid_0's auc: 0.849655	valid_0's binary_logloss: 0.138307	valid_1's auc: 0.839111	valid_1's binary_logloss: 0.147373
[8]	valid_0's auc: 0.85185	valid_0's binary_logloss: 0.136891	valid_1's auc: 0.838955	valid_1's binary_logloss: 0.146094
[9]	valid_0's auc: 0.853067	valid_0's binary_logloss: 0.135655	valid_1's auc: 0.838081	valid_1's binary_logloss: 0.14516
[10]	valid_0's auc: 0.853922	valid_0's binary_logloss: 0.134622	valid_1's auc: 0.837333	valid_1's binary_logloss: 0.144318
[11]	valid_0's auc: 0.854729	valid_0's binary_logloss: 0.133702	valid_1's auc: 0.83725	valid_1's binary_logloss: 0.143512
[12]	valid_0's auc: 0.856303	valid_0's binary_logloss: 0.132789	valid_1's auc: 0.837602	valid_1's binary_logloss: 0.142833
[13]	valid_0's auc: 0.857206	valid_0's binary_logloss: 0.132038	valid_1's auc: 0.837364	valid_1's binary_logloss: 0.142245
[14]	valid_0's auc: 0.858161	valid_0's binary_logloss: 0.131391	valid_1's auc: 0.83777	valid_1's binary_logloss: 0.141759
[15]	valid_0's auc: 0.858975	valid_0's binary_logloss: 0.130772	valid_1's auc: 0.837831	valid_1's binary_logloss: 0.14139
[16]	valid_0's auc: 0.859623	valid_0's binary_logloss: 0.130219	valid_1's auc: 0.837953	valid_1's binary_logloss: 0.141016
[17]	valid_0's auc: 0.860576	valid_0's binary_logloss: 0.129684	valid_1's auc: 0.837985	valid_1's binary_logloss: 0.140713
[18]	valid_0's auc: 0.861311	valid_0's binary_logloss: 0.129202	valid_1's auc: 0.83796	valid_1's binary_logloss: 0.140452
[19]	valid_0's auc: 0.862347	valid_0's binary_logloss: 0.128715	valid_1's auc: 0.838506	valid_1's binary_logloss: 0.140189
[20]	valid_0's auc: 0.86305	valid_0's binary_logloss: 0.128312	valid_1's auc: 0.837702	valid_1's binary_logloss: 0.140094
[21]	valid_0's auc: 0.863758	valid_0's binary_logloss: 0.127907	valid_1's auc: 0.838127	valid_1's binary_logloss: 0.139858
[22]	valid_0's auc: 0.864635	valid_0's binary_logloss: 0.127525	valid_1's auc: 0.838331	valid_1's binary_logloss: 0.139696
[23]	valid_0's auc: 0.865866	valid_0's binary_logloss: 0.127143	valid_1's auc: 0.837841	valid_1's binary_logloss: 0.139625
[24]	valid_0's auc: 0.867054	valid_0's binary_logloss: 0.126749	valid_1's auc: 0.838187	valid_1's binary_logloss: 0.139526
[25]	valid_0's auc: 0.867553	valid_0's binary_logloss: 0.126476	valid_1's auc: 0.838308	valid_1's binary_logloss: 0.13949
[26]	valid_0's auc: 0.868108	valid_0's binary_logloss: 0.126164	valid_1's auc: 0.838035	valid_1's binary_logloss: 0.139426
[27]	valid_0's auc: 0.869014	valid_0's binary_logloss: 0.125868	valid_1's auc: 0.837545	valid_1's binary_logloss: 0.139445
[28]	valid_0's auc: 0.869797	valid_0's binary_logloss: 0.12559	valid_1's auc: 0.837894	valid_1's binary_logloss: 0.139419
[29]	valid_0's auc: 0.870435	valid_0's binary_logloss: 0.1253	valid_1's auc: 0.838103	valid_1's binary_logloss: 0.139321
[30]	valid_0's auc: 0.87141	valid_0's binary_logloss: 0.125025	valid_1's auc: 0.838164	valid_1's binary_logloss: 0.139275
[31]	valid_0's auc: 0.872143	valid_0's binary_logloss: 0.124769	valid_1's auc: 0.837843	valid_1's binary_logloss: 0.139285
[32]	valid_0's auc: 0.872606	valid_0's binary_logloss: 0.124561	valid_1's auc: 0.837662	valid_1's binary_logloss: 0.139274
[33]	valid_0's auc: 0.873337	valid_0's binary_logloss: 0.124346	valid_1's auc: 0.837661	valid_1's binary_logloss: 0.139284
[34]	valid_0's auc: 0.873965	valid_0's binary_logloss: 0.124108	valid_1's auc: 0.837639	valid_1's binary_logloss: 0.139263
[35]	valid_0's auc: 0.87457	valid_0's binary_logloss: 0.123857	valid_1's auc: 0.838159	valid_1's binary_logloss: 0.139137
[36]	valid_0's auc: 0.874973	valid_0's binary_logloss: 0.123651	valid_1's auc: 0.838114	valid_1's binary_logloss: 0.139148
[37]	valid_0's auc: 0.875657	valid_0's binary_logloss: 0.123447	valid_1's auc: 0.838519	valid_1's binary_logloss: 0.139109
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.821427	valid_0's binary_logloss: 0.156592	valid_1's auc: 0.81711	valid_1's binary_logloss: 0.165273
[2]	valid_0's auc: 0.827893	valid_0's binary_logloss: 0.151336	valid_1's auc: 0.820533	valid_1's binary_logloss: 0.160243
[3]	valid_0's auc: 0.83753	valid_0's binary_logloss: 0.147487	valid_1's auc: 0.82841	valid_1's binary_logloss: 0.156547
[4]	valid_0's auc: 0.84038	valid_0's binary_logloss: 0.144428	valid_1's auc: 0.8313	valid_1's binary_logloss: 0.153575
[5]	valid_0's auc: 0.842945	valid_0's binary_logloss: 0.142089	valid_1's auc: 0.833579	valid_1's binary_logloss: 0.151354
[6]	valid_0's auc: 0.843246	valid_0's binary_logloss: 0.140186	valid_1's auc: 0.833781	valid_1's binary_logloss: 0.14953
[7]	valid_0's auc: 0.844301	valid_0's binary_logloss: 0.138471	valid_1's auc: 0.834317	valid_1's binary_logloss: 0.147954
[8]	valid_0's auc: 0.846945	valid_0's binary_logloss: 0.137078	valid_1's auc: 0.834895	valid_1's binary_logloss: 0.146786
[9]	valid_0's auc: 0.849381	valid_0's binary_logloss: 0.135906	valid_1's auc: 0.834922	valid_1's binary_logloss: 0.145762
[10]	valid_0's auc: 0.850944	valid_0's binary_logloss: 0.134855	valid_1's auc: 0.835441	valid_1's binary_logloss: 0.144958
[11]	valid_0's auc: 0.852557	valid_0's binary_logloss: 0.133895	valid_1's auc: 0.835103	valid_1's binary_logloss: 0.144293
[12]	valid_0's auc: 0.854609	valid_0's binary_logloss: 0.133013	valid_1's auc: 0.835686	valid_1's binary_logloss: 0.143793
[13]	valid_0's auc: 0.855817	valid_0's binary_logloss: 0.132247	valid_1's auc: 0.835296	valid_1's binary_logloss: 0.143302
[14]	valid_0's auc: 0.857501	valid_0's binary_logloss: 0.131545	valid_1's auc: 0.836432	valid_1's binary_logloss: 0.142761
[15]	valid_0's auc: 0.858907	valid_0's binary_logloss: 0.130878	valid_1's auc: 0.836329	valid_1's binary_logloss: 0.142383
[16]	valid_0's auc: 0.859887	valid_0's binary_logloss: 0.130287	valid_1's auc: 0.836611	valid_1's binary_logloss: 0.141883
[17]	valid_0's auc: 0.860889	valid_0's binary_logloss: 0.129757	valid_1's auc: 0.836848	valid_1's binary_logloss: 0.141535
[18]	valid_0's auc: 0.861827	valid_0's binary_logloss: 0.129301	valid_1's auc: 0.837106	valid_1's binary_logloss: 0.141257
[19]	valid_0's auc: 0.862972	valid_0's binary_logloss: 0.128826	valid_1's auc: 0.837185	valid_1's binary_logloss: 0.141043
[20]	valid_0's auc: 0.864083	valid_0's binary_logloss: 0.128369	valid_1's auc: 0.837509	valid_1's binary_logloss: 0.140794
[21]	valid_0's auc: 0.864747	valid_0's binary_logloss: 0.127959	valid_1's auc: 0.837888	valid_1's binary_logloss: 0.140626
[22]	valid_0's auc: 0.865769	valid_0's binary_logloss: 0.127562	valid_1's auc: 0.837811	valid_1's binary_logloss: 0.140487
[23]	valid_0's auc: 0.866657	valid_0's binary_logloss: 0.127217	valid_1's auc: 0.837884	valid_1's binary_logloss: 0.140328
[24]	valid_0's auc: 0.867293	valid_0's binary_logloss: 0.126875	valid_1's auc: 0.838481	valid_1's binary_logloss: 0.140215
[25]	valid_0's auc: 0.867983	valid_0's binary_logloss: 0.126562	valid_1's auc: 0.838239	valid_1's binary_logloss: 0.140124
[26]	valid_0's auc: 0.868559	valid_0's binary_logloss: 0.126248	valid_1's auc: 0.837903	valid_1's binary_logloss: 0.140092
[27]	valid_0's auc: 0.869394	valid_0's binary_logloss: 0.125936	valid_1's auc: 0.837493	valid_1's binary_logloss: 0.14006
[28]	valid_0's auc: 0.87048	valid_0's binary_logloss: 0.125677	valid_1's auc: 0.837623	valid_1's binary_logloss: 0.140007
[29]	valid_0's auc: 0.87105	valid_0's binary_logloss: 0.125405	valid_1's auc: 0.838216	valid_1's binary_logloss: 0.13986
[30]	valid_0's auc: 0.871749	valid_0's binary_logloss: 0.125147	valid_1's auc: 0.838898	valid_1's binary_logloss: 0.139742
[31]	valid_0's auc: 0.87247	valid_0's binary_logloss: 0.124907	valid_1's auc: 0.838959	valid_1's binary_logloss: 0.139727
[32]	valid_0's auc: 0.87282	valid_0's binary_logloss: 0.124724	valid_1's auc: 0.838675	valid_1's binary_logloss: 0.139761
[33]	valid_0's auc: 0.874106	valid_0's binary_logloss: 0.124412	valid_1's auc: 0.838893	valid_1's binary_logloss: 0.139687
[34]	valid_0's auc: 0.874887	valid_0's binary_logloss: 0.124169	valid_1's auc: 0.838801	valid_1's binary_logloss: 0.139672
[35]	valid_0's auc: 0.875447	valid_0's binary_logloss: 0.123934	valid_1's auc: 0.838835	valid_1's binary_logloss: 0.139667
[36]	valid_0's auc: 0.87617	valid_0's binary_logloss: 0.123693	valid_1's auc: 0.838505	valid_1's binary_logloss: 0.139699
[37]	valid_0's auc: 0.876793	valid_0's binary_logloss: 0.12346	valid_1's auc: 0.838104	valid_1's binary_logloss: 0.139783
[38]	valid_0's auc: 0.877265	valid_0's binary_logloss: 0.123251	valid_1's auc: 0.838267	valid_1's binary_logloss: 0.139787
[39]	valid_0's auc: 0.877869	valid_0's binary_logloss: 0.123018	valid_1's auc: 0.838004	valid_1's binary_logloss: 0.139806
[40]	valid_0's auc: 0.878509	valid_0's binary_logloss: 0.122803	valid_1's auc: 0.838086	valid_1's binary_logloss: 0.139745
[41]	valid_0's auc: 0.879077	valid_0's binary_logloss: 0.122585	valid_1's auc: 0.838538	valid_1's binary_logloss: 0.139694
[42]	valid_0's auc: 0.879515	valid_0's binary_logloss: 0.122368	valid_1's auc: 0.838647	valid_1's binary_logloss: 0.139655
[43]	valid_0's auc: 0.879985	valid_0's binary_logloss: 0.122166	valid_1's auc: 0.838495	valid_1's binary_logloss: 0.139653
[44]	valid_0's auc: 0.88041	valid_0's binary_logloss: 0.121985	valid_1's auc: 0.838221	valid_1's binary_logloss: 0.139755
[45]	valid_0's auc: 0.880907	valid_0's binary_logloss: 0.121777	valid_1's auc: 0.837981	valid_1's binary_logloss: 0.139769
[46]	valid_0's auc: 0.881216	valid_0's binary_logloss: 0.121594	valid_1's auc: 0.838471	valid_1's binary_logloss: 0.139693
[47]	valid_0's auc: 0.881591	valid_0's binary_logloss: 0.121422	valid_1's auc: 0.83861	valid_1's binary_logloss: 0.139687
[48]	valid_0's auc: 0.881867	valid_0's binary_logloss: 0.121266	valid_1's auc: 0.838593	valid_1's binary_logloss: 0.139682
[49]	valid_0's auc: 0.882285	valid_0's binary_logloss: 0.121041	valid_1's auc: 0.838317	valid_1's binary_logloss: 0.139741
[50]	valid_0's auc: 0.882828	valid_0's binary_logloss: 0.120853	valid_1's auc: 0.838244	valid_1's binary_logloss: 0.139759
[51]	valid_0's auc: 0.883154	valid_0's binary_logloss: 0.120688	valid_1's auc: 0.838222	valid_1's binary_logloss: 0.139803
[52]	valid_0's auc: 0.883348	valid_0's binary_logloss: 0.120567	valid_1's auc: 0.838064	valid_1's binary_logloss: 0.139824
[53]	valid_0's auc: 0.883583	valid_0's binary_logloss: 0.120424	valid_1's auc: 0.83788	valid_1's binary_logloss: 0.139844
[54]	valid_0's auc: 0.884106	valid_0's binary_logloss: 0.120208	valid_1's auc: 0.837625	valid_1's binary_logloss: 0.139886
[55]	valid_0's auc: 0.884777	valid_0's binary_logloss: 0.120039	valid_1's auc: 0.837585	valid_1's binary_logloss: 0.139902
[56]	valid_0's auc: 0.88511	valid_0's binary_logloss: 0.11989	valid_1's auc: 0.837646	valid_1's binary_logloss: 0.139926
[57]	valid_0's auc: 0.885365	valid_0's binary_logloss: 0.11975	valid_1's auc: 0.837639	valid_1's binary_logloss: 0.139934
[58]	valid_0's auc: 0.885606	valid_0's binary_logloss: 0.119595	valid_1's auc: 0.837726	valid_1's binary_logloss: 0.139938
[59]	valid_0's auc: 0.885965	valid_0's binary_logloss: 0.119403	valid_1's auc: 0.837558	valid_1's binary_logloss: 0.140007
[60]	valid_0's auc: 0.886208	valid_0's binary_logloss: 0.119263	valid_1's auc: 0.83744	valid_1's binary_logloss: 0.140079
[61]	valid_0's auc: 0.886458	valid_0's binary_logloss: 0.119118	valid_1's auc: 0.837349	valid_1's binary_logloss: 0.140059
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.835412	valid_0's binary_logloss: 0.155721	valid_1's auc: 0.81973	valid_1's binary_logloss: 0.164844
[2]	valid_0's auc: 0.841188	valid_0's binary_logloss: 0.150354	valid_1's auc: 0.823402	valid_1's binary_logloss: 0.16006
[3]	valid_0's auc: 0.846758	valid_0's binary_logloss: 0.146288	valid_1's auc: 0.824811	valid_1's binary_logloss: 0.15621
[4]	valid_0's auc: 0.850398	valid_0's binary_logloss: 0.143088	valid_1's auc: 0.830278	valid_1's binary_logloss: 0.153352
[5]	valid_0's auc: 0.853086	valid_0's binary_logloss: 0.140514	valid_1's auc: 0.833574	valid_1's binary_logloss: 0.151071
[6]	valid_0's auc: 0.855915	valid_0's binary_logloss: 0.138329	valid_1's auc: 0.834881	valid_1's binary_logloss: 0.149277
[7]	valid_0's auc: 0.858115	valid_0's binary_logloss: 0.136481	valid_1's auc: 0.833603	valid_1's binary_logloss: 0.14786
[8]	valid_0's auc: 0.859479	valid_0's binary_logloss: 0.134947	valid_1's auc: 0.834093	valid_1's binary_logloss: 0.146607
[9]	valid_0's auc: 0.86143	valid_0's binary_logloss: 0.133519	valid_1's auc: 0.833898	valid_1's binary_logloss: 0.14559
[10]	valid_0's auc: 0.862964	valid_0's binary_logloss: 0.132331	valid_1's auc: 0.835026	valid_1's binary_logloss: 0.144789
[11]	valid_0's auc: 0.864277	valid_0's binary_logloss: 0.13126	valid_1's auc: 0.834957	valid_1's binary_logloss: 0.144152
[12]	valid_0's auc: 0.865572	valid_0's binary_logloss: 0.130304	valid_1's auc: 0.833693	valid_1's binary_logloss: 0.143697
[13]	valid_0's auc: 0.867519	valid_0's binary_logloss: 0.129385	valid_1's auc: 0.833158	valid_1's binary_logloss: 0.143184
[14]	valid_0's auc: 0.869354	valid_0's binary_logloss: 0.128524	valid_1's auc: 0.833598	valid_1's binary_logloss: 0.142668
[15]	valid_0's auc: 0.870553	valid_0's binary_logloss: 0.127746	valid_1's auc: 0.833467	valid_1's binary_logloss: 0.142302
[16]	valid_0's auc: 0.871816	valid_0's binary_logloss: 0.126943	valid_1's auc: 0.83329	valid_1's binary_logloss: 0.142022
[17]	valid_0's auc: 0.872964	valid_0's binary_logloss: 0.126266	valid_1's auc: 0.83279	valid_1's binary_logloss: 0.141891
[18]	valid_0's auc: 0.874047	valid_0's binary_logloss: 0.125646	valid_1's auc: 0.831917	valid_1's binary_logloss: 0.141748
[19]	valid_0's auc: 0.875336	valid_0's binary_logloss: 0.125072	valid_1's auc: 0.831274	valid_1's binary_logloss: 0.141658
[20]	valid_0's auc: 0.876959	valid_0's binary_logloss: 0.124484	valid_1's auc: 0.831275	valid_1's binary_logloss: 0.141511
[21]	valid_0's auc: 0.878049	valid_0's binary_logloss: 0.123928	valid_1's auc: 0.830813	valid_1's binary_logloss: 0.141459
[22]	valid_0's auc: 0.878905	valid_0's binary_logloss: 0.123447	valid_1's auc: 0.83012	valid_1's binary_logloss: 0.141449
[23]	valid_0's auc: 0.879827	valid_0's binary_logloss: 0.12295	valid_1's auc: 0.829554	valid_1's binary_logloss: 0.141492
[24]	valid_0's auc: 0.880692	valid_0's binary_logloss: 0.122479	valid_1's auc: 0.829256	valid_1's binary_logloss: 0.141487
[25]	valid_0's auc: 0.881715	valid_0's binary_logloss: 0.121994	valid_1's auc: 0.829326	valid_1's binary_logloss: 0.141362
[26]	valid_0's auc: 0.883014	valid_0's binary_logloss: 0.121527	valid_1's auc: 0.829553	valid_1's binary_logloss: 0.14132
[27]	valid_0's auc: 0.884245	valid_0's binary_logloss: 0.121024	valid_1's auc: 0.829624	valid_1's binary_logloss: 0.14127
[28]	valid_0's auc: 0.885238	valid_0's binary_logloss: 0.12058	valid_1's auc: 0.829417	valid_1's binary_logloss: 0.141237
[29]	valid_0's auc: 0.88602	valid_0's binary_logloss: 0.120198	valid_1's auc: 0.82917	valid_1's binary_logloss: 0.141201
[30]	valid_0's auc: 0.88684	valid_0's binary_logloss: 0.119831	valid_1's auc: 0.82962	valid_1's binary_logloss: 0.141121
[31]	valid_0's auc: 0.887965	valid_0's binary_logloss: 0.119437	valid_1's auc: 0.83035	valid_1's binary_logloss: 0.14101
[32]	valid_0's auc: 0.88868	valid_0's binary_logloss: 0.119086	valid_1's auc: 0.82975	valid_1's binary_logloss: 0.141093
[33]	valid_0's auc: 0.889895	valid_0's binary_logloss: 0.118649	valid_1's auc: 0.829977	valid_1's binary_logloss: 0.141037
[34]	valid_0's auc: 0.890626	valid_0's binary_logloss: 0.118328	valid_1's auc: 0.829368	valid_1's binary_logloss: 0.141161
[35]	valid_0's auc: 0.89116	valid_0's binary_logloss: 0.11806	valid_1's auc: 0.829262	valid_1's binary_logloss: 0.141183
[36]	valid_0's auc: 0.891999	valid_0's binary_logloss: 0.11775	valid_1's auc: 0.828947	valid_1's binary_logloss: 0.14129
[37]	valid_0's auc: 0.892306	valid_0's binary_logloss: 0.117477	valid_1's auc: 0.828544	valid_1's binary_logloss: 0.141389
[38]	valid_0's auc: 0.892937	valid_0's binary_logloss: 0.117192	valid_1's auc: 0.827983	valid_1's binary_logloss: 0.141516
[39]	valid_0's auc: 0.893563	valid_0's binary_logloss: 0.116869	valid_1's auc: 0.828068	valid_1's binary_logloss: 0.141517
[40]	valid_0's auc: 0.893942	valid_0's binary_logloss: 0.11662	valid_1's auc: 0.827852	valid_1's binary_logloss: 0.141621
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.830474	valid_0's binary_logloss: 0.155928	valid_1's auc: 0.817343	valid_1's binary_logloss: 0.164928
[2]	valid_0's auc: 0.842931	valid_0's binary_logloss: 0.1503	valid_1's auc: 0.82699	valid_1's binary_logloss: 0.15948
[3]	valid_0's auc: 0.850877	valid_0's binary_logloss: 0.14631	valid_1's auc: 0.832212	valid_1's binary_logloss: 0.155775
[4]	valid_0's auc: 0.854431	valid_0's binary_logloss: 0.143104	valid_1's auc: 0.83392	valid_1's binary_logloss: 0.152698
[5]	valid_0's auc: 0.85663	valid_0's binary_logloss: 0.140582	valid_1's auc: 0.835094	valid_1's binary_logloss: 0.150349
[6]	valid_0's auc: 0.859142	valid_0's binary_logloss: 0.138289	valid_1's auc: 0.836166	valid_1's binary_logloss: 0.148424
[7]	valid_0's auc: 0.861364	valid_0's binary_logloss: 0.136413	valid_1's auc: 0.837184	valid_1's binary_logloss: 0.146912
[8]	valid_0's auc: 0.862199	valid_0's binary_logloss: 0.134841	valid_1's auc: 0.837545	valid_1's binary_logloss: 0.145726
[9]	valid_0's auc: 0.864095	valid_0's binary_logloss: 0.133364	valid_1's auc: 0.837242	valid_1's binary_logloss: 0.144736
[10]	valid_0's auc: 0.866024	valid_0's binary_logloss: 0.132096	valid_1's auc: 0.837719	valid_1's binary_logloss: 0.143766
[11]	valid_0's auc: 0.867454	valid_0's binary_logloss: 0.131002	valid_1's auc: 0.837865	valid_1's binary_logloss: 0.143009
[12]	valid_0's auc: 0.868329	valid_0's binary_logloss: 0.130024	valid_1's auc: 0.837259	valid_1's binary_logloss: 0.14244
[13]	valid_0's auc: 0.869137	valid_0's binary_logloss: 0.129145	valid_1's auc: 0.837689	valid_1's binary_logloss: 0.141896
[14]	valid_0's auc: 0.870957	valid_0's binary_logloss: 0.128226	valid_1's auc: 0.838226	valid_1's binary_logloss: 0.141392
[15]	valid_0's auc: 0.872273	valid_0's binary_logloss: 0.12745	valid_1's auc: 0.837906	valid_1's binary_logloss: 0.141019
[16]	valid_0's auc: 0.873243	valid_0's binary_logloss: 0.12672	valid_1's auc: 0.837761	valid_1's binary_logloss: 0.140677
[17]	valid_0's auc: 0.874251	valid_0's binary_logloss: 0.126044	valid_1's auc: 0.83701	valid_1's binary_logloss: 0.140582
[18]	valid_0's auc: 0.875622	valid_0's binary_logloss: 0.125387	valid_1's auc: 0.836179	valid_1's binary_logloss: 0.140485
[19]	valid_0's auc: 0.877031	valid_0's binary_logloss: 0.124759	valid_1's auc: 0.836188	valid_1's binary_logloss: 0.14029
[20]	valid_0's auc: 0.878046	valid_0's binary_logloss: 0.124156	valid_1's auc: 0.836531	valid_1's binary_logloss: 0.140133
[21]	valid_0's auc: 0.879478	valid_0's binary_logloss: 0.123507	valid_1's auc: 0.837068	valid_1's binary_logloss: 0.13995
[22]	valid_0's auc: 0.880423	valid_0's binary_logloss: 0.123029	valid_1's auc: 0.836817	valid_1's binary_logloss: 0.139912
[23]	valid_0's auc: 0.881684	valid_0's binary_logloss: 0.122492	valid_1's auc: 0.836983	valid_1's binary_logloss: 0.139762
[24]	valid_0's auc: 0.882873	valid_0's binary_logloss: 0.121986	valid_1's auc: 0.837319	valid_1's binary_logloss: 0.139659
[25]	valid_0's auc: 0.883597	valid_0's binary_logloss: 0.121566	valid_1's auc: 0.837154	valid_1's binary_logloss: 0.139623
[26]	valid_0's auc: 0.884814	valid_0's binary_logloss: 0.121104	valid_1's auc: 0.836302	valid_1's binary_logloss: 0.139668
[27]	valid_0's auc: 0.886026	valid_0's binary_logloss: 0.120635	valid_1's auc: 0.836521	valid_1's binary_logloss: 0.139601
[28]	valid_0's auc: 0.887071	valid_0's binary_logloss: 0.120222	valid_1's auc: 0.836646	valid_1's binary_logloss: 0.139557
[29]	valid_0's auc: 0.887946	valid_0's binary_logloss: 0.119804	valid_1's auc: 0.836735	valid_1's binary_logloss: 0.139518
[30]	valid_0's auc: 0.88898	valid_0's binary_logloss: 0.119416	valid_1's auc: 0.836858	valid_1's binary_logloss: 0.139499
[31]	valid_0's auc: 0.889792	valid_0's binary_logloss: 0.119058	valid_1's auc: 0.836917	valid_1's binary_logloss: 0.139463
[32]	valid_0's auc: 0.890876	valid_0's binary_logloss: 0.118631	valid_1's auc: 0.836346	valid_1's binary_logloss: 0.139532
[33]	valid_0's auc: 0.891629	valid_0's binary_logloss: 0.118259	valid_1's auc: 0.836206	valid_1's binary_logloss: 0.139603
[34]	valid_0's auc: 0.892446	valid_0's binary_logloss: 0.117893	valid_1's auc: 0.836005	valid_1's binary_logloss: 0.139603
[35]	valid_0's auc: 0.893407	valid_0's binary_logloss: 0.11752	valid_1's auc: 0.8361	valid_1's binary_logloss: 0.139574
[36]	valid_0's auc: 0.893836	valid_0's binary_logloss: 0.117247	valid_1's auc: 0.836147	valid_1's binary_logloss: 0.139608
[37]	valid_0's auc: 0.894774	valid_0's binary_logloss: 0.116913	valid_1's auc: 0.836601	valid_1's binary_logloss: 0.139569
[38]	valid_0's auc: 0.895494	valid_0's binary_logloss: 0.116611	valid_1's auc: 0.836232	valid_1's binary_logloss: 0.139645
[39]	valid_0's auc: 0.896102	valid_0's binary_logloss: 0.116275	valid_1's auc: 0.836415	valid_1's binary_logloss: 0.139653
[40]	valid_0's auc: 0.896715	valid_0's binary_logloss: 0.115934	valid_1's auc: 0.836463	valid_1's binary_logloss: 0.139671
[41]	valid_0's auc: 0.897232	valid_0's binary_logloss: 0.115612	valid_1's auc: 0.836223	valid_1's binary_logloss: 0.139762
[42]	valid_0's auc: 0.897875	valid_0's binary_logloss: 0.11528	valid_1's auc: 0.836151	valid_1's binary_logloss: 0.139777
[43]	valid_0's auc: 0.898493	valid_0's binary_logloss: 0.114999	valid_1's auc: 0.836216	valid_1's binary_logloss: 0.139761
[44]	valid_0's auc: 0.899179	valid_0's binary_logloss: 0.114703	valid_1's auc: 0.836328	valid_1's binary_logloss: 0.139755
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.834724	valid_0's binary_logloss: 0.15607	valid_1's auc: 0.822983	valid_1's binary_logloss: 0.165104
[2]	valid_0's auc: 0.842835	valid_0's binary_logloss: 0.150494	valid_1's auc: 0.830472	valid_1's binary_logloss: 0.159671
[3]	valid_0's auc: 0.847187	valid_0's binary_logloss: 0.146306	valid_1's auc: 0.830873	valid_1's binary_logloss: 0.155985
[4]	valid_0's auc: 0.850394	valid_0's binary_logloss: 0.143088	valid_1's auc: 0.830975	valid_1's binary_logloss: 0.15321
[5]	valid_0's auc: 0.853379	valid_0's binary_logloss: 0.140508	valid_1's auc: 0.832135	valid_1's binary_logloss: 0.150854
[6]	valid_0's auc: 0.855463	valid_0's binary_logloss: 0.138297	valid_1's auc: 0.833116	valid_1's binary_logloss: 0.149013
[7]	valid_0's auc: 0.856723	valid_0's binary_logloss: 0.136504	valid_1's auc: 0.833811	valid_1's binary_logloss: 0.147577
[8]	valid_0's auc: 0.858076	valid_0's binary_logloss: 0.13495	valid_1's auc: 0.835315	valid_1's binary_logloss: 0.146273
[9]	valid_0's auc: 0.861024	valid_0's binary_logloss: 0.133583	valid_1's auc: 0.835042	valid_1's binary_logloss: 0.145374
[10]	valid_0's auc: 0.862281	valid_0's binary_logloss: 0.132357	valid_1's auc: 0.834154	valid_1's binary_logloss: 0.144649
[11]	valid_0's auc: 0.864612	valid_0's binary_logloss: 0.131283	valid_1's auc: 0.834587	valid_1's binary_logloss: 0.143941
[12]	valid_0's auc: 0.866377	valid_0's binary_logloss: 0.130299	valid_1's auc: 0.834242	valid_1's binary_logloss: 0.143366
[13]	valid_0's auc: 0.868343	valid_0's binary_logloss: 0.129417	valid_1's auc: 0.833273	valid_1's binary_logloss: 0.142976
[14]	valid_0's auc: 0.86957	valid_0's binary_logloss: 0.128593	valid_1's auc: 0.833783	valid_1's binary_logloss: 0.142567
[15]	valid_0's auc: 0.871109	valid_0's binary_logloss: 0.127759	valid_1's auc: 0.834057	valid_1's binary_logloss: 0.142234
[16]	valid_0's auc: 0.872893	valid_0's binary_logloss: 0.126996	valid_1's auc: 0.835329	valid_1's binary_logloss: 0.141809
[17]	valid_0's auc: 0.874236	valid_0's binary_logloss: 0.12631	valid_1's auc: 0.834985	valid_1's binary_logloss: 0.141613
[18]	valid_0's auc: 0.875324	valid_0's binary_logloss: 0.125725	valid_1's auc: 0.834942	valid_1's binary_logloss: 0.141363
[19]	valid_0's auc: 0.876659	valid_0's binary_logloss: 0.125068	valid_1's auc: 0.835024	valid_1's binary_logloss: 0.141162
[20]	valid_0's auc: 0.877885	valid_0's binary_logloss: 0.124484	valid_1's auc: 0.835893	valid_1's binary_logloss: 0.140933
[21]	valid_0's auc: 0.879121	valid_0's binary_logloss: 0.12391	valid_1's auc: 0.837029	valid_1's binary_logloss: 0.140651
[22]	valid_0's auc: 0.880116	valid_0's binary_logloss: 0.123339	valid_1's auc: 0.837366	valid_1's binary_logloss: 0.140547
[23]	valid_0's auc: 0.881224	valid_0's binary_logloss: 0.12282	valid_1's auc: 0.837357	valid_1's binary_logloss: 0.140445
[24]	valid_0's auc: 0.882014	valid_0's binary_logloss: 0.122386	valid_1's auc: 0.837343	valid_1's binary_logloss: 0.140371
[25]	valid_0's auc: 0.88318	valid_0's binary_logloss: 0.121861	valid_1's auc: 0.83723	valid_1's binary_logloss: 0.140313
[26]	valid_0's auc: 0.884008	valid_0's binary_logloss: 0.121441	valid_1's auc: 0.837761	valid_1's binary_logloss: 0.140173
[27]	valid_0's auc: 0.884676	valid_0's binary_logloss: 0.121001	valid_1's auc: 0.838046	valid_1's binary_logloss: 0.140086
[28]	valid_0's auc: 0.885524	valid_0's binary_logloss: 0.120598	valid_1's auc: 0.838029	valid_1's binary_logloss: 0.140051
[29]	valid_0's auc: 0.886461	valid_0's binary_logloss: 0.120157	valid_1's auc: 0.837775	valid_1's binary_logloss: 0.140057
[30]	valid_0's auc: 0.887053	valid_0's binary_logloss: 0.119807	valid_1's auc: 0.837472	valid_1's binary_logloss: 0.140111
[31]	valid_0's auc: 0.888177	valid_0's binary_logloss: 0.119425	valid_1's auc: 0.837575	valid_1's binary_logloss: 0.140093
[32]	valid_0's auc: 0.889072	valid_0's binary_logloss: 0.119055	valid_1's auc: 0.837158	valid_1's binary_logloss: 0.140195
[33]	valid_0's auc: 0.889782	valid_0's binary_logloss: 0.118676	valid_1's auc: 0.837296	valid_1's binary_logloss: 0.140221
[34]	valid_0's auc: 0.890876	valid_0's binary_logloss: 0.118304	valid_1's auc: 0.837481	valid_1's binary_logloss: 0.140165
[35]	valid_0's auc: 0.891448	valid_0's binary_logloss: 0.11798	valid_1's auc: 0.837953	valid_1's binary_logloss: 0.140085
[36]	valid_0's auc: 0.892165	valid_0's binary_logloss: 0.11764	valid_1's auc: 0.837794	valid_1's binary_logloss: 0.140112
[37]	valid_0's auc: 0.892798	valid_0's binary_logloss: 0.117321	valid_1's auc: 0.837291	valid_1's binary_logloss: 0.140221
[38]	valid_0's auc: 0.893318	valid_0's binary_logloss: 0.117028	valid_1's auc: 0.837278	valid_1's binary_logloss: 0.140221
[39]	valid_0's auc: 0.894018	valid_0's binary_logloss: 0.116742	valid_1's auc: 0.83724	valid_1's binary_logloss: 0.140232
[40]	valid_0's auc: 0.894781	valid_0's binary_logloss: 0.116373	valid_1's auc: 0.836901	valid_1's binary_logloss: 0.140328
[41]	valid_0's auc: 0.895222	valid_0's binary_logloss: 0.116075	valid_1's auc: 0.836655	valid_1's binary_logloss: 0.140422
[42]	valid_0's auc: 0.895842	valid_0's binary_logloss: 0.115755	valid_1's auc: 0.836383	valid_1's binary_logloss: 0.140503
[43]	valid_0's auc: 0.896389	valid_0's binary_logloss: 0.115503	valid_1's auc: 0.836348	valid_1's binary_logloss: 0.140505
[44]	valid_0's auc: 0.896843	valid_0's binary_logloss: 0.115204	valid_1's auc: 0.836521	valid_1's binary_logloss: 0.140518
[45]	valid_0's auc: 0.897272	valid_0's binary_logloss: 0.114886	valid_1's auc: 0.836311	valid_1's binary_logloss: 0.140581
[46]	valid_0's auc: 0.898034	valid_0's binary_logloss: 0.114544	valid_1's auc: 0.835871	valid_1's binary_logloss: 0.140663
[47]	valid_0's auc: 0.898562	valid_0's binary_logloss: 0.114262	valid_1's auc: 0.835926	valid_1's binary_logloss: 0.140642
[48]	valid_0's auc: 0.898919	valid_0's binary_logloss: 0.114006	valid_1's auc: 0.835849	valid_1's binary_logloss: 0.140687
[49]	valid_0's auc: 0.899111	valid_0's binary_logloss: 0.113791	valid_1's auc: 0.835874	valid_1's binary_logloss: 0.140728
[50]	valid_0's auc: 0.89987	valid_0's binary_logloss: 0.113543	valid_1's auc: 0.835915	valid_1's binary_logloss: 0.14075
[51]	valid_0's auc: 0.90004	valid_0's binary_logloss: 0.113342	valid_1's auc: 0.835947	valid_1's binary_logloss: 0.140748
[52]	valid_0's auc: 0.900405	valid_0's binary_logloss: 0.113087	valid_1's auc: 0.836011	valid_1's binary_logloss: 0.140767
[53]	valid_0's auc: 0.900828	valid_0's binary_logloss: 0.112831	valid_1's auc: 0.836259	valid_1's binary_logloss: 0.140771
[54]	valid_0's auc: 0.901597	valid_0's binary_logloss: 0.112604	valid_1's auc: 0.836296	valid_1's binary_logloss: 0.14078
[55]	valid_0's auc: 0.901645	valid_0's binary_logloss: 0.112429	valid_1's auc: 0.836095	valid_1's binary_logloss: 0.140822
[56]	valid_0's auc: 0.902162	valid_0's binary_logloss: 0.112169	valid_1's auc: 0.835965	valid_1's binary_logloss: 0.14086
[57]	valid_0's auc: 0.902422	valid_0's binary_logloss: 0.111944	valid_1's auc: 0.835493	valid_1's binary_logloss: 0.140993
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.835412	valid_0's binary_logloss: 0.155721	valid_1's auc: 0.81973	valid_1's binary_logloss: 0.164844
[2]	valid_0's auc: 0.841188	valid_0's binary_logloss: 0.150354	valid_1's auc: 0.823402	valid_1's binary_logloss: 0.16006
[3]	valid_0's auc: 0.846758	valid_0's binary_logloss: 0.146288	valid_1's auc: 0.824811	valid_1's binary_logloss: 0.15621
[4]	valid_0's auc: 0.850398	valid_0's binary_logloss: 0.143088	valid_1's auc: 0.830278	valid_1's binary_logloss: 0.153352
[5]	valid_0's auc: 0.853086	valid_0's binary_logloss: 0.140514	valid_1's auc: 0.833574	valid_1's binary_logloss: 0.151071
[6]	valid_0's auc: 0.855915	valid_0's binary_logloss: 0.138329	valid_1's auc: 0.834881	valid_1's binary_logloss: 0.149277
[7]	valid_0's auc: 0.858115	valid_0's binary_logloss: 0.136481	valid_1's auc: 0.833603	valid_1's binary_logloss: 0.14786
[8]	valid_0's auc: 0.859479	valid_0's binary_logloss: 0.134947	valid_1's auc: 0.834093	valid_1's binary_logloss: 0.146607
[9]	valid_0's auc: 0.86143	valid_0's binary_logloss: 0.133519	valid_1's auc: 0.833898	valid_1's binary_logloss: 0.14559
[10]	valid_0's auc: 0.862964	valid_0's binary_logloss: 0.132331	valid_1's auc: 0.835026	valid_1's binary_logloss: 0.144789
[11]	valid_0's auc: 0.864277	valid_0's binary_logloss: 0.13126	valid_1's auc: 0.834957	valid_1's binary_logloss: 0.144152
[12]	valid_0's auc: 0.865572	valid_0's binary_logloss: 0.130304	valid_1's auc: 0.833693	valid_1's binary_logloss: 0.143697
[13]	valid_0's auc: 0.867519	valid_0's binary_logloss: 0.129385	valid_1's auc: 0.833158	valid_1's binary_logloss: 0.143184
[14]	valid_0's auc: 0.869354	valid_0's binary_logloss: 0.128524	valid_1's auc: 0.833598	valid_1's binary_logloss: 0.142668
[15]	valid_0's auc: 0.870553	valid_0's binary_logloss: 0.127746	valid_1's auc: 0.833467	valid_1's binary_logloss: 0.142302
[16]	valid_0's auc: 0.871816	valid_0's binary_logloss: 0.126943	valid_1's auc: 0.83329	valid_1's binary_logloss: 0.142022
[17]	valid_0's auc: 0.872964	valid_0's binary_logloss: 0.126266	valid_1's auc: 0.83279	valid_1's binary_logloss: 0.141891
[18]	valid_0's auc: 0.874047	valid_0's binary_logloss: 0.125646	valid_1's auc: 0.831917	valid_1's binary_logloss: 0.141748
[19]	valid_0's auc: 0.875336	valid_0's binary_logloss: 0.125072	valid_1's auc: 0.831274	valid_1's binary_logloss: 0.141658
[20]	valid_0's auc: 0.876959	valid_0's binary_logloss: 0.124484	valid_1's auc: 0.831275	valid_1's binary_logloss: 0.141511
[21]	valid_0's auc: 0.878049	valid_0's binary_logloss: 0.123928	valid_1's auc: 0.830813	valid_1's binary_logloss: 0.141459
[22]	valid_0's auc: 0.878905	valid_0's binary_logloss: 0.123447	valid_1's auc: 0.83012	valid_1's binary_logloss: 0.141449
[23]	valid_0's auc: 0.879827	valid_0's binary_logloss: 0.12295	valid_1's auc: 0.829554	valid_1's binary_logloss: 0.141492
[24]	valid_0's auc: 0.880692	valid_0's binary_logloss: 0.122479	valid_1's auc: 0.829256	valid_1's binary_logloss: 0.141487
[25]	valid_0's auc: 0.881715	valid_0's binary_logloss: 0.121994	valid_1's auc: 0.829326	valid_1's binary_logloss: 0.141362
[26]	valid_0's auc: 0.883014	valid_0's binary_logloss: 0.121527	valid_1's auc: 0.829553	valid_1's binary_logloss: 0.14132
[27]	valid_0's auc: 0.884245	valid_0's binary_logloss: 0.121024	valid_1's auc: 0.829624	valid_1's binary_logloss: 0.14127
[28]	valid_0's auc: 0.885238	valid_0's binary_logloss: 0.12058	valid_1's auc: 0.829417	valid_1's binary_logloss: 0.141237
[29]	valid_0's auc: 0.88602	valid_0's binary_logloss: 0.120198	valid_1's auc: 0.82917	valid_1's binary_logloss: 0.141201
[30]	valid_0's auc: 0.88684	valid_0's binary_logloss: 0.119831	valid_1's auc: 0.82962	valid_1's binary_logloss: 0.141121
[31]	valid_0's auc: 0.887965	valid_0's binary_logloss: 0.119437	valid_1's auc: 0.83035	valid_1's binary_logloss: 0.14101
[32]	valid_0's auc: 0.88868	valid_0's binary_logloss: 0.119086	valid_1's auc: 0.82975	valid_1's binary_logloss: 0.141093
[33]	valid_0's auc: 0.889895	valid_0's binary_logloss: 0.118649	valid_1's auc: 0.829977	valid_1's binary_logloss: 0.141037
[34]	valid_0's auc: 0.890626	valid_0's binary_logloss: 0.118328	valid_1's auc: 0.829368	valid_1's binary_logloss: 0.141161
[35]	valid_0's auc: 0.89116	valid_0's binary_logloss: 0.11806	valid_1's auc: 0.829262	valid_1's binary_logloss: 0.141183
[36]	valid_0's auc: 0.891999	valid_0's binary_logloss: 0.11775	valid_1's auc: 0.828947	valid_1's binary_logloss: 0.14129
[37]	valid_0's auc: 0.892306	valid_0's binary_logloss: 0.117477	valid_1's auc: 0.828544	valid_1's binary_logloss: 0.141389
[38]	valid_0's auc: 0.892937	valid_0's binary_logloss: 0.117192	valid_1's auc: 0.827983	valid_1's binary_logloss: 0.141516
[39]	valid_0's auc: 0.893563	valid_0's binary_logloss: 0.116869	valid_1's auc: 0.828068	valid_1's binary_logloss: 0.141517
[40]	valid_0's auc: 0.893942	valid_0's binary_logloss: 0.11662	valid_1's auc: 0.827852	valid_1's binary_logloss: 0.141621
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.830474	valid_0's binary_logloss: 0.155928	valid_1's auc: 0.817343	valid_1's binary_logloss: 0.164928
[2]	valid_0's auc: 0.842931	valid_0's binary_logloss: 0.1503	valid_1's auc: 0.82699	valid_1's binary_logloss: 0.15948
[3]	valid_0's auc: 0.850877	valid_0's binary_logloss: 0.14631	valid_1's auc: 0.832212	valid_1's binary_logloss: 0.155775
[4]	valid_0's auc: 0.854431	valid_0's binary_logloss: 0.143104	valid_1's auc: 0.83392	valid_1's binary_logloss: 0.152698
[5]	valid_0's auc: 0.85663	valid_0's binary_logloss: 0.140582	valid_1's auc: 0.835094	valid_1's binary_logloss: 0.150349
[6]	valid_0's auc: 0.859142	valid_0's binary_logloss: 0.138289	valid_1's auc: 0.836166	valid_1's binary_logloss: 0.148424
[7]	valid_0's auc: 0.861364	valid_0's binary_logloss: 0.136413	valid_1's auc: 0.837184	valid_1's binary_logloss: 0.146912
[8]	valid_0's auc: 0.862199	valid_0's binary_logloss: 0.134841	valid_1's auc: 0.837545	valid_1's binary_logloss: 0.145726
[9]	valid_0's auc: 0.864095	valid_0's binary_logloss: 0.133364	valid_1's auc: 0.837242	valid_1's binary_logloss: 0.144736
[10]	valid_0's auc: 0.866024	valid_0's binary_logloss: 0.132096	valid_1's auc: 0.837719	valid_1's binary_logloss: 0.143766
[11]	valid_0's auc: 0.867454	valid_0's binary_logloss: 0.131002	valid_1's auc: 0.837865	valid_1's binary_logloss: 0.143009
[12]	valid_0's auc: 0.868329	valid_0's binary_logloss: 0.130024	valid_1's auc: 0.837259	valid_1's binary_logloss: 0.14244
[13]	valid_0's auc: 0.869137	valid_0's binary_logloss: 0.129145	valid_1's auc: 0.837689	valid_1's binary_logloss: 0.141896
[14]	valid_0's auc: 0.870957	valid_0's binary_logloss: 0.128226	valid_1's auc: 0.838226	valid_1's binary_logloss: 0.141392
[15]	valid_0's auc: 0.872273	valid_0's binary_logloss: 0.12745	valid_1's auc: 0.837906	valid_1's binary_logloss: 0.141019
[16]	valid_0's auc: 0.873243	valid_0's binary_logloss: 0.12672	valid_1's auc: 0.837761	valid_1's binary_logloss: 0.140677
[17]	valid_0's auc: 0.874251	valid_0's binary_logloss: 0.126044	valid_1's auc: 0.83701	valid_1's binary_logloss: 0.140582
[18]	valid_0's auc: 0.875622	valid_0's binary_logloss: 0.125387	valid_1's auc: 0.836179	valid_1's binary_logloss: 0.140485
[19]	valid_0's auc: 0.877031	valid_0's binary_logloss: 0.124759	valid_1's auc: 0.836188	valid_1's binary_logloss: 0.14029
[20]	valid_0's auc: 0.878046	valid_0's binary_logloss: 0.124156	valid_1's auc: 0.836531	valid_1's binary_logloss: 0.140133
[21]	valid_0's auc: 0.879478	valid_0's binary_logloss: 0.123507	valid_1's auc: 0.837068	valid_1's binary_logloss: 0.13995
[22]	valid_0's auc: 0.880423	valid_0's binary_logloss: 0.123029	valid_1's auc: 0.836817	valid_1's binary_logloss: 0.139912
[23]	valid_0's auc: 0.881684	valid_0's binary_logloss: 0.122492	valid_1's auc: 0.836983	valid_1's binary_logloss: 0.139762
[24]	valid_0's auc: 0.882873	valid_0's binary_logloss: 0.121986	valid_1's auc: 0.837319	valid_1's binary_logloss: 0.139659
[25]	valid_0's auc: 0.883597	valid_0's binary_logloss: 0.121566	valid_1's auc: 0.837154	valid_1's binary_logloss: 0.139623
[26]	valid_0's auc: 0.884814	valid_0's binary_logloss: 0.121104	valid_1's auc: 0.836302	valid_1's binary_logloss: 0.139668
[27]	valid_0's auc: 0.886026	valid_0's binary_logloss: 0.120635	valid_1's auc: 0.836521	valid_1's binary_logloss: 0.139601
[28]	valid_0's auc: 0.887071	valid_0's binary_logloss: 0.120222	valid_1's auc: 0.836646	valid_1's binary_logloss: 0.139557
[29]	valid_0's auc: 0.887946	valid_0's binary_logloss: 0.119804	valid_1's auc: 0.836735	valid_1's binary_logloss: 0.139518
[30]	valid_0's auc: 0.88898	valid_0's binary_logloss: 0.119416	valid_1's auc: 0.836858	valid_1's binary_logloss: 0.139499
[31]	valid_0's auc: 0.889792	valid_0's binary_logloss: 0.119058	valid_1's auc: 0.836917	valid_1's binary_logloss: 0.139463
[32]	valid_0's auc: 0.890876	valid_0's binary_logloss: 0.118631	valid_1's auc: 0.836346	valid_1's binary_logloss: 0.139532
[33]	valid_0's auc: 0.891629	valid_0's binary_logloss: 0.118259	valid_1's auc: 0.836206	valid_1's binary_logloss: 0.139603
[34]	valid_0's auc: 0.892446	valid_0's binary_logloss: 0.117893	valid_1's auc: 0.836005	valid_1's binary_logloss: 0.139603
[35]	valid_0's auc: 0.893407	valid_0's binary_logloss: 0.11752	valid_1's auc: 0.8361	valid_1's binary_logloss: 0.139574
[36]	valid_0's auc: 0.893836	valid_0's binary_logloss: 0.117247	valid_1's auc: 0.836147	valid_1's binary_logloss: 0.139608
[37]	valid_0's auc: 0.894774	valid_0's binary_logloss: 0.116913	valid_1's auc: 0.836601	valid_1's binary_logloss: 0.139569
[38]	valid_0's auc: 0.895494	valid_0's binary_logloss: 0.116611	valid_1's auc: 0.836232	valid_1's binary_logloss: 0.139645
[39]	valid_0's auc: 0.896102	valid_0's binary_logloss: 0.116275	valid_1's auc: 0.836415	valid_1's binary_logloss: 0.139653
[40]	valid_0's auc: 0.896715	valid_0's binary_logloss: 0.115934	valid_1's auc: 0.836463	valid_1's binary_logloss: 0.139671
[41]	valid_0's auc: 0.897232	valid_0's binary_logloss: 0.115612	valid_1's auc: 0.836223	valid_1's binary_logloss: 0.139762
[42]	valid_0's auc: 0.897875	valid_0's binary_logloss: 0.11528	valid_1's auc: 0.836151	valid_1's binary_logloss: 0.139777
[43]	valid_0's auc: 0.898493	valid_0's binary_logloss: 0.114999	valid_1's auc: 0.836216	valid_1's binary_logloss: 0.139761
[44]	valid_0's auc: 0.899179	valid_0's binary_logloss: 0.114703	valid_1's auc: 0.836328	valid_1's binary_logloss: 0.139755
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.834724	valid_0's binary_logloss: 0.15607	valid_1's auc: 0.822983	valid_1's binary_logloss: 0.165104
[2]	valid_0's auc: 0.842835	valid_0's binary_logloss: 0.150494	valid_1's auc: 0.830472	valid_1's binary_logloss: 0.159671
[3]	valid_0's auc: 0.847187	valid_0's binary_logloss: 0.146306	valid_1's auc: 0.830873	valid_1's binary_logloss: 0.155985
[4]	valid_0's auc: 0.850394	valid_0's binary_logloss: 0.143088	valid_1's auc: 0.830975	valid_1's binary_logloss: 0.15321
[5]	valid_0's auc: 0.853379	valid_0's binary_logloss: 0.140508	valid_1's auc: 0.832135	valid_1's binary_logloss: 0.150854
[6]	valid_0's auc: 0.855463	valid_0's binary_logloss: 0.138297	valid_1's auc: 0.833116	valid_1's binary_logloss: 0.149013
[7]	valid_0's auc: 0.856723	valid_0's binary_logloss: 0.136504	valid_1's auc: 0.833811	valid_1's binary_logloss: 0.147577
[8]	valid_0's auc: 0.858076	valid_0's binary_logloss: 0.13495	valid_1's auc: 0.835315	valid_1's binary_logloss: 0.146273
[9]	valid_0's auc: 0.861024	valid_0's binary_logloss: 0.133583	valid_1's auc: 0.835042	valid_1's binary_logloss: 0.145374
[10]	valid_0's auc: 0.862281	valid_0's binary_logloss: 0.132357	valid_1's auc: 0.834154	valid_1's binary_logloss: 0.144649
[11]	valid_0's auc: 0.864612	valid_0's binary_logloss: 0.131283	valid_1's auc: 0.834587	valid_1's binary_logloss: 0.143941
[12]	valid_0's auc: 0.866377	valid_0's binary_logloss: 0.130299	valid_1's auc: 0.834242	valid_1's binary_logloss: 0.143366
[13]	valid_0's auc: 0.868343	valid_0's binary_logloss: 0.129417	valid_1's auc: 0.833273	valid_1's binary_logloss: 0.142976
[14]	valid_0's auc: 0.86957	valid_0's binary_logloss: 0.128593	valid_1's auc: 0.833783	valid_1's binary_logloss: 0.142567
[15]	valid_0's auc: 0.871109	valid_0's binary_logloss: 0.127759	valid_1's auc: 0.834057	valid_1's binary_logloss: 0.142234
[16]	valid_0's auc: 0.872893	valid_0's binary_logloss: 0.126996	valid_1's auc: 0.835329	valid_1's binary_logloss: 0.141809
[17]	valid_0's auc: 0.874236	valid_0's binary_logloss: 0.12631	valid_1's auc: 0.834985	valid_1's binary_logloss: 0.141613
[18]	valid_0's auc: 0.875324	valid_0's binary_logloss: 0.125725	valid_1's auc: 0.834942	valid_1's binary_logloss: 0.141363
[19]	valid_0's auc: 0.876659	valid_0's binary_logloss: 0.125068	valid_1's auc: 0.835024	valid_1's binary_logloss: 0.141162
[20]	valid_0's auc: 0.877885	valid_0's binary_logloss: 0.124484	valid_1's auc: 0.835893	valid_1's binary_logloss: 0.140933
[21]	valid_0's auc: 0.879121	valid_0's binary_logloss: 0.12391	valid_1's auc: 0.837029	valid_1's binary_logloss: 0.140651
[22]	valid_0's auc: 0.880116	valid_0's binary_logloss: 0.123339	valid_1's auc: 0.837366	valid_1's binary_logloss: 0.140547
[23]	valid_0's auc: 0.881224	valid_0's binary_logloss: 0.12282	valid_1's auc: 0.837357	valid_1's binary_logloss: 0.140445
[24]	valid_0's auc: 0.882014	valid_0's binary_logloss: 0.122386	valid_1's auc: 0.837343	valid_1's binary_logloss: 0.140371
[25]	valid_0's auc: 0.88318	valid_0's binary_logloss: 0.121861	valid_1's auc: 0.83723	valid_1's binary_logloss: 0.140313
[26]	valid_0's auc: 0.884008	valid_0's binary_logloss: 0.121441	valid_1's auc: 0.837761	valid_1's binary_logloss: 0.140173
[27]	valid_0's auc: 0.884676	valid_0's binary_logloss: 0.121001	valid_1's auc: 0.838046	valid_1's binary_logloss: 0.140086
[28]	valid_0's auc: 0.885524	valid_0's binary_logloss: 0.120598	valid_1's auc: 0.838029	valid_1's binary_logloss: 0.140051
[29]	valid_0's auc: 0.886461	valid_0's binary_logloss: 0.120157	valid_1's auc: 0.837775	valid_1's binary_logloss: 0.140057
[30]	valid_0's auc: 0.887053	valid_0's binary_logloss: 0.119807	valid_1's auc: 0.837472	valid_1's binary_logloss: 0.140111
[31]	valid_0's auc: 0.888177	valid_0's binary_logloss: 0.119425	valid_1's auc: 0.837575	valid_1's binary_logloss: 0.140093
[32]	valid_0's auc: 0.889072	valid_0's binary_logloss: 0.119055	valid_1's auc: 0.837158	valid_1's binary_logloss: 0.140195
[33]	valid_0's auc: 0.889782	valid_0's binary_logloss: 0.118676	valid_1's auc: 0.837296	valid_1's binary_logloss: 0.140221
[34]	valid_0's auc: 0.890876	valid_0's binary_logloss: 0.118304	valid_1's auc: 0.837481	valid_1's binary_logloss: 0.140165
[35]	valid_0's auc: 0.891448	valid_0's binary_logloss: 0.11798	valid_1's auc: 0.837953	valid_1's binary_logloss: 0.140085
[36]	valid_0's auc: 0.892165	valid_0's binary_logloss: 0.11764	valid_1's auc: 0.837794	valid_1's binary_logloss: 0.140112
[37]	valid_0's auc: 0.892798	valid_0's binary_logloss: 0.117321	valid_1's auc: 0.837291	valid_1's binary_logloss: 0.140221
[38]	valid_0's auc: 0.893318	valid_0's binary_logloss: 0.117028	valid_1's auc: 0.837278	valid_1's binary_logloss: 0.140221
[39]	valid_0's auc: 0.894018	valid_0's binary_logloss: 0.116742	valid_1's auc: 0.83724	valid_1's binary_logloss: 0.140232
[40]	valid_0's auc: 0.894781	valid_0's binary_logloss: 0.116373	valid_1's auc: 0.836901	valid_1's binary_logloss: 0.140328
[41]	valid_0's auc: 0.895222	valid_0's binary_logloss: 0.116075	valid_1's auc: 0.836655	valid_1's binary_logloss: 0.140422
[42]	valid_0's auc: 0.895842	valid_0's binary_logloss: 0.115755	valid_1's auc: 0.836383	valid_1's binary_logloss: 0.140503
[43]	valid_0's auc: 0.896389	valid_0's binary_logloss: 0.115503	valid_1's auc: 0.836348	valid_1's binary_logloss: 0.140505
[44]	valid_0's auc: 0.896843	valid_0's binary_logloss: 0.115204	valid_1's auc: 0.836521	valid_1's binary_logloss: 0.140518
[45]	valid_0's auc: 0.897272	valid_0's binary_logloss: 0.114886	valid_1's auc: 0.836311	valid_1's binary_logloss: 0.140581
[46]	valid_0's auc: 0.898034	valid_0's binary_logloss: 0.114544	valid_1's auc: 0.835871	valid_1's binary_logloss: 0.140663
[47]	valid_0's auc: 0.898562	valid_0's binary_logloss: 0.114262	valid_1's auc: 0.835926	valid_1's binary_logloss: 0.140642
[48]	valid_0's auc: 0.898919	valid_0's binary_logloss: 0.114006	valid_1's auc: 0.835849	valid_1's binary_logloss: 0.140687
[49]	valid_0's auc: 0.899111	valid_0's binary_logloss: 0.113791	valid_1's auc: 0.835874	valid_1's binary_logloss: 0.140728
[50]	valid_0's auc: 0.89987	valid_0's binary_logloss: 0.113543	valid_1's auc: 0.835915	valid_1's binary_logloss: 0.14075
[51]	valid_0's auc: 0.90004	valid_0's binary_logloss: 0.113342	valid_1's auc: 0.835947	valid_1's binary_logloss: 0.140748
[52]	valid_0's auc: 0.900405	valid_0's binary_logloss: 0.113087	valid_1's auc: 0.836011	valid_1's binary_logloss: 0.140767
[53]	valid_0's auc: 0.900828	valid_0's binary_logloss: 0.112831	valid_1's auc: 0.836259	valid_1's binary_logloss: 0.140771
[54]	valid_0's auc: 0.901597	valid_0's binary_logloss: 0.112604	valid_1's auc: 0.836296	valid_1's binary_logloss: 0.14078
[55]	valid_0's auc: 0.901645	valid_0's binary_logloss: 0.112429	valid_1's auc: 0.836095	valid_1's binary_logloss: 0.140822
[56]	valid_0's auc: 0.902162	valid_0's binary_logloss: 0.112169	valid_1's auc: 0.835965	valid_1's binary_logloss: 0.14086
[57]	valid_0's auc: 0.902422	valid_0's binary_logloss: 0.111944	valid_1's auc: 0.835493	valid_1's binary_logloss: 0.140993
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.820235	valid_0's binary_logloss: 0.156085	valid_1's auc: 0.81613	valid_1's binary_logloss: 0.164992
[2]	valid_0's auc: 0.825778	valid_0's binary_logloss: 0.150951	valid_1's auc: 0.821835	valid_1's binary_logloss: 0.159874
[3]	valid_0's auc: 0.832262	valid_0's binary_logloss: 0.147158	valid_1's auc: 0.826533	valid_1's binary_logloss: 0.156346
[4]	valid_0's auc: 0.83865	valid_0's binary_logloss: 0.144126	valid_1's auc: 0.833166	valid_1's binary_logloss: 0.1534
[5]	valid_0's auc: 0.842822	valid_0's binary_logloss: 0.141725	valid_1's auc: 0.836448	valid_1's binary_logloss: 0.151167
[6]	valid_0's auc: 0.844702	valid_0's binary_logloss: 0.139642	valid_1's auc: 0.837094	valid_1's binary_logloss: 0.149356
[7]	valid_0's auc: 0.847144	valid_0's binary_logloss: 0.13794	valid_1's auc: 0.837965	valid_1's binary_logloss: 0.147853
[8]	valid_0's auc: 0.848277	valid_0's binary_logloss: 0.136499	valid_1's auc: 0.837663	valid_1's binary_logloss: 0.146543
[9]	valid_0's auc: 0.849328	valid_0's binary_logloss: 0.135326	valid_1's auc: 0.837413	valid_1's binary_logloss: 0.145528
[10]	valid_0's auc: 0.851112	valid_0's binary_logloss: 0.134188	valid_1's auc: 0.836954	valid_1's binary_logloss: 0.14466
[11]	valid_0's auc: 0.852613	valid_0's binary_logloss: 0.133257	valid_1's auc: 0.837393	valid_1's binary_logloss: 0.143843
[12]	valid_0's auc: 0.854906	valid_0's binary_logloss: 0.132346	valid_1's auc: 0.837459	valid_1's binary_logloss: 0.143285
[13]	valid_0's auc: 0.855656	valid_0's binary_logloss: 0.131601	valid_1's auc: 0.837612	valid_1's binary_logloss: 0.142732
[14]	valid_0's auc: 0.857076	valid_0's binary_logloss: 0.130884	valid_1's auc: 0.837055	valid_1's binary_logloss: 0.142403
[15]	valid_0's auc: 0.857961	valid_0's binary_logloss: 0.130252	valid_1's auc: 0.837198	valid_1's binary_logloss: 0.142031
[16]	valid_0's auc: 0.860191	valid_0's binary_logloss: 0.129596	valid_1's auc: 0.836016	valid_1's binary_logloss: 0.141822
[17]	valid_0's auc: 0.860941	valid_0's binary_logloss: 0.129064	valid_1's auc: 0.836076	valid_1's binary_logloss: 0.141551
[18]	valid_0's auc: 0.862201	valid_0's binary_logloss: 0.128565	valid_1's auc: 0.835929	valid_1's binary_logloss: 0.141326
[19]	valid_0's auc: 0.863581	valid_0's binary_logloss: 0.128105	valid_1's auc: 0.835256	valid_1's binary_logloss: 0.141243
[20]	valid_0's auc: 0.864799	valid_0's binary_logloss: 0.127654	valid_1's auc: 0.83435	valid_1's binary_logloss: 0.141148
[21]	valid_0's auc: 0.866472	valid_0's binary_logloss: 0.127165	valid_1's auc: 0.834176	valid_1's binary_logloss: 0.141041
[22]	valid_0's auc: 0.867055	valid_0's binary_logloss: 0.126777	valid_1's auc: 0.834173	valid_1's binary_logloss: 0.140887
[23]	valid_0's auc: 0.867726	valid_0's binary_logloss: 0.12643	valid_1's auc: 0.833577	valid_1's binary_logloss: 0.140909
[24]	valid_0's auc: 0.868612	valid_0's binary_logloss: 0.126061	valid_1's auc: 0.833336	valid_1's binary_logloss: 0.140824
[25]	valid_0's auc: 0.869224	valid_0's binary_logloss: 0.125753	valid_1's auc: 0.833428	valid_1's binary_logloss: 0.140793
[26]	valid_0's auc: 0.870183	valid_0's binary_logloss: 0.125414	valid_1's auc: 0.83333	valid_1's binary_logloss: 0.140724
[27]	valid_0's auc: 0.870926	valid_0's binary_logloss: 0.125123	valid_1's auc: 0.832503	valid_1's binary_logloss: 0.140772
[28]	valid_0's auc: 0.872431	valid_0's binary_logloss: 0.124766	valid_1's auc: 0.832826	valid_1's binary_logloss: 0.140685
[29]	valid_0's auc: 0.873397	valid_0's binary_logloss: 0.124495	valid_1's auc: 0.833175	valid_1's binary_logloss: 0.140604
[30]	valid_0's auc: 0.87475	valid_0's binary_logloss: 0.12417	valid_1's auc: 0.833614	valid_1's binary_logloss: 0.140497
[31]	valid_0's auc: 0.875407	valid_0's binary_logloss: 0.12389	valid_1's auc: 0.833706	valid_1's binary_logloss: 0.140428
[32]	valid_0's auc: 0.876136	valid_0's binary_logloss: 0.123637	valid_1's auc: 0.833458	valid_1's binary_logloss: 0.140448
[33]	valid_0's auc: 0.876575	valid_0's binary_logloss: 0.123421	valid_1's auc: 0.832965	valid_1's binary_logloss: 0.140498
[34]	valid_0's auc: 0.877224	valid_0's binary_logloss: 0.123219	valid_1's auc: 0.832659	valid_1's binary_logloss: 0.140537
[35]	valid_0's auc: 0.877898	valid_0's binary_logloss: 0.122947	valid_1's auc: 0.832787	valid_1's binary_logloss: 0.140536
[36]	valid_0's auc: 0.878334	valid_0's binary_logloss: 0.122724	valid_1's auc: 0.832724	valid_1's binary_logloss: 0.14053
[37]	valid_0's auc: 0.878762	valid_0's binary_logloss: 0.122514	valid_1's auc: 0.832581	valid_1's binary_logloss: 0.140533
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.814371	valid_0's binary_logloss: 0.156452	valid_1's auc: 0.813175	valid_1's binary_logloss: 0.165418
[2]	valid_0's auc: 0.827277	valid_0's binary_logloss: 0.151084	valid_1's auc: 0.819635	valid_1's binary_logloss: 0.160159
[3]	valid_0's auc: 0.837033	valid_0's binary_logloss: 0.14722	valid_1's auc: 0.828221	valid_1's binary_logloss: 0.156492
[4]	valid_0's auc: 0.840167	valid_0's binary_logloss: 0.14423	valid_1's auc: 0.830942	valid_1's binary_logloss: 0.153586
[5]	valid_0's auc: 0.842499	valid_0's binary_logloss: 0.141721	valid_1's auc: 0.833301	valid_1's binary_logloss: 0.151219
[6]	valid_0's auc: 0.845403	valid_0's binary_logloss: 0.139708	valid_1's auc: 0.836412	valid_1's binary_logloss: 0.149312
[7]	valid_0's auc: 0.848049	valid_0's binary_logloss: 0.138024	valid_1's auc: 0.836054	valid_1's binary_logloss: 0.14779
[8]	valid_0's auc: 0.849694	valid_0's binary_logloss: 0.136542	valid_1's auc: 0.837537	valid_1's binary_logloss: 0.146417
[9]	valid_0's auc: 0.851646	valid_0's binary_logloss: 0.135289	valid_1's auc: 0.838418	valid_1's binary_logloss: 0.145329
[10]	valid_0's auc: 0.853642	valid_0's binary_logloss: 0.134189	valid_1's auc: 0.839342	valid_1's binary_logloss: 0.144374
[11]	valid_0's auc: 0.855647	valid_0's binary_logloss: 0.133227	valid_1's auc: 0.840035	valid_1's binary_logloss: 0.143552
[12]	valid_0's auc: 0.856768	valid_0's binary_logloss: 0.132399	valid_1's auc: 0.839294	valid_1's binary_logloss: 0.143047
[13]	valid_0's auc: 0.85763	valid_0's binary_logloss: 0.13165	valid_1's auc: 0.838911	valid_1's binary_logloss: 0.142469
[14]	valid_0's auc: 0.859243	valid_0's binary_logloss: 0.130936	valid_1's auc: 0.838705	valid_1's binary_logloss: 0.141913
[15]	valid_0's auc: 0.860124	valid_0's binary_logloss: 0.130312	valid_1's auc: 0.838608	valid_1's binary_logloss: 0.141547
[16]	valid_0's auc: 0.861358	valid_0's binary_logloss: 0.129687	valid_1's auc: 0.838422	valid_1's binary_logloss: 0.141134
[17]	valid_0's auc: 0.862159	valid_0's binary_logloss: 0.129139	valid_1's auc: 0.838636	valid_1's binary_logloss: 0.140786
[18]	valid_0's auc: 0.862729	valid_0's binary_logloss: 0.128664	valid_1's auc: 0.838342	valid_1's binary_logloss: 0.140538
[19]	valid_0's auc: 0.863842	valid_0's binary_logloss: 0.128137	valid_1's auc: 0.838464	valid_1's binary_logloss: 0.140331
[20]	valid_0's auc: 0.864859	valid_0's binary_logloss: 0.127657	valid_1's auc: 0.837832	valid_1's binary_logloss: 0.140179
[21]	valid_0's auc: 0.866227	valid_0's binary_logloss: 0.127137	valid_1's auc: 0.837735	valid_1's binary_logloss: 0.140043
[22]	valid_0's auc: 0.866925	valid_0's binary_logloss: 0.126772	valid_1's auc: 0.838268	valid_1's binary_logloss: 0.139927
[23]	valid_0's auc: 0.867727	valid_0's binary_logloss: 0.126369	valid_1's auc: 0.838482	valid_1's binary_logloss: 0.139787
[24]	valid_0's auc: 0.868239	valid_0's binary_logloss: 0.126013	valid_1's auc: 0.838767	valid_1's binary_logloss: 0.13964
[25]	valid_0's auc: 0.869304	valid_0's binary_logloss: 0.125622	valid_1's auc: 0.838562	valid_1's binary_logloss: 0.139648
[26]	valid_0's auc: 0.870347	valid_0's binary_logloss: 0.125288	valid_1's auc: 0.838228	valid_1's binary_logloss: 0.139618
[27]	valid_0's auc: 0.871198	valid_0's binary_logloss: 0.124953	valid_1's auc: 0.838403	valid_1's binary_logloss: 0.139594
[28]	valid_0's auc: 0.872024	valid_0's binary_logloss: 0.124672	valid_1's auc: 0.838405	valid_1's binary_logloss: 0.139526
[29]	valid_0's auc: 0.873184	valid_0's binary_logloss: 0.124303	valid_1's auc: 0.838211	valid_1's binary_logloss: 0.139531
[30]	valid_0's auc: 0.874076	valid_0's binary_logloss: 0.12403	valid_1's auc: 0.838983	valid_1's binary_logloss: 0.139411
[31]	valid_0's auc: 0.874768	valid_0's binary_logloss: 0.123745	valid_1's auc: 0.839314	valid_1's binary_logloss: 0.139314
[32]	valid_0's auc: 0.875593	valid_0's binary_logloss: 0.123486	valid_1's auc: 0.838875	valid_1's binary_logloss: 0.139322
[33]	valid_0's auc: 0.8767	valid_0's binary_logloss: 0.123182	valid_1's auc: 0.838809	valid_1's binary_logloss: 0.139329
[34]	valid_0's auc: 0.87774	valid_0's binary_logloss: 0.122892	valid_1's auc: 0.838376	valid_1's binary_logloss: 0.139342
[35]	valid_0's auc: 0.878372	valid_0's binary_logloss: 0.122634	valid_1's auc: 0.838454	valid_1's binary_logloss: 0.13931
[36]	valid_0's auc: 0.879098	valid_0's binary_logloss: 0.122414	valid_1's auc: 0.838895	valid_1's binary_logloss: 0.13925
[37]	valid_0's auc: 0.879502	valid_0's binary_logloss: 0.122216	valid_1's auc: 0.838441	valid_1's binary_logloss: 0.139302
[38]	valid_0's auc: 0.880036	valid_0's binary_logloss: 0.121998	valid_1's auc: 0.838582	valid_1's binary_logloss: 0.139306
[39]	valid_0's auc: 0.880641	valid_0's binary_logloss: 0.121716	valid_1's auc: 0.838787	valid_1's binary_logloss: 0.139269
[40]	valid_0's auc: 0.881249	valid_0's binary_logloss: 0.121482	valid_1's auc: 0.838906	valid_1's binary_logloss: 0.139223
[41]	valid_0's auc: 0.881919	valid_0's binary_logloss: 0.121223	valid_1's auc: 0.838567	valid_1's binary_logloss: 0.13926
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.821645	valid_0's binary_logloss: 0.156528	valid_1's auc: 0.81857	valid_1's binary_logloss: 0.165101
[2]	valid_0's auc: 0.827488	valid_0's binary_logloss: 0.151189	valid_1's auc: 0.822299	valid_1's binary_logloss: 0.160072
[3]	valid_0's auc: 0.837855	valid_0's binary_logloss: 0.147263	valid_1's auc: 0.829855	valid_1's binary_logloss: 0.156527
[4]	valid_0's auc: 0.840063	valid_0's binary_logloss: 0.144261	valid_1's auc: 0.833088	valid_1's binary_logloss: 0.153446
[5]	valid_0's auc: 0.842802	valid_0's binary_logloss: 0.141691	valid_1's auc: 0.834541	valid_1's binary_logloss: 0.151144
[6]	valid_0's auc: 0.844	valid_0's binary_logloss: 0.139654	valid_1's auc: 0.834542	valid_1's binary_logloss: 0.149333
[7]	valid_0's auc: 0.845838	valid_0's binary_logloss: 0.138002	valid_1's auc: 0.835645	valid_1's binary_logloss: 0.147676
[8]	valid_0's auc: 0.846869	valid_0's binary_logloss: 0.136628	valid_1's auc: 0.836118	valid_1's binary_logloss: 0.146491
[9]	valid_0's auc: 0.849282	valid_0's binary_logloss: 0.135382	valid_1's auc: 0.837542	valid_1's binary_logloss: 0.14539
[10]	valid_0's auc: 0.851021	valid_0's binary_logloss: 0.134282	valid_1's auc: 0.836942	valid_1's binary_logloss: 0.144584
[11]	valid_0's auc: 0.852037	valid_0's binary_logloss: 0.133358	valid_1's auc: 0.8374	valid_1's binary_logloss: 0.143836
[12]	valid_0's auc: 0.854496	valid_0's binary_logloss: 0.132505	valid_1's auc: 0.838593	valid_1's binary_logloss: 0.143171
[13]	valid_0's auc: 0.857514	valid_0's binary_logloss: 0.131695	valid_1's auc: 0.838558	valid_1's binary_logloss: 0.142646
[14]	valid_0's auc: 0.858827	valid_0's binary_logloss: 0.131006	valid_1's auc: 0.838498	valid_1's binary_logloss: 0.142158
[15]	valid_0's auc: 0.860574	valid_0's binary_logloss: 0.130352	valid_1's auc: 0.837435	valid_1's binary_logloss: 0.141868
[16]	valid_0's auc: 0.861239	valid_0's binary_logloss: 0.129765	valid_1's auc: 0.837374	valid_1's binary_logloss: 0.141537
[17]	valid_0's auc: 0.86217	valid_0's binary_logloss: 0.129164	valid_1's auc: 0.837703	valid_1's binary_logloss: 0.141192
[18]	valid_0's auc: 0.863228	valid_0's binary_logloss: 0.128615	valid_1's auc: 0.837526	valid_1's binary_logloss: 0.140917
[19]	valid_0's auc: 0.86473	valid_0's binary_logloss: 0.128113	valid_1's auc: 0.838235	valid_1's binary_logloss: 0.140572
[20]	valid_0's auc: 0.865797	valid_0's binary_logloss: 0.127679	valid_1's auc: 0.838788	valid_1's binary_logloss: 0.140332
[21]	valid_0's auc: 0.866561	valid_0's binary_logloss: 0.127235	valid_1's auc: 0.839171	valid_1's binary_logloss: 0.140108
[22]	valid_0's auc: 0.867237	valid_0's binary_logloss: 0.12688	valid_1's auc: 0.839213	valid_1's binary_logloss: 0.13991
[23]	valid_0's auc: 0.867894	valid_0's binary_logloss: 0.126519	valid_1's auc: 0.839641	valid_1's binary_logloss: 0.139745
[24]	valid_0's auc: 0.868501	valid_0's binary_logloss: 0.126192	valid_1's auc: 0.840025	valid_1's binary_logloss: 0.139593
[25]	valid_0's auc: 0.869311	valid_0's binary_logloss: 0.125838	valid_1's auc: 0.839961	valid_1's binary_logloss: 0.139531
[26]	valid_0's auc: 0.870325	valid_0's binary_logloss: 0.125518	valid_1's auc: 0.839261	valid_1's binary_logloss: 0.139524
[27]	valid_0's auc: 0.871488	valid_0's binary_logloss: 0.125147	valid_1's auc: 0.839671	valid_1's binary_logloss: 0.139365
[28]	valid_0's auc: 0.87235	valid_0's binary_logloss: 0.12484	valid_1's auc: 0.840114	valid_1's binary_logloss: 0.139236
[29]	valid_0's auc: 0.872991	valid_0's binary_logloss: 0.124593	valid_1's auc: 0.839491	valid_1's binary_logloss: 0.139271
[30]	valid_0's auc: 0.874129	valid_0's binary_logloss: 0.124312	valid_1's auc: 0.839589	valid_1's binary_logloss: 0.13918
[31]	valid_0's auc: 0.875305	valid_0's binary_logloss: 0.123988	valid_1's auc: 0.839441	valid_1's binary_logloss: 0.139184
[32]	valid_0's auc: 0.875943	valid_0's binary_logloss: 0.123748	valid_1's auc: 0.839268	valid_1's binary_logloss: 0.13919
[33]	valid_0's auc: 0.876575	valid_0's binary_logloss: 0.123484	valid_1's auc: 0.839549	valid_1's binary_logloss: 0.139075
[34]	valid_0's auc: 0.877426	valid_0's binary_logloss: 0.123156	valid_1's auc: 0.839087	valid_1's binary_logloss: 0.139148
[35]	valid_0's auc: 0.87822	valid_0's binary_logloss: 0.122873	valid_1's auc: 0.8389	valid_1's binary_logloss: 0.139187
[36]	valid_0's auc: 0.878932	valid_0's binary_logloss: 0.12259	valid_1's auc: 0.838921	valid_1's binary_logloss: 0.139194
[37]	valid_0's auc: 0.879842	valid_0's binary_logloss: 0.12233	valid_1's auc: 0.839133	valid_1's binary_logloss: 0.139161
[38]	valid_0's auc: 0.880497	valid_0's binary_logloss: 0.12208	valid_1's auc: 0.838975	valid_1's binary_logloss: 0.139143
[39]	valid_0's auc: 0.881056	valid_0's binary_logloss: 0.121827	valid_1's auc: 0.839037	valid_1's binary_logloss: 0.139138
[40]	valid_0's auc: 0.881604	valid_0's binary_logloss: 0.121603	valid_1's auc: 0.839204	valid_1's binary_logloss: 0.139119
[41]	valid_0's auc: 0.882159	valid_0's binary_logloss: 0.121355	valid_1's auc: 0.839277	valid_1's binary_logloss: 0.139091
[42]	valid_0's auc: 0.882757	valid_0's binary_logloss: 0.121116	valid_1's auc: 0.838964	valid_1's binary_logloss: 0.139133
[43]	valid_0's auc: 0.883143	valid_0's binary_logloss: 0.120918	valid_1's auc: 0.839024	valid_1's binary_logloss: 0.139124
[44]	valid_0's auc: 0.883697	valid_0's binary_logloss: 0.12072	valid_1's auc: 0.838652	valid_1's binary_logloss: 0.139203
[45]	valid_0's auc: 0.884292	valid_0's binary_logloss: 0.120482	valid_1's auc: 0.839016	valid_1's binary_logloss: 0.139124
[46]	valid_0's auc: 0.884969	valid_0's binary_logloss: 0.120266	valid_1's auc: 0.838683	valid_1's binary_logloss: 0.139184
[47]	valid_0's auc: 0.8853	valid_0's binary_logloss: 0.120089	valid_1's auc: 0.838624	valid_1's binary_logloss: 0.139193
[48]	valid_0's auc: 0.885876	valid_0's binary_logloss: 0.11993	valid_1's auc: 0.838569	valid_1's binary_logloss: 0.139212
[49]	valid_0's auc: 0.886141	valid_0's binary_logloss: 0.119757	valid_1's auc: 0.838345	valid_1's binary_logloss: 0.139288
[50]	valid_0's auc: 0.886433	valid_0's binary_logloss: 0.119595	valid_1's auc: 0.838342	valid_1's binary_logloss: 0.139332
[51]	valid_0's auc: 0.886975	valid_0's binary_logloss: 0.119377	valid_1's auc: 0.838335	valid_1's binary_logloss: 0.139331
[52]	valid_0's auc: 0.887568	valid_0's binary_logloss: 0.119161	valid_1's auc: 0.838204	valid_1's binary_logloss: 0.139331
[53]	valid_0's auc: 0.887867	valid_0's binary_logloss: 0.118974	valid_1's auc: 0.838044	valid_1's binary_logloss: 0.13936
[54]	valid_0's auc: 0.888093	valid_0's binary_logloss: 0.118834	valid_1's auc: 0.838137	valid_1's binary_logloss: 0.13935
[55]	valid_0's auc: 0.888289	valid_0's binary_logloss: 0.118675	valid_1's auc: 0.837878	valid_1's binary_logloss: 0.139392
[56]	valid_0's auc: 0.888615	valid_0's binary_logloss: 0.118561	valid_1's auc: 0.837776	valid_1's binary_logloss: 0.139418
[57]	valid_0's auc: 0.889157	valid_0's binary_logloss: 0.118369	valid_1's auc: 0.837585	valid_1's binary_logloss: 0.139447
[58]	valid_0's auc: 0.889659	valid_0's binary_logloss: 0.11819	valid_1's auc: 0.837789	valid_1's binary_logloss: 0.139431
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.820235	valid_0's binary_logloss: 0.156085	valid_1's auc: 0.81613	valid_1's binary_logloss: 0.164992
[2]	valid_0's auc: 0.825778	valid_0's binary_logloss: 0.150951	valid_1's auc: 0.821835	valid_1's binary_logloss: 0.159874
[3]	valid_0's auc: 0.832262	valid_0's binary_logloss: 0.147158	valid_1's auc: 0.826533	valid_1's binary_logloss: 0.156346
[4]	valid_0's auc: 0.83865	valid_0's binary_logloss: 0.144126	valid_1's auc: 0.833166	valid_1's binary_logloss: 0.1534
[5]	valid_0's auc: 0.842822	valid_0's binary_logloss: 0.141725	valid_1's auc: 0.836448	valid_1's binary_logloss: 0.151167
[6]	valid_0's auc: 0.844702	valid_0's binary_logloss: 0.139642	valid_1's auc: 0.837094	valid_1's binary_logloss: 0.149356
[7]	valid_0's auc: 0.847144	valid_0's binary_logloss: 0.13794	valid_1's auc: 0.837965	valid_1's binary_logloss: 0.147853
[8]	valid_0's auc: 0.848277	valid_0's binary_logloss: 0.136499	valid_1's auc: 0.837663	valid_1's binary_logloss: 0.146543
[9]	valid_0's auc: 0.849328	valid_0's binary_logloss: 0.135326	valid_1's auc: 0.837413	valid_1's binary_logloss: 0.145528
[10]	valid_0's auc: 0.851112	valid_0's binary_logloss: 0.134188	valid_1's auc: 0.836954	valid_1's binary_logloss: 0.14466
[11]	valid_0's auc: 0.852613	valid_0's binary_logloss: 0.133257	valid_1's auc: 0.837393	valid_1's binary_logloss: 0.143843
[12]	valid_0's auc: 0.854906	valid_0's binary_logloss: 0.132346	valid_1's auc: 0.837459	valid_1's binary_logloss: 0.143285
[13]	valid_0's auc: 0.855656	valid_0's binary_logloss: 0.131601	valid_1's auc: 0.837612	valid_1's binary_logloss: 0.142732
[14]	valid_0's auc: 0.857076	valid_0's binary_logloss: 0.130884	valid_1's auc: 0.837055	valid_1's binary_logloss: 0.142403
[15]	valid_0's auc: 0.857961	valid_0's binary_logloss: 0.130252	valid_1's auc: 0.837198	valid_1's binary_logloss: 0.142031
[16]	valid_0's auc: 0.860191	valid_0's binary_logloss: 0.129596	valid_1's auc: 0.836016	valid_1's binary_logloss: 0.141822
[17]	valid_0's auc: 0.860941	valid_0's binary_logloss: 0.129064	valid_1's auc: 0.836076	valid_1's binary_logloss: 0.141551
[18]	valid_0's auc: 0.862201	valid_0's binary_logloss: 0.128565	valid_1's auc: 0.835929	valid_1's binary_logloss: 0.141326
[19]	valid_0's auc: 0.863581	valid_0's binary_logloss: 0.128105	valid_1's auc: 0.835256	valid_1's binary_logloss: 0.141243
[20]	valid_0's auc: 0.864799	valid_0's binary_logloss: 0.127654	valid_1's auc: 0.83435	valid_1's binary_logloss: 0.141148
[21]	valid_0's auc: 0.866472	valid_0's binary_logloss: 0.127165	valid_1's auc: 0.834176	valid_1's binary_logloss: 0.141041
[22]	valid_0's auc: 0.867055	valid_0's binary_logloss: 0.126777	valid_1's auc: 0.834173	valid_1's binary_logloss: 0.140887
[23]	valid_0's auc: 0.867726	valid_0's binary_logloss: 0.12643	valid_1's auc: 0.833577	valid_1's binary_logloss: 0.140909
[24]	valid_0's auc: 0.868612	valid_0's binary_logloss: 0.126061	valid_1's auc: 0.833336	valid_1's binary_logloss: 0.140824
[25]	valid_0's auc: 0.869224	valid_0's binary_logloss: 0.125753	valid_1's auc: 0.833428	valid_1's binary_logloss: 0.140793
[26]	valid_0's auc: 0.870183	valid_0's binary_logloss: 0.125414	valid_1's auc: 0.83333	valid_1's binary_logloss: 0.140724
[27]	valid_0's auc: 0.870926	valid_0's binary_logloss: 0.125123	valid_1's auc: 0.832503	valid_1's binary_logloss: 0.140772
[28]	valid_0's auc: 0.872431	valid_0's binary_logloss: 0.124766	valid_1's auc: 0.832826	valid_1's binary_logloss: 0.140685
[29]	valid_0's auc: 0.873397	valid_0's binary_logloss: 0.124495	valid_1's auc: 0.833175	valid_1's binary_logloss: 0.140604
[30]	valid_0's auc: 0.87475	valid_0's binary_logloss: 0.12417	valid_1's auc: 0.833614	valid_1's binary_logloss: 0.140497
[31]	valid_0's auc: 0.875407	valid_0's binary_logloss: 0.12389	valid_1's auc: 0.833706	valid_1's binary_logloss: 0.140428
[32]	valid_0's auc: 0.876136	valid_0's binary_logloss: 0.123637	valid_1's auc: 0.833458	valid_1's binary_logloss: 0.140448
[33]	valid_0's auc: 0.876575	valid_0's binary_logloss: 0.123421	valid_1's auc: 0.832965	valid_1's binary_logloss: 0.140498
[34]	valid_0's auc: 0.877224	valid_0's binary_logloss: 0.123219	valid_1's auc: 0.832659	valid_1's binary_logloss: 0.140537
[35]	valid_0's auc: 0.877898	valid_0's binary_logloss: 0.122947	valid_1's auc: 0.832787	valid_1's binary_logloss: 0.140536
[36]	valid_0's auc: 0.878334	valid_0's binary_logloss: 0.122724	valid_1's auc: 0.832724	valid_1's binary_logloss: 0.14053
[37]	valid_0's auc: 0.878762	valid_0's binary_logloss: 0.122514	valid_1's auc: 0.832581	valid_1's binary_logloss: 0.140533
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.814371	valid_0's binary_logloss: 0.156452	valid_1's auc: 0.813175	valid_1's binary_logloss: 0.165418
[2]	valid_0's auc: 0.827277	valid_0's binary_logloss: 0.151084	valid_1's auc: 0.819635	valid_1's binary_logloss: 0.160159
[3]	valid_0's auc: 0.837033	valid_0's binary_logloss: 0.14722	valid_1's auc: 0.828221	valid_1's binary_logloss: 0.156492
[4]	valid_0's auc: 0.840167	valid_0's binary_logloss: 0.14423	valid_1's auc: 0.830942	valid_1's binary_logloss: 0.153586
[5]	valid_0's auc: 0.842499	valid_0's binary_logloss: 0.141721	valid_1's auc: 0.833301	valid_1's binary_logloss: 0.151219
[6]	valid_0's auc: 0.845403	valid_0's binary_logloss: 0.139708	valid_1's auc: 0.836412	valid_1's binary_logloss: 0.149312
[7]	valid_0's auc: 0.848049	valid_0's binary_logloss: 0.138024	valid_1's auc: 0.836054	valid_1's binary_logloss: 0.14779
[8]	valid_0's auc: 0.849694	valid_0's binary_logloss: 0.136542	valid_1's auc: 0.837537	valid_1's binary_logloss: 0.146417
[9]	valid_0's auc: 0.851646	valid_0's binary_logloss: 0.135289	valid_1's auc: 0.838418	valid_1's binary_logloss: 0.145329
[10]	valid_0's auc: 0.853642	valid_0's binary_logloss: 0.134189	valid_1's auc: 0.839342	valid_1's binary_logloss: 0.144374
[11]	valid_0's auc: 0.855647	valid_0's binary_logloss: 0.133227	valid_1's auc: 0.840035	valid_1's binary_logloss: 0.143552
[12]	valid_0's auc: 0.856768	valid_0's binary_logloss: 0.132399	valid_1's auc: 0.839294	valid_1's binary_logloss: 0.143047
[13]	valid_0's auc: 0.85763	valid_0's binary_logloss: 0.13165	valid_1's auc: 0.838911	valid_1's binary_logloss: 0.142469
[14]	valid_0's auc: 0.859243	valid_0's binary_logloss: 0.130936	valid_1's auc: 0.838705	valid_1's binary_logloss: 0.141913
[15]	valid_0's auc: 0.860124	valid_0's binary_logloss: 0.130312	valid_1's auc: 0.838608	valid_1's binary_logloss: 0.141547
[16]	valid_0's auc: 0.861358	valid_0's binary_logloss: 0.129687	valid_1's auc: 0.838422	valid_1's binary_logloss: 0.141134
[17]	valid_0's auc: 0.862159	valid_0's binary_logloss: 0.129139	valid_1's auc: 0.838636	valid_1's binary_logloss: 0.140786
[18]	valid_0's auc: 0.862729	valid_0's binary_logloss: 0.128664	valid_1's auc: 0.838342	valid_1's binary_logloss: 0.140538
[19]	valid_0's auc: 0.863842	valid_0's binary_logloss: 0.128137	valid_1's auc: 0.838464	valid_1's binary_logloss: 0.140331
[20]	valid_0's auc: 0.864859	valid_0's binary_logloss: 0.127657	valid_1's auc: 0.837832	valid_1's binary_logloss: 0.140179
[21]	valid_0's auc: 0.866227	valid_0's binary_logloss: 0.127137	valid_1's auc: 0.837735	valid_1's binary_logloss: 0.140043
[22]	valid_0's auc: 0.866925	valid_0's binary_logloss: 0.126772	valid_1's auc: 0.838268	valid_1's binary_logloss: 0.139927
[23]	valid_0's auc: 0.867727	valid_0's binary_logloss: 0.126369	valid_1's auc: 0.838482	valid_1's binary_logloss: 0.139787
[24]	valid_0's auc: 0.868239	valid_0's binary_logloss: 0.126013	valid_1's auc: 0.838767	valid_1's binary_logloss: 0.13964
[25]	valid_0's auc: 0.869304	valid_0's binary_logloss: 0.125622	valid_1's auc: 0.838562	valid_1's binary_logloss: 0.139648
[26]	valid_0's auc: 0.870347	valid_0's binary_logloss: 0.125288	valid_1's auc: 0.838228	valid_1's binary_logloss: 0.139618
[27]	valid_0's auc: 0.871198	valid_0's binary_logloss: 0.124953	valid_1's auc: 0.838403	valid_1's binary_logloss: 0.139594
[28]	valid_0's auc: 0.872024	valid_0's binary_logloss: 0.124672	valid_1's auc: 0.838405	valid_1's binary_logloss: 0.139526
[29]	valid_0's auc: 0.873184	valid_0's binary_logloss: 0.124303	valid_1's auc: 0.838211	valid_1's binary_logloss: 0.139531
[30]	valid_0's auc: 0.874076	valid_0's binary_logloss: 0.12403	valid_1's auc: 0.838983	valid_1's binary_logloss: 0.139411
[31]	valid_0's auc: 0.874768	valid_0's binary_logloss: 0.123745	valid_1's auc: 0.839314	valid_1's binary_logloss: 0.139314
[32]	valid_0's auc: 0.875593	valid_0's binary_logloss: 0.123486	valid_1's auc: 0.838875	valid_1's binary_logloss: 0.139322
[33]	valid_0's auc: 0.8767	valid_0's binary_logloss: 0.123182	valid_1's auc: 0.838809	valid_1's binary_logloss: 0.139329
[34]	valid_0's auc: 0.87774	valid_0's binary_logloss: 0.122892	valid_1's auc: 0.838376	valid_1's binary_logloss: 0.139342
[35]	valid_0's auc: 0.878372	valid_0's binary_logloss: 0.122634	valid_1's auc: 0.838454	valid_1's binary_logloss: 0.13931
[36]	valid_0's auc: 0.879098	valid_0's binary_logloss: 0.122414	valid_1's auc: 0.838895	valid_1's binary_logloss: 0.13925
[37]	valid_0's auc: 0.879502	valid_0's binary_logloss: 0.122216	valid_1's auc: 0.838441	valid_1's binary_logloss: 0.139302
[38]	valid_0's auc: 0.880036	valid_0's binary_logloss: 0.121998	valid_1's auc: 0.838582	valid_1's binary_logloss: 0.139306
[39]	valid_0's auc: 0.880641	valid_0's binary_logloss: 0.121716	valid_1's auc: 0.838787	valid_1's binary_logloss: 0.139269
[40]	valid_0's auc: 0.881249	valid_0's binary_logloss: 0.121482	valid_1's auc: 0.838906	valid_1's binary_logloss: 0.139223
[41]	valid_0's auc: 0.881919	valid_0's binary_logloss: 0.121223	valid_1's auc: 0.838567	valid_1's binary_logloss: 0.13926
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.821645	valid_0's binary_logloss: 0.156528	valid_1's auc: 0.81857	valid_1's binary_logloss: 0.165101
[2]	valid_0's auc: 0.827488	valid_0's binary_logloss: 0.151189	valid_1's auc: 0.822299	valid_1's binary_logloss: 0.160072
[3]	valid_0's auc: 0.837855	valid_0's binary_logloss: 0.147263	valid_1's auc: 0.829855	valid_1's binary_logloss: 0.156527
[4]	valid_0's auc: 0.840063	valid_0's binary_logloss: 0.144261	valid_1's auc: 0.833088	valid_1's binary_logloss: 0.153446
[5]	valid_0's auc: 0.842802	valid_0's binary_logloss: 0.141691	valid_1's auc: 0.834541	valid_1's binary_logloss: 0.151144
[6]	valid_0's auc: 0.844	valid_0's binary_logloss: 0.139654	valid_1's auc: 0.834542	valid_1's binary_logloss: 0.149333
[7]	valid_0's auc: 0.845838	valid_0's binary_logloss: 0.138002	valid_1's auc: 0.835645	valid_1's binary_logloss: 0.147676
[8]	valid_0's auc: 0.846869	valid_0's binary_logloss: 0.136628	valid_1's auc: 0.836118	valid_1's binary_logloss: 0.146491
[9]	valid_0's auc: 0.849282	valid_0's binary_logloss: 0.135382	valid_1's auc: 0.837542	valid_1's binary_logloss: 0.14539
[10]	valid_0's auc: 0.851021	valid_0's binary_logloss: 0.134282	valid_1's auc: 0.836942	valid_1's binary_logloss: 0.144584
[11]	valid_0's auc: 0.852037	valid_0's binary_logloss: 0.133358	valid_1's auc: 0.8374	valid_1's binary_logloss: 0.143836
[12]	valid_0's auc: 0.854496	valid_0's binary_logloss: 0.132505	valid_1's auc: 0.838593	valid_1's binary_logloss: 0.143171
[13]	valid_0's auc: 0.857514	valid_0's binary_logloss: 0.131695	valid_1's auc: 0.838558	valid_1's binary_logloss: 0.142646
[14]	valid_0's auc: 0.858827	valid_0's binary_logloss: 0.131006	valid_1's auc: 0.838498	valid_1's binary_logloss: 0.142158
[15]	valid_0's auc: 0.860574	valid_0's binary_logloss: 0.130352	valid_1's auc: 0.837435	valid_1's binary_logloss: 0.141868
[16]	valid_0's auc: 0.861239	valid_0's binary_logloss: 0.129765	valid_1's auc: 0.837374	valid_1's binary_logloss: 0.141537
[17]	valid_0's auc: 0.86217	valid_0's binary_logloss: 0.129164	valid_1's auc: 0.837703	valid_1's binary_logloss: 0.141192
[18]	valid_0's auc: 0.863228	valid_0's binary_logloss: 0.128615	valid_1's auc: 0.837526	valid_1's binary_logloss: 0.140917
[19]	valid_0's auc: 0.86473	valid_0's binary_logloss: 0.128113	valid_1's auc: 0.838235	valid_1's binary_logloss: 0.140572
[20]	valid_0's auc: 0.865797	valid_0's binary_logloss: 0.127679	valid_1's auc: 0.838788	valid_1's binary_logloss: 0.140332
[21]	valid_0's auc: 0.866561	valid_0's binary_logloss: 0.127235	valid_1's auc: 0.839171	valid_1's binary_logloss: 0.140108
[22]	valid_0's auc: 0.867237	valid_0's binary_logloss: 0.12688	valid_1's auc: 0.839213	valid_1's binary_logloss: 0.13991
[23]	valid_0's auc: 0.867894	valid_0's binary_logloss: 0.126519	valid_1's auc: 0.839641	valid_1's binary_logloss: 0.139745
[24]	valid_0's auc: 0.868501	valid_0's binary_logloss: 0.126192	valid_1's auc: 0.840025	valid_1's binary_logloss: 0.139593
[25]	valid_0's auc: 0.869311	valid_0's binary_logloss: 0.125838	valid_1's auc: 0.839961	valid_1's binary_logloss: 0.139531
[26]	valid_0's auc: 0.870325	valid_0's binary_logloss: 0.125518	valid_1's auc: 0.839261	valid_1's binary_logloss: 0.139524
[27]	valid_0's auc: 0.871488	valid_0's binary_logloss: 0.125147	valid_1's auc: 0.839671	valid_1's binary_logloss: 0.139365
[28]	valid_0's auc: 0.87235	valid_0's binary_logloss: 0.12484	valid_1's auc: 0.840114	valid_1's binary_logloss: 0.139236
[29]	valid_0's auc: 0.872991	valid_0's binary_logloss: 0.124593	valid_1's auc: 0.839491	valid_1's binary_logloss: 0.139271
[30]	valid_0's auc: 0.874129	valid_0's binary_logloss: 0.124312	valid_1's auc: 0.839589	valid_1's binary_logloss: 0.13918
[31]	valid_0's auc: 0.875305	valid_0's binary_logloss: 0.123988	valid_1's auc: 0.839441	valid_1's binary_logloss: 0.139184
[32]	valid_0's auc: 0.875943	valid_0's binary_logloss: 0.123748	valid_1's auc: 0.839268	valid_1's binary_logloss: 0.13919
[33]	valid_0's auc: 0.876575	valid_0's binary_logloss: 0.123484	valid_1's auc: 0.839549	valid_1's binary_logloss: 0.139075
[34]	valid_0's auc: 0.877426	valid_0's binary_logloss: 0.123156	valid_1's auc: 0.839087	valid_1's binary_logloss: 0.139148
[35]	valid_0's auc: 0.87822	valid_0's binary_logloss: 0.122873	valid_1's auc: 0.8389	valid_1's binary_logloss: 0.139187
[36]	valid_0's auc: 0.878932	valid_0's binary_logloss: 0.12259	valid_1's auc: 0.838921	valid_1's binary_logloss: 0.139194
[37]	valid_0's auc: 0.879842	valid_0's binary_logloss: 0.12233	valid_1's auc: 0.839133	valid_1's binary_logloss: 0.139161
[38]	valid_0's auc: 0.880497	valid_0's binary_logloss: 0.12208	valid_1's auc: 0.838975	valid_1's binary_logloss: 0.139143
[39]	valid_0's auc: 0.881056	valid_0's binary_logloss: 0.121827	valid_1's auc: 0.839037	valid_1's binary_logloss: 0.139138
[40]	valid_0's auc: 0.881604	valid_0's binary_logloss: 0.121603	valid_1's auc: 0.839204	valid_1's binary_logloss: 0.139119
[41]	valid_0's auc: 0.882159	valid_0's binary_logloss: 0.121355	valid_1's auc: 0.839277	valid_1's binary_logloss: 0.139091
[42]	valid_0's auc: 0.882757	valid_0's binary_logloss: 0.121116	valid_1's auc: 0.838964	valid_1's binary_logloss: 0.139133
[43]	valid_0's auc: 0.883143	valid_0's binary_logloss: 0.120918	valid_1's auc: 0.839024	valid_1's binary_logloss: 0.139124
[44]	valid_0's auc: 0.883697	valid_0's binary_logloss: 0.12072	valid_1's auc: 0.838652	valid_1's binary_logloss: 0.139203
[45]	valid_0's auc: 0.884292	valid_0's binary_logloss: 0.120482	valid_1's auc: 0.839016	valid_1's binary_logloss: 0.139124
[46]	valid_0's auc: 0.884969	valid_0's binary_logloss: 0.120266	valid_1's auc: 0.838683	valid_1's binary_logloss: 0.139184
[47]	valid_0's auc: 0.8853	valid_0's binary_logloss: 0.120089	valid_1's auc: 0.838624	valid_1's binary_logloss: 0.139193
[48]	valid_0's auc: 0.885876	valid_0's binary_logloss: 0.11993	valid_1's auc: 0.838569	valid_1's binary_logloss: 0.139212
[49]	valid_0's auc: 0.886141	valid_0's binary_logloss: 0.119757	valid_1's auc: 0.838345	valid_1's binary_logloss: 0.139288
[50]	valid_0's auc: 0.886433	valid_0's binary_logloss: 0.119595	valid_1's auc: 0.838342	valid_1's binary_logloss: 0.139332
[51]	valid_0's auc: 0.886975	valid_0's binary_logloss: 0.119377	valid_1's auc: 0.838335	valid_1's binary_logloss: 0.139331
[52]	valid_0's auc: 0.887568	valid_0's binary_logloss: 0.119161	valid_1's auc: 0.838204	valid_1's binary_logloss: 0.139331
[53]	valid_0's auc: 0.887867	valid_0's binary_logloss: 0.118974	valid_1's auc: 0.838044	valid_1's binary_logloss: 0.13936
[54]	valid_0's auc: 0.888093	valid_0's binary_logloss: 0.118834	valid_1's auc: 0.838137	valid_1's binary_logloss: 0.13935
[55]	valid_0's auc: 0.888289	valid_0's binary_logloss: 0.118675	valid_1's auc: 0.837878	valid_1's binary_logloss: 0.139392
[56]	valid_0's auc: 0.888615	valid_0's binary_logloss: 0.118561	valid_1's auc: 0.837776	valid_1's binary_logloss: 0.139418
[57]	valid_0's auc: 0.889157	valid_0's binary_logloss: 0.118369	valid_1's auc: 0.837585	valid_1's binary_logloss: 0.139447
[58]	valid_0's auc: 0.889659	valid_0's binary_logloss: 0.11819	valid_1's auc: 0.837789	valid_1's binary_logloss: 0.139431
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.832891	valid_0's binary_logloss: 0.155302	valid_1's auc: 0.818851	valid_1's binary_logloss: 0.164826
[2]	valid_0's auc: 0.84519	valid_0's binary_logloss: 0.149727	valid_1's auc: 0.827144	valid_1's binary_logloss: 0.159879
[3]	valid_0's auc: 0.848018	valid_0's binary_logloss: 0.145627	valid_1's auc: 0.826851	valid_1's binary_logloss: 0.15631
[4]	valid_0's auc: 0.851096	valid_0's binary_logloss: 0.142423	valid_1's auc: 0.83073	valid_1's binary_logloss: 0.1534
[5]	valid_0's auc: 0.854735	valid_0's binary_logloss: 0.139746	valid_1's auc: 0.832753	valid_1's binary_logloss: 0.151136
[6]	valid_0's auc: 0.856928	valid_0's binary_logloss: 0.137509	valid_1's auc: 0.835605	valid_1's binary_logloss: 0.14924
[7]	valid_0's auc: 0.859448	valid_0's binary_logloss: 0.135575	valid_1's auc: 0.835612	valid_1's binary_logloss: 0.147799
[8]	valid_0's auc: 0.861685	valid_0's binary_logloss: 0.133953	valid_1's auc: 0.834408	valid_1's binary_logloss: 0.146634
[9]	valid_0's auc: 0.863391	valid_0's binary_logloss: 0.132468	valid_1's auc: 0.835623	valid_1's binary_logloss: 0.145549
[10]	valid_0's auc: 0.865858	valid_0's binary_logloss: 0.131185	valid_1's auc: 0.83487	valid_1's binary_logloss: 0.144745
[11]	valid_0's auc: 0.867134	valid_0's binary_logloss: 0.130116	valid_1's auc: 0.834692	valid_1's binary_logloss: 0.14411
[12]	valid_0's auc: 0.868217	valid_0's binary_logloss: 0.129097	valid_1's auc: 0.834746	valid_1's binary_logloss: 0.143527
[13]	valid_0's auc: 0.87073	valid_0's binary_logloss: 0.128129	valid_1's auc: 0.833582	valid_1's binary_logloss: 0.143122
[14]	valid_0's auc: 0.872621	valid_0's binary_logloss: 0.12721	valid_1's auc: 0.833205	valid_1's binary_logloss: 0.142745
[15]	valid_0's auc: 0.874007	valid_0's binary_logloss: 0.126363	valid_1's auc: 0.83246	valid_1's binary_logloss: 0.142489
[16]	valid_0's auc: 0.875141	valid_0's binary_logloss: 0.125606	valid_1's auc: 0.831958	valid_1's binary_logloss: 0.142275
[17]	valid_0's auc: 0.876061	valid_0's binary_logloss: 0.124928	valid_1's auc: 0.831586	valid_1's binary_logloss: 0.142141
[18]	valid_0's auc: 0.876982	valid_0's binary_logloss: 0.124313	valid_1's auc: 0.830954	valid_1's binary_logloss: 0.142066
[19]	valid_0's auc: 0.877885	valid_0's binary_logloss: 0.123709	valid_1's auc: 0.830572	valid_1's binary_logloss: 0.14196
[20]	valid_0's auc: 0.879378	valid_0's binary_logloss: 0.123088	valid_1's auc: 0.830076	valid_1's binary_logloss: 0.14196
[21]	valid_0's auc: 0.880647	valid_0's binary_logloss: 0.122488	valid_1's auc: 0.830109	valid_1's binary_logloss: 0.141858
[22]	valid_0's auc: 0.881614	valid_0's binary_logloss: 0.121973	valid_1's auc: 0.829735	valid_1's binary_logloss: 0.141822
[23]	valid_0's auc: 0.882402	valid_0's binary_logloss: 0.121554	valid_1's auc: 0.829254	valid_1's binary_logloss: 0.141805
[24]	valid_0's auc: 0.883011	valid_0's binary_logloss: 0.121078	valid_1's auc: 0.829054	valid_1's binary_logloss: 0.14178
[25]	valid_0's auc: 0.884627	valid_0's binary_logloss: 0.120587	valid_1's auc: 0.82942	valid_1's binary_logloss: 0.141653
[26]	valid_0's auc: 0.885304	valid_0's binary_logloss: 0.120169	valid_1's auc: 0.828716	valid_1's binary_logloss: 0.141755
[27]	valid_0's auc: 0.88664	valid_0's binary_logloss: 0.119673	valid_1's auc: 0.828869	valid_1's binary_logloss: 0.141682
[28]	valid_0's auc: 0.887143	valid_0's binary_logloss: 0.119308	valid_1's auc: 0.828987	valid_1's binary_logloss: 0.141649
[29]	valid_0's auc: 0.88825	valid_0's binary_logloss: 0.1189	valid_1's auc: 0.829075	valid_1's binary_logloss: 0.141601
[30]	valid_0's auc: 0.889081	valid_0's binary_logloss: 0.118531	valid_1's auc: 0.828871	valid_1's binary_logloss: 0.141605
[31]	valid_0's auc: 0.890195	valid_0's binary_logloss: 0.118117	valid_1's auc: 0.828972	valid_1's binary_logloss: 0.141605
[32]	valid_0's auc: 0.890928	valid_0's binary_logloss: 0.117735	valid_1's auc: 0.827969	valid_1's binary_logloss: 0.141796
[33]	valid_0's auc: 0.891505	valid_0's binary_logloss: 0.117389	valid_1's auc: 0.827611	valid_1's binary_logloss: 0.141916
[34]	valid_0's auc: 0.892223	valid_0's binary_logloss: 0.11707	valid_1's auc: 0.827019	valid_1's binary_logloss: 0.142051
[35]	valid_0's auc: 0.892825	valid_0's binary_logloss: 0.116751	valid_1's auc: 0.826865	valid_1's binary_logloss: 0.142116
[36]	valid_0's auc: 0.893984	valid_0's binary_logloss: 0.116353	valid_1's auc: 0.827203	valid_1's binary_logloss: 0.14207
[37]	valid_0's auc: 0.89456	valid_0's binary_logloss: 0.11603	valid_1's auc: 0.827292	valid_1's binary_logloss: 0.142005
[38]	valid_0's auc: 0.89511	valid_0's binary_logloss: 0.115713	valid_1's auc: 0.827214	valid_1's binary_logloss: 0.14206
[39]	valid_0's auc: 0.895738	valid_0's binary_logloss: 0.115415	valid_1's auc: 0.82695	valid_1's binary_logloss: 0.142162
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.833054	valid_0's binary_logloss: 0.15572	valid_1's auc: 0.817048	valid_1's binary_logloss: 0.165036
[2]	valid_0's auc: 0.841397	valid_0's binary_logloss: 0.149862	valid_1's auc: 0.82157	valid_1's binary_logloss: 0.159575
[3]	valid_0's auc: 0.849058	valid_0's binary_logloss: 0.145662	valid_1's auc: 0.829866	valid_1's binary_logloss: 0.155774
[4]	valid_0's auc: 0.854301	valid_0's binary_logloss: 0.142356	valid_1's auc: 0.832415	valid_1's binary_logloss: 0.152936
[5]	valid_0's auc: 0.858045	valid_0's binary_logloss: 0.139697	valid_1's auc: 0.834554	valid_1's binary_logloss: 0.150635
[6]	valid_0's auc: 0.860767	valid_0's binary_logloss: 0.137458	valid_1's auc: 0.834885	valid_1's binary_logloss: 0.148761
[7]	valid_0's auc: 0.863011	valid_0's binary_logloss: 0.135522	valid_1's auc: 0.835812	valid_1's binary_logloss: 0.147245
[8]	valid_0's auc: 0.864923	valid_0's binary_logloss: 0.133792	valid_1's auc: 0.836656	valid_1's binary_logloss: 0.145923
[9]	valid_0's auc: 0.865706	valid_0's binary_logloss: 0.13236	valid_1's auc: 0.836912	valid_1's binary_logloss: 0.144867
[10]	valid_0's auc: 0.867693	valid_0's binary_logloss: 0.131066	valid_1's auc: 0.837266	valid_1's binary_logloss: 0.143895
[11]	valid_0's auc: 0.868596	valid_0's binary_logloss: 0.129937	valid_1's auc: 0.836466	valid_1's binary_logloss: 0.143255
[12]	valid_0's auc: 0.87012	valid_0's binary_logloss: 0.128904	valid_1's auc: 0.836589	valid_1's binary_logloss: 0.142728
[13]	valid_0's auc: 0.871703	valid_0's binary_logloss: 0.127913	valid_1's auc: 0.836567	valid_1's binary_logloss: 0.142105
[14]	valid_0's auc: 0.873468	valid_0's binary_logloss: 0.126983	valid_1's auc: 0.835538	valid_1's binary_logloss: 0.141771
[15]	valid_0's auc: 0.874839	valid_0's binary_logloss: 0.126147	valid_1's auc: 0.835363	valid_1's binary_logloss: 0.141464
[16]	valid_0's auc: 0.876399	valid_0's binary_logloss: 0.125331	valid_1's auc: 0.83478	valid_1's binary_logloss: 0.141245
[17]	valid_0's auc: 0.877465	valid_0's binary_logloss: 0.124655	valid_1's auc: 0.834621	valid_1's binary_logloss: 0.141028
[18]	valid_0's auc: 0.878935	valid_0's binary_logloss: 0.123944	valid_1's auc: 0.834165	valid_1's binary_logloss: 0.140935
[19]	valid_0's auc: 0.88046	valid_0's binary_logloss: 0.123313	valid_1's auc: 0.834629	valid_1's binary_logloss: 0.140738
[20]	valid_0's auc: 0.881517	valid_0's binary_logloss: 0.12269	valid_1's auc: 0.8347	valid_1's binary_logloss: 0.140611
[21]	valid_0's auc: 0.882464	valid_0's binary_logloss: 0.122095	valid_1's auc: 0.834656	valid_1's binary_logloss: 0.140487
[22]	valid_0's auc: 0.883744	valid_0's binary_logloss: 0.121504	valid_1's auc: 0.834562	valid_1's binary_logloss: 0.140328
[23]	valid_0's auc: 0.885301	valid_0's binary_logloss: 0.12091	valid_1's auc: 0.835278	valid_1's binary_logloss: 0.140199
[24]	valid_0's auc: 0.886266	valid_0's binary_logloss: 0.120437	valid_1's auc: 0.835728	valid_1's binary_logloss: 0.140094
[25]	valid_0's auc: 0.88755	valid_0's binary_logloss: 0.119931	valid_1's auc: 0.836199	valid_1's binary_logloss: 0.140076
[26]	valid_0's auc: 0.888525	valid_0's binary_logloss: 0.119473	valid_1's auc: 0.836708	valid_1's binary_logloss: 0.139945
[27]	valid_0's auc: 0.889589	valid_0's binary_logloss: 0.119012	valid_1's auc: 0.836951	valid_1's binary_logloss: 0.139843
[28]	valid_0's auc: 0.890552	valid_0's binary_logloss: 0.118602	valid_1's auc: 0.836524	valid_1's binary_logloss: 0.139871
[29]	valid_0's auc: 0.891402	valid_0's binary_logloss: 0.118166	valid_1's auc: 0.836264	valid_1's binary_logloss: 0.139884
[30]	valid_0's auc: 0.891982	valid_0's binary_logloss: 0.117805	valid_1's auc: 0.835959	valid_1's binary_logloss: 0.139937
[31]	valid_0's auc: 0.893185	valid_0's binary_logloss: 0.117392	valid_1's auc: 0.836384	valid_1's binary_logloss: 0.13992
[32]	valid_0's auc: 0.894065	valid_0's binary_logloss: 0.117017	valid_1's auc: 0.836341	valid_1's binary_logloss: 0.139888
[33]	valid_0's auc: 0.894791	valid_0's binary_logloss: 0.116671	valid_1's auc: 0.836753	valid_1's binary_logloss: 0.139812
[34]	valid_0's auc: 0.895313	valid_0's binary_logloss: 0.116321	valid_1's auc: 0.836733	valid_1's binary_logloss: 0.139826
[35]	valid_0's auc: 0.895876	valid_0's binary_logloss: 0.116039	valid_1's auc: 0.836245	valid_1's binary_logloss: 0.139883
[36]	valid_0's auc: 0.896909	valid_0's binary_logloss: 0.115684	valid_1's auc: 0.836079	valid_1's binary_logloss: 0.139912
[37]	valid_0's auc: 0.897427	valid_0's binary_logloss: 0.115388	valid_1's auc: 0.835564	valid_1's binary_logloss: 0.140024
[38]	valid_0's auc: 0.898442	valid_0's binary_logloss: 0.115006	valid_1's auc: 0.835612	valid_1's binary_logloss: 0.140075
[39]	valid_0's auc: 0.899304	valid_0's binary_logloss: 0.114592	valid_1's auc: 0.836273	valid_1's binary_logloss: 0.139974
[40]	valid_0's auc: 0.89974	valid_0's binary_logloss: 0.11432	valid_1's auc: 0.836096	valid_1's binary_logloss: 0.140042
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.830643	valid_0's binary_logloss: 0.155759	valid_1's auc: 0.816734	valid_1's binary_logloss: 0.164985
[2]	valid_0's auc: 0.839353	valid_0's binary_logloss: 0.149977	valid_1's auc: 0.822571	valid_1's binary_logloss: 0.159808
[3]	valid_0's auc: 0.847366	valid_0's binary_logloss: 0.145866	valid_1's auc: 0.829312	valid_1's binary_logloss: 0.156171
[4]	valid_0's auc: 0.850911	valid_0's binary_logloss: 0.14247	valid_1's auc: 0.830848	valid_1's binary_logloss: 0.153328
[5]	valid_0's auc: 0.854674	valid_0's binary_logloss: 0.139764	valid_1's auc: 0.833041	valid_1's binary_logloss: 0.151023
[6]	valid_0's auc: 0.856722	valid_0's binary_logloss: 0.1375	valid_1's auc: 0.834264	valid_1's binary_logloss: 0.149166
[7]	valid_0's auc: 0.858253	valid_0's binary_logloss: 0.135713	valid_1's auc: 0.834998	valid_1's binary_logloss: 0.147631
[8]	valid_0's auc: 0.859768	valid_0's binary_logloss: 0.134063	valid_1's auc: 0.835678	valid_1's binary_logloss: 0.146384
[9]	valid_0's auc: 0.86262	valid_0's binary_logloss: 0.132622	valid_1's auc: 0.836272	valid_1's binary_logloss: 0.145313
[10]	valid_0's auc: 0.864631	valid_0's binary_logloss: 0.131324	valid_1's auc: 0.835827	valid_1's binary_logloss: 0.144553
[11]	valid_0's auc: 0.866805	valid_0's binary_logloss: 0.130172	valid_1's auc: 0.835375	valid_1's binary_logloss: 0.143933
[12]	valid_0's auc: 0.868266	valid_0's binary_logloss: 0.129101	valid_1's auc: 0.835951	valid_1's binary_logloss: 0.143342
[13]	valid_0's auc: 0.870762	valid_0's binary_logloss: 0.128144	valid_1's auc: 0.83626	valid_1's binary_logloss: 0.142813
[14]	valid_0's auc: 0.872747	valid_0's binary_logloss: 0.127222	valid_1's auc: 0.835864	valid_1's binary_logloss: 0.142466
[15]	valid_0's auc: 0.874158	valid_0's binary_logloss: 0.126428	valid_1's auc: 0.83548	valid_1's binary_logloss: 0.142108
[16]	valid_0's auc: 0.875931	valid_0's binary_logloss: 0.125651	valid_1's auc: 0.836367	valid_1's binary_logloss: 0.141684
[17]	valid_0's auc: 0.876854	valid_0's binary_logloss: 0.124918	valid_1's auc: 0.835689	valid_1's binary_logloss: 0.141524
[18]	valid_0's auc: 0.878211	valid_0's binary_logloss: 0.124197	valid_1's auc: 0.835893	valid_1's binary_logloss: 0.141285
[19]	valid_0's auc: 0.879125	valid_0's binary_logloss: 0.123553	valid_1's auc: 0.835877	valid_1's binary_logloss: 0.141128
[20]	valid_0's auc: 0.880489	valid_0's binary_logloss: 0.122856	valid_1's auc: 0.835385	valid_1's binary_logloss: 0.141032
[21]	valid_0's auc: 0.881696	valid_0's binary_logloss: 0.122219	valid_1's auc: 0.835822	valid_1's binary_logloss: 0.140843
[22]	valid_0's auc: 0.882257	valid_0's binary_logloss: 0.121726	valid_1's auc: 0.835849	valid_1's binary_logloss: 0.140761
[23]	valid_0's auc: 0.883635	valid_0's binary_logloss: 0.121206	valid_1's auc: 0.836223	valid_1's binary_logloss: 0.140607
[24]	valid_0's auc: 0.884533	valid_0's binary_logloss: 0.120734	valid_1's auc: 0.836473	valid_1's binary_logloss: 0.14049
[25]	valid_0's auc: 0.885234	valid_0's binary_logloss: 0.120268	valid_1's auc: 0.836722	valid_1's binary_logloss: 0.140403
[26]	valid_0's auc: 0.886292	valid_0's binary_logloss: 0.119794	valid_1's auc: 0.836549	valid_1's binary_logloss: 0.140423
[27]	valid_0's auc: 0.887064	valid_0's binary_logloss: 0.119366	valid_1's auc: 0.836155	valid_1's binary_logloss: 0.140447
[28]	valid_0's auc: 0.887621	valid_0's binary_logloss: 0.119008	valid_1's auc: 0.835594	valid_1's binary_logloss: 0.140532
[29]	valid_0's auc: 0.888965	valid_0's binary_logloss: 0.118547	valid_1's auc: 0.835464	valid_1's binary_logloss: 0.140508
[30]	valid_0's auc: 0.889898	valid_0's binary_logloss: 0.118139	valid_1's auc: 0.83577	valid_1's binary_logloss: 0.140461
[31]	valid_0's auc: 0.890896	valid_0's binary_logloss: 0.117734	valid_1's auc: 0.835475	valid_1's binary_logloss: 0.140463
[32]	valid_0's auc: 0.892374	valid_0's binary_logloss: 0.1173	valid_1's auc: 0.835364	valid_1's binary_logloss: 0.140506
[33]	valid_0's auc: 0.893164	valid_0's binary_logloss: 0.116978	valid_1's auc: 0.835865	valid_1's binary_logloss: 0.14041
[34]	valid_0's auc: 0.893848	valid_0's binary_logloss: 0.11662	valid_1's auc: 0.836021	valid_1's binary_logloss: 0.140353
[35]	valid_0's auc: 0.894232	valid_0's binary_logloss: 0.116323	valid_1's auc: 0.8359	valid_1's binary_logloss: 0.140396
[36]	valid_0's auc: 0.895003	valid_0's binary_logloss: 0.115986	valid_1's auc: 0.835855	valid_1's binary_logloss: 0.140416
[37]	valid_0's auc: 0.895898	valid_0's binary_logloss: 0.115609	valid_1's auc: 0.836185	valid_1's binary_logloss: 0.140369
[38]	valid_0's auc: 0.896459	valid_0's binary_logloss: 0.11527	valid_1's auc: 0.835754	valid_1's binary_logloss: 0.140443
[39]	valid_0's auc: 0.897377	valid_0's binary_logloss: 0.114873	valid_1's auc: 0.835638	valid_1's binary_logloss: 0.140474
[40]	valid_0's auc: 0.89776	valid_0's binary_logloss: 0.114588	valid_1's auc: 0.835639	valid_1's binary_logloss: 0.140491
[41]	valid_0's auc: 0.898583	valid_0's binary_logloss: 0.114302	valid_1's auc: 0.835705	valid_1's binary_logloss: 0.140506
[42]	valid_0's auc: 0.899197	valid_0's binary_logloss: 0.113975	valid_1's auc: 0.835052	valid_1's binary_logloss: 0.14064
[43]	valid_0's auc: 0.899803	valid_0's binary_logloss: 0.113654	valid_1's auc: 0.835035	valid_1's binary_logloss: 0.140691
[44]	valid_0's auc: 0.900641	valid_0's binary_logloss: 0.113388	valid_1's auc: 0.835214	valid_1's binary_logloss: 0.140703
[45]	valid_0's auc: 0.900962	valid_0's binary_logloss: 0.113098	valid_1's auc: 0.835276	valid_1's binary_logloss: 0.140695
[46]	valid_0's auc: 0.901584	valid_0's binary_logloss: 0.112771	valid_1's auc: 0.83495	valid_1's binary_logloss: 0.140754
[47]	valid_0's auc: 0.902256	valid_0's binary_logloss: 0.112493	valid_1's auc: 0.835639	valid_1's binary_logloss: 0.14064
[48]	valid_0's auc: 0.902688	valid_0's binary_logloss: 0.112198	valid_1's auc: 0.835495	valid_1's binary_logloss: 0.140691
[49]	valid_0's auc: 0.902922	valid_0's binary_logloss: 0.111944	valid_1's auc: 0.835281	valid_1's binary_logloss: 0.140819
[50]	valid_0's auc: 0.903747	valid_0's binary_logloss: 0.111595	valid_1's auc: 0.835359	valid_1's binary_logloss: 0.140811
[51]	valid_0's auc: 0.904427	valid_0's binary_logloss: 0.111354	valid_1's auc: 0.835245	valid_1's binary_logloss: 0.140873
[52]	valid_0's auc: 0.90467	valid_0's binary_logloss: 0.111111	valid_1's auc: 0.835057	valid_1's binary_logloss: 0.140993
[53]	valid_0's auc: 0.904868	valid_0's binary_logloss: 0.110853	valid_1's auc: 0.834751	valid_1's binary_logloss: 0.14108
[54]	valid_0's auc: 0.905166	valid_0's binary_logloss: 0.110627	valid_1's auc: 0.83411	valid_1's binary_logloss: 0.141282
[55]	valid_0's auc: 0.905665	valid_0's binary_logloss: 0.110375	valid_1's auc: 0.833739	valid_1's binary_logloss: 0.141413
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.832891	valid_0's binary_logloss: 0.155302	valid_1's auc: 0.818851	valid_1's binary_logloss: 0.164826
[2]	valid_0's auc: 0.84519	valid_0's binary_logloss: 0.149727	valid_1's auc: 0.827144	valid_1's binary_logloss: 0.159879
[3]	valid_0's auc: 0.848018	valid_0's binary_logloss: 0.145627	valid_1's auc: 0.826851	valid_1's binary_logloss: 0.15631
[4]	valid_0's auc: 0.851096	valid_0's binary_logloss: 0.142423	valid_1's auc: 0.83073	valid_1's binary_logloss: 0.1534
[5]	valid_0's auc: 0.854735	valid_0's binary_logloss: 0.139746	valid_1's auc: 0.832753	valid_1's binary_logloss: 0.151136
[6]	valid_0's auc: 0.856928	valid_0's binary_logloss: 0.137509	valid_1's auc: 0.835605	valid_1's binary_logloss: 0.14924
[7]	valid_0's auc: 0.859448	valid_0's binary_logloss: 0.135575	valid_1's auc: 0.835612	valid_1's binary_logloss: 0.147799
[8]	valid_0's auc: 0.861685	valid_0's binary_logloss: 0.133953	valid_1's auc: 0.834408	valid_1's binary_logloss: 0.146634
[9]	valid_0's auc: 0.863391	valid_0's binary_logloss: 0.132468	valid_1's auc: 0.835623	valid_1's binary_logloss: 0.145549
[10]	valid_0's auc: 0.865858	valid_0's binary_logloss: 0.131185	valid_1's auc: 0.83487	valid_1's binary_logloss: 0.144745
[11]	valid_0's auc: 0.867134	valid_0's binary_logloss: 0.130116	valid_1's auc: 0.834692	valid_1's binary_logloss: 0.14411
[12]	valid_0's auc: 0.868217	valid_0's binary_logloss: 0.129097	valid_1's auc: 0.834746	valid_1's binary_logloss: 0.143527
[13]	valid_0's auc: 0.87073	valid_0's binary_logloss: 0.128129	valid_1's auc: 0.833582	valid_1's binary_logloss: 0.143122
[14]	valid_0's auc: 0.872621	valid_0's binary_logloss: 0.12721	valid_1's auc: 0.833205	valid_1's binary_logloss: 0.142745
[15]	valid_0's auc: 0.874007	valid_0's binary_logloss: 0.126363	valid_1's auc: 0.83246	valid_1's binary_logloss: 0.142489
[16]	valid_0's auc: 0.875141	valid_0's binary_logloss: 0.125606	valid_1's auc: 0.831958	valid_1's binary_logloss: 0.142275
[17]	valid_0's auc: 0.876061	valid_0's binary_logloss: 0.124928	valid_1's auc: 0.831586	valid_1's binary_logloss: 0.142141
[18]	valid_0's auc: 0.876982	valid_0's binary_logloss: 0.124313	valid_1's auc: 0.830954	valid_1's binary_logloss: 0.142066
[19]	valid_0's auc: 0.877885	valid_0's binary_logloss: 0.123709	valid_1's auc: 0.830572	valid_1's binary_logloss: 0.14196
[20]	valid_0's auc: 0.879378	valid_0's binary_logloss: 0.123088	valid_1's auc: 0.830076	valid_1's binary_logloss: 0.14196
[21]	valid_0's auc: 0.880647	valid_0's binary_logloss: 0.122488	valid_1's auc: 0.830109	valid_1's binary_logloss: 0.141858
[22]	valid_0's auc: 0.881614	valid_0's binary_logloss: 0.121973	valid_1's auc: 0.829735	valid_1's binary_logloss: 0.141822
[23]	valid_0's auc: 0.882402	valid_0's binary_logloss: 0.121554	valid_1's auc: 0.829254	valid_1's binary_logloss: 0.141805
[24]	valid_0's auc: 0.883011	valid_0's binary_logloss: 0.121078	valid_1's auc: 0.829054	valid_1's binary_logloss: 0.14178
[25]	valid_0's auc: 0.884627	valid_0's binary_logloss: 0.120587	valid_1's auc: 0.82942	valid_1's binary_logloss: 0.141653
[26]	valid_0's auc: 0.885304	valid_0's binary_logloss: 0.120169	valid_1's auc: 0.828716	valid_1's binary_logloss: 0.141755
[27]	valid_0's auc: 0.88664	valid_0's binary_logloss: 0.119673	valid_1's auc: 0.828869	valid_1's binary_logloss: 0.141682
[28]	valid_0's auc: 0.887143	valid_0's binary_logloss: 0.119308	valid_1's auc: 0.828987	valid_1's binary_logloss: 0.141649
[29]	valid_0's auc: 0.88825	valid_0's binary_logloss: 0.1189	valid_1's auc: 0.829075	valid_1's binary_logloss: 0.141601
[30]	valid_0's auc: 0.889081	valid_0's binary_logloss: 0.118531	valid_1's auc: 0.828871	valid_1's binary_logloss: 0.141605
[31]	valid_0's auc: 0.890195	valid_0's binary_logloss: 0.118117	valid_1's auc: 0.828972	valid_1's binary_logloss: 0.141605
[32]	valid_0's auc: 0.890928	valid_0's binary_logloss: 0.117735	valid_1's auc: 0.827969	valid_1's binary_logloss: 0.141796
[33]	valid_0's auc: 0.891505	valid_0's binary_logloss: 0.117389	valid_1's auc: 0.827611	valid_1's binary_logloss: 0.141916
[34]	valid_0's auc: 0.892223	valid_0's binary_logloss: 0.11707	valid_1's auc: 0.827019	valid_1's binary_logloss: 0.142051
[35]	valid_0's auc: 0.892825	valid_0's binary_logloss: 0.116751	valid_1's auc: 0.826865	valid_1's binary_logloss: 0.142116
[36]	valid_0's auc: 0.893984	valid_0's binary_logloss: 0.116353	valid_1's auc: 0.827203	valid_1's binary_logloss: 0.14207
[37]	valid_0's auc: 0.89456	valid_0's binary_logloss: 0.11603	valid_1's auc: 0.827292	valid_1's binary_logloss: 0.142005
[38]	valid_0's auc: 0.89511	valid_0's binary_logloss: 0.115713	valid_1's auc: 0.827214	valid_1's binary_logloss: 0.14206
[39]	valid_0's auc: 0.895738	valid_0's binary_logloss: 0.115415	valid_1's auc: 0.82695	valid_1's binary_logloss: 0.142162
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.833054	valid_0's binary_logloss: 0.15572	valid_1's auc: 0.817048	valid_1's binary_logloss: 0.165036
[2]	valid_0's auc: 0.841397	valid_0's binary_logloss: 0.149862	valid_1's auc: 0.82157	valid_1's binary_logloss: 0.159575
[3]	valid_0's auc: 0.849058	valid_0's binary_logloss: 0.145662	valid_1's auc: 0.829866	valid_1's binary_logloss: 0.155774
[4]	valid_0's auc: 0.854301	valid_0's binary_logloss: 0.142356	valid_1's auc: 0.832415	valid_1's binary_logloss: 0.152936
[5]	valid_0's auc: 0.858045	valid_0's binary_logloss: 0.139697	valid_1's auc: 0.834554	valid_1's binary_logloss: 0.150635
[6]	valid_0's auc: 0.860767	valid_0's binary_logloss: 0.137458	valid_1's auc: 0.834885	valid_1's binary_logloss: 0.148761
[7]	valid_0's auc: 0.863011	valid_0's binary_logloss: 0.135522	valid_1's auc: 0.835812	valid_1's binary_logloss: 0.147245
[8]	valid_0's auc: 0.864923	valid_0's binary_logloss: 0.133792	valid_1's auc: 0.836656	valid_1's binary_logloss: 0.145923
[9]	valid_0's auc: 0.865706	valid_0's binary_logloss: 0.13236	valid_1's auc: 0.836912	valid_1's binary_logloss: 0.144867
[10]	valid_0's auc: 0.867693	valid_0's binary_logloss: 0.131066	valid_1's auc: 0.837266	valid_1's binary_logloss: 0.143895
[11]	valid_0's auc: 0.868596	valid_0's binary_logloss: 0.129937	valid_1's auc: 0.836466	valid_1's binary_logloss: 0.143255
[12]	valid_0's auc: 0.87012	valid_0's binary_logloss: 0.128904	valid_1's auc: 0.836589	valid_1's binary_logloss: 0.142728
[13]	valid_0's auc: 0.871703	valid_0's binary_logloss: 0.127913	valid_1's auc: 0.836567	valid_1's binary_logloss: 0.142105
[14]	valid_0's auc: 0.873468	valid_0's binary_logloss: 0.126983	valid_1's auc: 0.835538	valid_1's binary_logloss: 0.141771
[15]	valid_0's auc: 0.874839	valid_0's binary_logloss: 0.126147	valid_1's auc: 0.835363	valid_1's binary_logloss: 0.141464
[16]	valid_0's auc: 0.876399	valid_0's binary_logloss: 0.125331	valid_1's auc: 0.83478	valid_1's binary_logloss: 0.141245
[17]	valid_0's auc: 0.877465	valid_0's binary_logloss: 0.124655	valid_1's auc: 0.834621	valid_1's binary_logloss: 0.141028
[18]	valid_0's auc: 0.878935	valid_0's binary_logloss: 0.123944	valid_1's auc: 0.834165	valid_1's binary_logloss: 0.140935
[19]	valid_0's auc: 0.88046	valid_0's binary_logloss: 0.123313	valid_1's auc: 0.834629	valid_1's binary_logloss: 0.140738
[20]	valid_0's auc: 0.881517	valid_0's binary_logloss: 0.12269	valid_1's auc: 0.8347	valid_1's binary_logloss: 0.140611
[21]	valid_0's auc: 0.882464	valid_0's binary_logloss: 0.122095	valid_1's auc: 0.834656	valid_1's binary_logloss: 0.140487
[22]	valid_0's auc: 0.883744	valid_0's binary_logloss: 0.121504	valid_1's auc: 0.834562	valid_1's binary_logloss: 0.140328
[23]	valid_0's auc: 0.885301	valid_0's binary_logloss: 0.12091	valid_1's auc: 0.835278	valid_1's binary_logloss: 0.140199
[24]	valid_0's auc: 0.886266	valid_0's binary_logloss: 0.120437	valid_1's auc: 0.835728	valid_1's binary_logloss: 0.140094
[25]	valid_0's auc: 0.88755	valid_0's binary_logloss: 0.119931	valid_1's auc: 0.836199	valid_1's binary_logloss: 0.140076
[26]	valid_0's auc: 0.888525	valid_0's binary_logloss: 0.119473	valid_1's auc: 0.836708	valid_1's binary_logloss: 0.139945
[27]	valid_0's auc: 0.889589	valid_0's binary_logloss: 0.119012	valid_1's auc: 0.836951	valid_1's binary_logloss: 0.139843
[28]	valid_0's auc: 0.890552	valid_0's binary_logloss: 0.118602	valid_1's auc: 0.836524	valid_1's binary_logloss: 0.139871
[29]	valid_0's auc: 0.891402	valid_0's binary_logloss: 0.118166	valid_1's auc: 0.836264	valid_1's binary_logloss: 0.139884
[30]	valid_0's auc: 0.891982	valid_0's binary_logloss: 0.117805	valid_1's auc: 0.835959	valid_1's binary_logloss: 0.139937
[31]	valid_0's auc: 0.893185	valid_0's binary_logloss: 0.117392	valid_1's auc: 0.836384	valid_1's binary_logloss: 0.13992
[32]	valid_0's auc: 0.894065	valid_0's binary_logloss: 0.117017	valid_1's auc: 0.836341	valid_1's binary_logloss: 0.139888
[33]	valid_0's auc: 0.894791	valid_0's binary_logloss: 0.116671	valid_1's auc: 0.836753	valid_1's binary_logloss: 0.139812
[34]	valid_0's auc: 0.895313	valid_0's binary_logloss: 0.116321	valid_1's auc: 0.836733	valid_1's binary_logloss: 0.139826
[35]	valid_0's auc: 0.895876	valid_0's binary_logloss: 0.116039	valid_1's auc: 0.836245	valid_1's binary_logloss: 0.139883
[36]	valid_0's auc: 0.896909	valid_0's binary_logloss: 0.115684	valid_1's auc: 0.836079	valid_1's binary_logloss: 0.139912
[37]	valid_0's auc: 0.897427	valid_0's binary_logloss: 0.115388	valid_1's auc: 0.835564	valid_1's binary_logloss: 0.140024
[38]	valid_0's auc: 0.898442	valid_0's binary_logloss: 0.115006	valid_1's auc: 0.835612	valid_1's binary_logloss: 0.140075
[39]	valid_0's auc: 0.899304	valid_0's binary_logloss: 0.114592	valid_1's auc: 0.836273	valid_1's binary_logloss: 0.139974
[40]	valid_0's auc: 0.89974	valid_0's binary_logloss: 0.11432	valid_1's auc: 0.836096	valid_1's binary_logloss: 0.140042
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.830643	valid_0's binary_logloss: 0.155759	valid_1's auc: 0.816734	valid_1's binary_logloss: 0.164985
[2]	valid_0's auc: 0.839353	valid_0's binary_logloss: 0.149977	valid_1's auc: 0.822571	valid_1's binary_logloss: 0.159808
[3]	valid_0's auc: 0.847366	valid_0's binary_logloss: 0.145866	valid_1's auc: 0.829312	valid_1's binary_logloss: 0.156171
[4]	valid_0's auc: 0.850911	valid_0's binary_logloss: 0.14247	valid_1's auc: 0.830848	valid_1's binary_logloss: 0.153328
[5]	valid_0's auc: 0.854674	valid_0's binary_logloss: 0.139764	valid_1's auc: 0.833041	valid_1's binary_logloss: 0.151023
[6]	valid_0's auc: 0.856722	valid_0's binary_logloss: 0.1375	valid_1's auc: 0.834264	valid_1's binary_logloss: 0.149166
[7]	valid_0's auc: 0.858253	valid_0's binary_logloss: 0.135713	valid_1's auc: 0.834998	valid_1's binary_logloss: 0.147631
[8]	valid_0's auc: 0.859768	valid_0's binary_logloss: 0.134063	valid_1's auc: 0.835678	valid_1's binary_logloss: 0.146384
[9]	valid_0's auc: 0.86262	valid_0's binary_logloss: 0.132622	valid_1's auc: 0.836272	valid_1's binary_logloss: 0.145313
[10]	valid_0's auc: 0.864631	valid_0's binary_logloss: 0.131324	valid_1's auc: 0.835827	valid_1's binary_logloss: 0.144553
[11]	valid_0's auc: 0.866805	valid_0's binary_logloss: 0.130172	valid_1's auc: 0.835375	valid_1's binary_logloss: 0.143933
[12]	valid_0's auc: 0.868266	valid_0's binary_logloss: 0.129101	valid_1's auc: 0.835951	valid_1's binary_logloss: 0.143342
[13]	valid_0's auc: 0.870762	valid_0's binary_logloss: 0.128144	valid_1's auc: 0.83626	valid_1's binary_logloss: 0.142813
[14]	valid_0's auc: 0.872747	valid_0's binary_logloss: 0.127222	valid_1's auc: 0.835864	valid_1's binary_logloss: 0.142466
[15]	valid_0's auc: 0.874158	valid_0's binary_logloss: 0.126428	valid_1's auc: 0.83548	valid_1's binary_logloss: 0.142108
[16]	valid_0's auc: 0.875931	valid_0's binary_logloss: 0.125651	valid_1's auc: 0.836367	valid_1's binary_logloss: 0.141684
[17]	valid_0's auc: 0.876854	valid_0's binary_logloss: 0.124918	valid_1's auc: 0.835689	valid_1's binary_logloss: 0.141524
[18]	valid_0's auc: 0.878211	valid_0's binary_logloss: 0.124197	valid_1's auc: 0.835893	valid_1's binary_logloss: 0.141285
[19]	valid_0's auc: 0.879125	valid_0's binary_logloss: 0.123553	valid_1's auc: 0.835877	valid_1's binary_logloss: 0.141128
[20]	valid_0's auc: 0.880489	valid_0's binary_logloss: 0.122856	valid_1's auc: 0.835385	valid_1's binary_logloss: 0.141032
[21]	valid_0's auc: 0.881696	valid_0's binary_logloss: 0.122219	valid_1's auc: 0.835822	valid_1's binary_logloss: 0.140843
[22]	valid_0's auc: 0.882257	valid_0's binary_logloss: 0.121726	valid_1's auc: 0.835849	valid_1's binary_logloss: 0.140761
[23]	valid_0's auc: 0.883635	valid_0's binary_logloss: 0.121206	valid_1's auc: 0.836223	valid_1's binary_logloss: 0.140607
[24]	valid_0's auc: 0.884533	valid_0's binary_logloss: 0.120734	valid_1's auc: 0.836473	valid_1's binary_logloss: 0.14049
[25]	valid_0's auc: 0.885234	valid_0's binary_logloss: 0.120268	valid_1's auc: 0.836722	valid_1's binary_logloss: 0.140403
[26]	valid_0's auc: 0.886292	valid_0's binary_logloss: 0.119794	valid_1's auc: 0.836549	valid_1's binary_logloss: 0.140423
[27]	valid_0's auc: 0.887064	valid_0's binary_logloss: 0.119366	valid_1's auc: 0.836155	valid_1's binary_logloss: 0.140447
[28]	valid_0's auc: 0.887621	valid_0's binary_logloss: 0.119008	valid_1's auc: 0.835594	valid_1's binary_logloss: 0.140532
[29]	valid_0's auc: 0.888965	valid_0's binary_logloss: 0.118547	valid_1's auc: 0.835464	valid_1's binary_logloss: 0.140508
[30]	valid_0's auc: 0.889898	valid_0's binary_logloss: 0.118139	valid_1's auc: 0.83577	valid_1's binary_logloss: 0.140461
[31]	valid_0's auc: 0.890896	valid_0's binary_logloss: 0.117734	valid_1's auc: 0.835475	valid_1's binary_logloss: 0.140463
[32]	valid_0's auc: 0.892374	valid_0's binary_logloss: 0.1173	valid_1's auc: 0.835364	valid_1's binary_logloss: 0.140506
[33]	valid_0's auc: 0.893164	valid_0's binary_logloss: 0.116978	valid_1's auc: 0.835865	valid_1's binary_logloss: 0.14041
[34]	valid_0's auc: 0.893848	valid_0's binary_logloss: 0.11662	valid_1's auc: 0.836021	valid_1's binary_logloss: 0.140353
[35]	valid_0's auc: 0.894232	valid_0's binary_logloss: 0.116323	valid_1's auc: 0.8359	valid_1's binary_logloss: 0.140396
[36]	valid_0's auc: 0.895003	valid_0's binary_logloss: 0.115986	valid_1's auc: 0.835855	valid_1's binary_logloss: 0.140416
[37]	valid_0's auc: 0.895898	valid_0's binary_logloss: 0.115609	valid_1's auc: 0.836185	valid_1's binary_logloss: 0.140369
[38]	valid_0's auc: 0.896459	valid_0's binary_logloss: 0.11527	valid_1's auc: 0.835754	valid_1's binary_logloss: 0.140443
[39]	valid_0's auc: 0.897377	valid_0's binary_logloss: 0.114873	valid_1's auc: 0.835638	valid_1's binary_logloss: 0.140474
[40]	valid_0's auc: 0.89776	valid_0's binary_logloss: 0.114588	valid_1's auc: 0.835639	valid_1's binary_logloss: 0.140491
[41]	valid_0's auc: 0.898583	valid_0's binary_logloss: 0.114302	valid_1's auc: 0.835705	valid_1's binary_logloss: 0.140506
[42]	valid_0's auc: 0.899197	valid_0's binary_logloss: 0.113975	valid_1's auc: 0.835052	valid_1's binary_logloss: 0.14064
[43]	valid_0's auc: 0.899803	valid_0's binary_logloss: 0.113654	valid_1's auc: 0.835035	valid_1's binary_logloss: 0.140691
[44]	valid_0's auc: 0.900641	valid_0's binary_logloss: 0.113388	valid_1's auc: 0.835214	valid_1's binary_logloss: 0.140703
[45]	valid_0's auc: 0.900962	valid_0's binary_logloss: 0.113098	valid_1's auc: 0.835276	valid_1's binary_logloss: 0.140695
[46]	valid_0's auc: 0.901584	valid_0's binary_logloss: 0.112771	valid_1's auc: 0.83495	valid_1's binary_logloss: 0.140754
[47]	valid_0's auc: 0.902256	valid_0's binary_logloss: 0.112493	valid_1's auc: 0.835639	valid_1's binary_logloss: 0.14064
[48]	valid_0's auc: 0.902688	valid_0's binary_logloss: 0.112198	valid_1's auc: 0.835495	valid_1's binary_logloss: 0.140691
[49]	valid_0's auc: 0.902922	valid_0's binary_logloss: 0.111944	valid_1's auc: 0.835281	valid_1's binary_logloss: 0.140819
[50]	valid_0's auc: 0.903747	valid_0's binary_logloss: 0.111595	valid_1's auc: 0.835359	valid_1's binary_logloss: 0.140811
[51]	valid_0's auc: 0.904427	valid_0's binary_logloss: 0.111354	valid_1's auc: 0.835245	valid_1's binary_logloss: 0.140873
[52]	valid_0's auc: 0.90467	valid_0's binary_logloss: 0.111111	valid_1's auc: 0.835057	valid_1's binary_logloss: 0.140993
[53]	valid_0's auc: 0.904868	valid_0's binary_logloss: 0.110853	valid_1's auc: 0.834751	valid_1's binary_logloss: 0.14108
[54]	valid_0's auc: 0.905166	valid_0's binary_logloss: 0.110627	valid_1's auc: 0.83411	valid_1's binary_logloss: 0.141282
[55]	valid_0's auc: 0.905665	valid_0's binary_logloss: 0.110375	valid_1's auc: 0.833739	valid_1's binary_logloss: 0.141413
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.824873	valid_0's binary_logloss: 0.156222	valid_1's auc: 0.817791	valid_1's binary_logloss: 0.165072
[2]	valid_0's auc: 0.828725	valid_0's binary_logloss: 0.151244	valid_1's auc: 0.822586	valid_1's binary_logloss: 0.160253
[3]	valid_0's auc: 0.83594	valid_0's binary_logloss: 0.147423	valid_1's auc: 0.828474	valid_1's binary_logloss: 0.156542
[4]	valid_0's auc: 0.839489	valid_0's binary_logloss: 0.144426	valid_1's auc: 0.831396	valid_1's binary_logloss: 0.153706
[5]	valid_0's auc: 0.843358	valid_0's binary_logloss: 0.142067	valid_1's auc: 0.833466	valid_1's binary_logloss: 0.151399
[6]	valid_0's auc: 0.845601	valid_0's binary_logloss: 0.14009	valid_1's auc: 0.833857	valid_1's binary_logloss: 0.149488
[7]	valid_0's auc: 0.846477	valid_0's binary_logloss: 0.138491	valid_1's auc: 0.833143	valid_1's binary_logloss: 0.148023
[8]	valid_0's auc: 0.847725	valid_0's binary_logloss: 0.137129	valid_1's auc: 0.833971	valid_1's binary_logloss: 0.146757
[9]	valid_0's auc: 0.848442	valid_0's binary_logloss: 0.135908	valid_1's auc: 0.835976	valid_1's binary_logloss: 0.145685
[10]	valid_0's auc: 0.849759	valid_0's binary_logloss: 0.134781	valid_1's auc: 0.836214	valid_1's binary_logloss: 0.144769
[11]	valid_0's auc: 0.852238	valid_0's binary_logloss: 0.133835	valid_1's auc: 0.837243	valid_1's binary_logloss: 0.143925
[12]	valid_0's auc: 0.853743	valid_0's binary_logloss: 0.132972	valid_1's auc: 0.836647	valid_1's binary_logloss: 0.143391
[13]	valid_0's auc: 0.854568	valid_0's binary_logloss: 0.132256	valid_1's auc: 0.837182	valid_1's binary_logloss: 0.142849
[14]	valid_0's auc: 0.855928	valid_0's binary_logloss: 0.131554	valid_1's auc: 0.835941	valid_1's binary_logloss: 0.142474
[15]	valid_0's auc: 0.85712	valid_0's binary_logloss: 0.130984	valid_1's auc: 0.834938	valid_1's binary_logloss: 0.142198
[16]	valid_0's auc: 0.858721	valid_0's binary_logloss: 0.130371	valid_1's auc: 0.83561	valid_1's binary_logloss: 0.141802
[17]	valid_0's auc: 0.859281	valid_0's binary_logloss: 0.129877	valid_1's auc: 0.835146	valid_1's binary_logloss: 0.141605
[18]	valid_0's auc: 0.859881	valid_0's binary_logloss: 0.129417	valid_1's auc: 0.835386	valid_1's binary_logloss: 0.14132
[19]	valid_0's auc: 0.861409	valid_0's binary_logloss: 0.128929	valid_1's auc: 0.834974	valid_1's binary_logloss: 0.141151
[20]	valid_0's auc: 0.862574	valid_0's binary_logloss: 0.128458	valid_1's auc: 0.834949	valid_1's binary_logloss: 0.140968
[21]	valid_0's auc: 0.863262	valid_0's binary_logloss: 0.128069	valid_1's auc: 0.834616	valid_1's binary_logloss: 0.14086
[22]	valid_0's auc: 0.864655	valid_0's binary_logloss: 0.127684	valid_1's auc: 0.834363	valid_1's binary_logloss: 0.140766
[23]	valid_0's auc: 0.865247	valid_0's binary_logloss: 0.127349	valid_1's auc: 0.834317	valid_1's binary_logloss: 0.140688
[24]	valid_0's auc: 0.865882	valid_0's binary_logloss: 0.12704	valid_1's auc: 0.833543	valid_1's binary_logloss: 0.14068
[25]	valid_0's auc: 0.867496	valid_0's binary_logloss: 0.126629	valid_1's auc: 0.834195	valid_1's binary_logloss: 0.140539
[26]	valid_0's auc: 0.867923	valid_0's binary_logloss: 0.126353	valid_1's auc: 0.834028	valid_1's binary_logloss: 0.140506
[27]	valid_0's auc: 0.868685	valid_0's binary_logloss: 0.126058	valid_1's auc: 0.834718	valid_1's binary_logloss: 0.140359
[28]	valid_0's auc: 0.869304	valid_0's binary_logloss: 0.125764	valid_1's auc: 0.834935	valid_1's binary_logloss: 0.140287
[29]	valid_0's auc: 0.870037	valid_0's binary_logloss: 0.125514	valid_1's auc: 0.834481	valid_1's binary_logloss: 0.140258
[30]	valid_0's auc: 0.870785	valid_0's binary_logloss: 0.125254	valid_1's auc: 0.834179	valid_1's binary_logloss: 0.140275
[31]	valid_0's auc: 0.871706	valid_0's binary_logloss: 0.124992	valid_1's auc: 0.834475	valid_1's binary_logloss: 0.140205
[32]	valid_0's auc: 0.872582	valid_0's binary_logloss: 0.124728	valid_1's auc: 0.834353	valid_1's binary_logloss: 0.140189
[33]	valid_0's auc: 0.873445	valid_0's binary_logloss: 0.124481	valid_1's auc: 0.834592	valid_1's binary_logloss: 0.140082
[34]	valid_0's auc: 0.874095	valid_0's binary_logloss: 0.12426	valid_1's auc: 0.83436	valid_1's binary_logloss: 0.140101
[35]	valid_0's auc: 0.874869	valid_0's binary_logloss: 0.123982	valid_1's auc: 0.834045	valid_1's binary_logloss: 0.140151
[36]	valid_0's auc: 0.875446	valid_0's binary_logloss: 0.123753	valid_1's auc: 0.834073	valid_1's binary_logloss: 0.140125
[37]	valid_0's auc: 0.875763	valid_0's binary_logloss: 0.123587	valid_1's auc: 0.833611	valid_1's binary_logloss: 0.140201
[38]	valid_0's auc: 0.876603	valid_0's binary_logloss: 0.123335	valid_1's auc: 0.833805	valid_1's binary_logloss: 0.140159
[39]	valid_0's auc: 0.877126	valid_0's binary_logloss: 0.123134	valid_1's auc: 0.834422	valid_1's binary_logloss: 0.140048
[40]	valid_0's auc: 0.877575	valid_0's binary_logloss: 0.123013	valid_1's auc: 0.834343	valid_1's binary_logloss: 0.140069
[41]	valid_0's auc: 0.87809	valid_0's binary_logloss: 0.122813	valid_1's auc: 0.834199	valid_1's binary_logloss: 0.140085
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.821831	valid_0's binary_logloss: 0.156466	valid_1's auc: 0.817525	valid_1's binary_logloss: 0.165186
[2]	valid_0's auc: 0.831974	valid_0's binary_logloss: 0.151137	valid_1's auc: 0.82532	valid_1's binary_logloss: 0.159691
[3]	valid_0's auc: 0.839496	valid_0's binary_logloss: 0.14733	valid_1's auc: 0.831946	valid_1's binary_logloss: 0.156
[4]	valid_0's auc: 0.843984	valid_0's binary_logloss: 0.144371	valid_1's auc: 0.834064	valid_1's binary_logloss: 0.153082
[5]	valid_0's auc: 0.845854	valid_0's binary_logloss: 0.142024	valid_1's auc: 0.836918	valid_1's binary_logloss: 0.150735
[6]	valid_0's auc: 0.848041	valid_0's binary_logloss: 0.140009	valid_1's auc: 0.838831	valid_1's binary_logloss: 0.148771
[7]	valid_0's auc: 0.849655	valid_0's binary_logloss: 0.138307	valid_1's auc: 0.839111	valid_1's binary_logloss: 0.147373
[8]	valid_0's auc: 0.85185	valid_0's binary_logloss: 0.136891	valid_1's auc: 0.838955	valid_1's binary_logloss: 0.146094
[9]	valid_0's auc: 0.853067	valid_0's binary_logloss: 0.135655	valid_1's auc: 0.838081	valid_1's binary_logloss: 0.14516
[10]	valid_0's auc: 0.853922	valid_0's binary_logloss: 0.134622	valid_1's auc: 0.837333	valid_1's binary_logloss: 0.144318
[11]	valid_0's auc: 0.854729	valid_0's binary_logloss: 0.133702	valid_1's auc: 0.83725	valid_1's binary_logloss: 0.143512
[12]	valid_0's auc: 0.856303	valid_0's binary_logloss: 0.132789	valid_1's auc: 0.837602	valid_1's binary_logloss: 0.142833
[13]	valid_0's auc: 0.857206	valid_0's binary_logloss: 0.132038	valid_1's auc: 0.837364	valid_1's binary_logloss: 0.142245
[14]	valid_0's auc: 0.858161	valid_0's binary_logloss: 0.131391	valid_1's auc: 0.83777	valid_1's binary_logloss: 0.141759
[15]	valid_0's auc: 0.858975	valid_0's binary_logloss: 0.130772	valid_1's auc: 0.837831	valid_1's binary_logloss: 0.14139
[16]	valid_0's auc: 0.859623	valid_0's binary_logloss: 0.130219	valid_1's auc: 0.837953	valid_1's binary_logloss: 0.141016
[17]	valid_0's auc: 0.860576	valid_0's binary_logloss: 0.129684	valid_1's auc: 0.837985	valid_1's binary_logloss: 0.140713
[18]	valid_0's auc: 0.861311	valid_0's binary_logloss: 0.129202	valid_1's auc: 0.83796	valid_1's binary_logloss: 0.140452
[19]	valid_0's auc: 0.862347	valid_0's binary_logloss: 0.128715	valid_1's auc: 0.838506	valid_1's binary_logloss: 0.140189
[20]	valid_0's auc: 0.86305	valid_0's binary_logloss: 0.128312	valid_1's auc: 0.837702	valid_1's binary_logloss: 0.140094
[21]	valid_0's auc: 0.863758	valid_0's binary_logloss: 0.127907	valid_1's auc: 0.838127	valid_1's binary_logloss: 0.139858
[22]	valid_0's auc: 0.864635	valid_0's binary_logloss: 0.127525	valid_1's auc: 0.838331	valid_1's binary_logloss: 0.139696
[23]	valid_0's auc: 0.865866	valid_0's binary_logloss: 0.127143	valid_1's auc: 0.837841	valid_1's binary_logloss: 0.139625
[24]	valid_0's auc: 0.867054	valid_0's binary_logloss: 0.126749	valid_1's auc: 0.838187	valid_1's binary_logloss: 0.139526
[25]	valid_0's auc: 0.867553	valid_0's binary_logloss: 0.126476	valid_1's auc: 0.838308	valid_1's binary_logloss: 0.13949
[26]	valid_0's auc: 0.868108	valid_0's binary_logloss: 0.126164	valid_1's auc: 0.838035	valid_1's binary_logloss: 0.139426
[27]	valid_0's auc: 0.869014	valid_0's binary_logloss: 0.125868	valid_1's auc: 0.837545	valid_1's binary_logloss: 0.139445
[28]	valid_0's auc: 0.869797	valid_0's binary_logloss: 0.12559	valid_1's auc: 0.837894	valid_1's binary_logloss: 0.139419
[29]	valid_0's auc: 0.870435	valid_0's binary_logloss: 0.1253	valid_1's auc: 0.838103	valid_1's binary_logloss: 0.139321
[30]	valid_0's auc: 0.87141	valid_0's binary_logloss: 0.125025	valid_1's auc: 0.838164	valid_1's binary_logloss: 0.139275
[31]	valid_0's auc: 0.872143	valid_0's binary_logloss: 0.124769	valid_1's auc: 0.837843	valid_1's binary_logloss: 0.139285
[32]	valid_0's auc: 0.872606	valid_0's binary_logloss: 0.124561	valid_1's auc: 0.837662	valid_1's binary_logloss: 0.139274
[33]	valid_0's auc: 0.873337	valid_0's binary_logloss: 0.124346	valid_1's auc: 0.837661	valid_1's binary_logloss: 0.139284
[34]	valid_0's auc: 0.873965	valid_0's binary_logloss: 0.124108	valid_1's auc: 0.837639	valid_1's binary_logloss: 0.139263
[35]	valid_0's auc: 0.87457	valid_0's binary_logloss: 0.123857	valid_1's auc: 0.838159	valid_1's binary_logloss: 0.139137
[36]	valid_0's auc: 0.874973	valid_0's binary_logloss: 0.123651	valid_1's auc: 0.838114	valid_1's binary_logloss: 0.139148
[37]	valid_0's auc: 0.875657	valid_0's binary_logloss: 0.123447	valid_1's auc: 0.838519	valid_1's binary_logloss: 0.139109
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.821427	valid_0's binary_logloss: 0.156592	valid_1's auc: 0.81711	valid_1's binary_logloss: 0.165273
[2]	valid_0's auc: 0.827893	valid_0's binary_logloss: 0.151336	valid_1's auc: 0.820533	valid_1's binary_logloss: 0.160243
[3]	valid_0's auc: 0.83753	valid_0's binary_logloss: 0.147487	valid_1's auc: 0.82841	valid_1's binary_logloss: 0.156547
[4]	valid_0's auc: 0.84038	valid_0's binary_logloss: 0.144428	valid_1's auc: 0.8313	valid_1's binary_logloss: 0.153575
[5]	valid_0's auc: 0.842945	valid_0's binary_logloss: 0.142089	valid_1's auc: 0.833579	valid_1's binary_logloss: 0.151354
[6]	valid_0's auc: 0.843246	valid_0's binary_logloss: 0.140186	valid_1's auc: 0.833781	valid_1's binary_logloss: 0.14953
[7]	valid_0's auc: 0.844301	valid_0's binary_logloss: 0.138471	valid_1's auc: 0.834317	valid_1's binary_logloss: 0.147954
[8]	valid_0's auc: 0.846945	valid_0's binary_logloss: 0.137078	valid_1's auc: 0.834895	valid_1's binary_logloss: 0.146786
[9]	valid_0's auc: 0.849381	valid_0's binary_logloss: 0.135906	valid_1's auc: 0.834922	valid_1's binary_logloss: 0.145762
[10]	valid_0's auc: 0.850944	valid_0's binary_logloss: 0.134855	valid_1's auc: 0.835441	valid_1's binary_logloss: 0.144958
[11]	valid_0's auc: 0.852557	valid_0's binary_logloss: 0.133895	valid_1's auc: 0.835103	valid_1's binary_logloss: 0.144293
[12]	valid_0's auc: 0.854609	valid_0's binary_logloss: 0.133013	valid_1's auc: 0.835686	valid_1's binary_logloss: 0.143793
[13]	valid_0's auc: 0.855817	valid_0's binary_logloss: 0.132247	valid_1's auc: 0.835296	valid_1's binary_logloss: 0.143302
[14]	valid_0's auc: 0.857501	valid_0's binary_logloss: 0.131545	valid_1's auc: 0.836432	valid_1's binary_logloss: 0.142761
[15]	valid_0's auc: 0.858907	valid_0's binary_logloss: 0.130878	valid_1's auc: 0.836329	valid_1's binary_logloss: 0.142383
[16]	valid_0's auc: 0.859887	valid_0's binary_logloss: 0.130287	valid_1's auc: 0.836611	valid_1's binary_logloss: 0.141883
[17]	valid_0's auc: 0.860889	valid_0's binary_logloss: 0.129757	valid_1's auc: 0.836848	valid_1's binary_logloss: 0.141535
[18]	valid_0's auc: 0.861827	valid_0's binary_logloss: 0.129301	valid_1's auc: 0.837106	valid_1's binary_logloss: 0.141257
[19]	valid_0's auc: 0.862972	valid_0's binary_logloss: 0.128826	valid_1's auc: 0.837185	valid_1's binary_logloss: 0.141043
[20]	valid_0's auc: 0.864083	valid_0's binary_logloss: 0.128369	valid_1's auc: 0.837509	valid_1's binary_logloss: 0.140794
[21]	valid_0's auc: 0.864747	valid_0's binary_logloss: 0.127959	valid_1's auc: 0.837888	valid_1's binary_logloss: 0.140626
[22]	valid_0's auc: 0.865769	valid_0's binary_logloss: 0.127562	valid_1's auc: 0.837811	valid_1's binary_logloss: 0.140487
[23]	valid_0's auc: 0.866657	valid_0's binary_logloss: 0.127217	valid_1's auc: 0.837884	valid_1's binary_logloss: 0.140328
[24]	valid_0's auc: 0.867293	valid_0's binary_logloss: 0.126875	valid_1's auc: 0.838481	valid_1's binary_logloss: 0.140215
[25]	valid_0's auc: 0.867983	valid_0's binary_logloss: 0.126562	valid_1's auc: 0.838239	valid_1's binary_logloss: 0.140124
[26]	valid_0's auc: 0.868559	valid_0's binary_logloss: 0.126248	valid_1's auc: 0.837903	valid_1's binary_logloss: 0.140092
[27]	valid_0's auc: 0.869394	valid_0's binary_logloss: 0.125936	valid_1's auc: 0.837493	valid_1's binary_logloss: 0.14006
[28]	valid_0's auc: 0.87048	valid_0's binary_logloss: 0.125677	valid_1's auc: 0.837623	valid_1's binary_logloss: 0.140007
[29]	valid_0's auc: 0.87105	valid_0's binary_logloss: 0.125405	valid_1's auc: 0.838216	valid_1's binary_logloss: 0.13986
[30]	valid_0's auc: 0.871749	valid_0's binary_logloss: 0.125147	valid_1's auc: 0.838898	valid_1's binary_logloss: 0.139742
[31]	valid_0's auc: 0.87247	valid_0's binary_logloss: 0.124907	valid_1's auc: 0.838959	valid_1's binary_logloss: 0.139727
[32]	valid_0's auc: 0.87282	valid_0's binary_logloss: 0.124724	valid_1's auc: 0.838675	valid_1's binary_logloss: 0.139761
[33]	valid_0's auc: 0.874106	valid_0's binary_logloss: 0.124412	valid_1's auc: 0.838893	valid_1's binary_logloss: 0.139687
[34]	valid_0's auc: 0.874887	valid_0's binary_logloss: 0.124169	valid_1's auc: 0.838801	valid_1's binary_logloss: 0.139672
[35]	valid_0's auc: 0.875447	valid_0's binary_logloss: 0.123934	valid_1's auc: 0.838835	valid_1's binary_logloss: 0.139667
[36]	valid_0's auc: 0.87617	valid_0's binary_logloss: 0.123693	valid_1's auc: 0.838505	valid_1's binary_logloss: 0.139699
[37]	valid_0's auc: 0.876793	valid_0's binary_logloss: 0.12346	valid_1's auc: 0.838104	valid_1's binary_logloss: 0.139783
[38]	valid_0's auc: 0.877265	valid_0's binary_logloss: 0.123251	valid_1's auc: 0.838267	valid_1's binary_logloss: 0.139787
[39]	valid_0's auc: 0.877869	valid_0's binary_logloss: 0.123018	valid_1's auc: 0.838004	valid_1's binary_logloss: 0.139806
[40]	valid_0's auc: 0.878509	valid_0's binary_logloss: 0.122803	valid_1's auc: 0.838086	valid_1's binary_logloss: 0.139745
[41]	valid_0's auc: 0.879077	valid_0's binary_logloss: 0.122585	valid_1's auc: 0.838538	valid_1's binary_logloss: 0.139694
[42]	valid_0's auc: 0.879515	valid_0's binary_logloss: 0.122368	valid_1's auc: 0.838647	valid_1's binary_logloss: 0.139655
[43]	valid_0's auc: 0.879985	valid_0's binary_logloss: 0.122166	valid_1's auc: 0.838495	valid_1's binary_logloss: 0.139653
[44]	valid_0's auc: 0.88041	valid_0's binary_logloss: 0.121985	valid_1's auc: 0.838221	valid_1's binary_logloss: 0.139755
[45]	valid_0's auc: 0.880907	valid_0's binary_logloss: 0.121777	valid_1's auc: 0.837981	valid_1's binary_logloss: 0.139769
[46]	valid_0's auc: 0.881216	valid_0's binary_logloss: 0.121594	valid_1's auc: 0.838471	valid_1's binary_logloss: 0.139693
[47]	valid_0's auc: 0.881591	valid_0's binary_logloss: 0.121422	valid_1's auc: 0.83861	valid_1's binary_logloss: 0.139687
[48]	valid_0's auc: 0.881867	valid_0's binary_logloss: 0.121266	valid_1's auc: 0.838593	valid_1's binary_logloss: 0.139682
[49]	valid_0's auc: 0.882285	valid_0's binary_logloss: 0.121041	valid_1's auc: 0.838317	valid_1's binary_logloss: 0.139741
[50]	valid_0's auc: 0.882828	valid_0's binary_logloss: 0.120853	valid_1's auc: 0.838244	valid_1's binary_logloss: 0.139759
[51]	valid_0's auc: 0.883154	valid_0's binary_logloss: 0.120688	valid_1's auc: 0.838222	valid_1's binary_logloss: 0.139803
[52]	valid_0's auc: 0.883348	valid_0's binary_logloss: 0.120567	valid_1's auc: 0.838064	valid_1's binary_logloss: 0.139824
[53]	valid_0's auc: 0.883583	valid_0's binary_logloss: 0.120424	valid_1's auc: 0.83788	valid_1's binary_logloss: 0.139844
[54]	valid_0's auc: 0.884106	valid_0's binary_logloss: 0.120208	valid_1's auc: 0.837625	valid_1's binary_logloss: 0.139886
[55]	valid_0's auc: 0.884777	valid_0's binary_logloss: 0.120039	valid_1's auc: 0.837585	valid_1's binary_logloss: 0.139902
[56]	valid_0's auc: 0.88511	valid_0's binary_logloss: 0.11989	valid_1's auc: 0.837646	valid_1's binary_logloss: 0.139926
[57]	valid_0's auc: 0.885365	valid_0's binary_logloss: 0.11975	valid_1's auc: 0.837639	valid_1's binary_logloss: 0.139934
[58]	valid_0's auc: 0.885606	valid_0's binary_logloss: 0.119595	valid_1's auc: 0.837726	valid_1's binary_logloss: 0.139938
[59]	valid_0's auc: 0.885965	valid_0's binary_logloss: 0.119403	valid_1's auc: 0.837558	valid_1's binary_logloss: 0.140007
[60]	valid_0's auc: 0.886208	valid_0's binary_logloss: 0.119263	valid_1's auc: 0.83744	valid_1's binary_logloss: 0.140079
[61]	valid_0's auc: 0.886458	valid_0's binary_logloss: 0.119118	valid_1's auc: 0.837349	valid_1's binary_logloss: 0.140059
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.824873	valid_0's binary_logloss: 0.156222	valid_1's auc: 0.817791	valid_1's binary_logloss: 0.165072
[2]	valid_0's auc: 0.828725	valid_0's binary_logloss: 0.151244	valid_1's auc: 0.822586	valid_1's binary_logloss: 0.160253
[3]	valid_0's auc: 0.83594	valid_0's binary_logloss: 0.147423	valid_1's auc: 0.828474	valid_1's binary_logloss: 0.156542
[4]	valid_0's auc: 0.839489	valid_0's binary_logloss: 0.144426	valid_1's auc: 0.831396	valid_1's binary_logloss: 0.153706
[5]	valid_0's auc: 0.843358	valid_0's binary_logloss: 0.142067	valid_1's auc: 0.833466	valid_1's binary_logloss: 0.151399
[6]	valid_0's auc: 0.845601	valid_0's binary_logloss: 0.14009	valid_1's auc: 0.833857	valid_1's binary_logloss: 0.149488
[7]	valid_0's auc: 0.846477	valid_0's binary_logloss: 0.138491	valid_1's auc: 0.833143	valid_1's binary_logloss: 0.148023
[8]	valid_0's auc: 0.847725	valid_0's binary_logloss: 0.137129	valid_1's auc: 0.833971	valid_1's binary_logloss: 0.146757
[9]	valid_0's auc: 0.848442	valid_0's binary_logloss: 0.135908	valid_1's auc: 0.835976	valid_1's binary_logloss: 0.145685
[10]	valid_0's auc: 0.849759	valid_0's binary_logloss: 0.134781	valid_1's auc: 0.836214	valid_1's binary_logloss: 0.144769
[11]	valid_0's auc: 0.852238	valid_0's binary_logloss: 0.133835	valid_1's auc: 0.837243	valid_1's binary_logloss: 0.143925
[12]	valid_0's auc: 0.853743	valid_0's binary_logloss: 0.132972	valid_1's auc: 0.836647	valid_1's binary_logloss: 0.143391
[13]	valid_0's auc: 0.854568	valid_0's binary_logloss: 0.132256	valid_1's auc: 0.837182	valid_1's binary_logloss: 0.142849
[14]	valid_0's auc: 0.855928	valid_0's binary_logloss: 0.131554	valid_1's auc: 0.835941	valid_1's binary_logloss: 0.142474
[15]	valid_0's auc: 0.85712	valid_0's binary_logloss: 0.130984	valid_1's auc: 0.834938	valid_1's binary_logloss: 0.142198
[16]	valid_0's auc: 0.858721	valid_0's binary_logloss: 0.130371	valid_1's auc: 0.83561	valid_1's binary_logloss: 0.141802
[17]	valid_0's auc: 0.859281	valid_0's binary_logloss: 0.129877	valid_1's auc: 0.835146	valid_1's binary_logloss: 0.141605
[18]	valid_0's auc: 0.859881	valid_0's binary_logloss: 0.129417	valid_1's auc: 0.835386	valid_1's binary_logloss: 0.14132
[19]	valid_0's auc: 0.861409	valid_0's binary_logloss: 0.128929	valid_1's auc: 0.834974	valid_1's binary_logloss: 0.141151
[20]	valid_0's auc: 0.862574	valid_0's binary_logloss: 0.128458	valid_1's auc: 0.834949	valid_1's binary_logloss: 0.140968
[21]	valid_0's auc: 0.863262	valid_0's binary_logloss: 0.128069	valid_1's auc: 0.834616	valid_1's binary_logloss: 0.14086
[22]	valid_0's auc: 0.864655	valid_0's binary_logloss: 0.127684	valid_1's auc: 0.834363	valid_1's binary_logloss: 0.140766
[23]	valid_0's auc: 0.865247	valid_0's binary_logloss: 0.127349	valid_1's auc: 0.834317	valid_1's binary_logloss: 0.140688
[24]	valid_0's auc: 0.865882	valid_0's binary_logloss: 0.12704	valid_1's auc: 0.833543	valid_1's binary_logloss: 0.14068
[25]	valid_0's auc: 0.867496	valid_0's binary_logloss: 0.126629	valid_1's auc: 0.834195	valid_1's binary_logloss: 0.140539
[26]	valid_0's auc: 0.867923	valid_0's binary_logloss: 0.126353	valid_1's auc: 0.834028	valid_1's binary_logloss: 0.140506
[27]	valid_0's auc: 0.868685	valid_0's binary_logloss: 0.126058	valid_1's auc: 0.834718	valid_1's binary_logloss: 0.140359
[28]	valid_0's auc: 0.869304	valid_0's binary_logloss: 0.125764	valid_1's auc: 0.834935	valid_1's binary_logloss: 0.140287
[29]	valid_0's auc: 0.870037	valid_0's binary_logloss: 0.125514	valid_1's auc: 0.834481	valid_1's binary_logloss: 0.140258
[30]	valid_0's auc: 0.870785	valid_0's binary_logloss: 0.125254	valid_1's auc: 0.834179	valid_1's binary_logloss: 0.140275
[31]	valid_0's auc: 0.871706	valid_0's binary_logloss: 0.124992	valid_1's auc: 0.834475	valid_1's binary_logloss: 0.140205
[32]	valid_0's auc: 0.872582	valid_0's binary_logloss: 0.124728	valid_1's auc: 0.834353	valid_1's binary_logloss: 0.140189
[33]	valid_0's auc: 0.873445	valid_0's binary_logloss: 0.124481	valid_1's auc: 0.834592	valid_1's binary_logloss: 0.140082
[34]	valid_0's auc: 0.874095	valid_0's binary_logloss: 0.12426	valid_1's auc: 0.83436	valid_1's binary_logloss: 0.140101
[35]	valid_0's auc: 0.874869	valid_0's binary_logloss: 0.123982	valid_1's auc: 0.834045	valid_1's binary_logloss: 0.140151
[36]	valid_0's auc: 0.875446	valid_0's binary_logloss: 0.123753	valid_1's auc: 0.834073	valid_1's binary_logloss: 0.140125
[37]	valid_0's auc: 0.875763	valid_0's binary_logloss: 0.123587	valid_1's auc: 0.833611	valid_1's binary_logloss: 0.140201
[38]	valid_0's auc: 0.876603	valid_0's binary_logloss: 0.123335	valid_1's auc: 0.833805	valid_1's binary_logloss: 0.140159
[39]	valid_0's auc: 0.877126	valid_0's binary_logloss: 0.123134	valid_1's auc: 0.834422	valid_1's binary_logloss: 0.140048
[40]	valid_0's auc: 0.877575	valid_0's binary_logloss: 0.123013	valid_1's auc: 0.834343	valid_1's binary_logloss: 0.140069
[41]	valid_0's auc: 0.87809	valid_0's binary_logloss: 0.122813	valid_1's auc: 0.834199	valid_1's binary_logloss: 0.140085
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.821831	valid_0's binary_logloss: 0.156466	valid_1's auc: 0.817525	valid_1's binary_logloss: 0.165186
[2]	valid_0's auc: 0.831974	valid_0's binary_logloss: 0.151137	valid_1's auc: 0.82532	valid_1's binary_logloss: 0.159691
[3]	valid_0's auc: 0.839496	valid_0's binary_logloss: 0.14733	valid_1's auc: 0.831946	valid_1's binary_logloss: 0.156
[4]	valid_0's auc: 0.843984	valid_0's binary_logloss: 0.144371	valid_1's auc: 0.834064	valid_1's binary_logloss: 0.153082
[5]	valid_0's auc: 0.845854	valid_0's binary_logloss: 0.142024	valid_1's auc: 0.836918	valid_1's binary_logloss: 0.150735
[6]	valid_0's auc: 0.848041	valid_0's binary_logloss: 0.140009	valid_1's auc: 0.838831	valid_1's binary_logloss: 0.148771
[7]	valid_0's auc: 0.849655	valid_0's binary_logloss: 0.138307	valid_1's auc: 0.839111	valid_1's binary_logloss: 0.147373
[8]	valid_0's auc: 0.85185	valid_0's binary_logloss: 0.136891	valid_1's auc: 0.838955	valid_1's binary_logloss: 0.146094
[9]	valid_0's auc: 0.853067	valid_0's binary_logloss: 0.135655	valid_1's auc: 0.838081	valid_1's binary_logloss: 0.14516
[10]	valid_0's auc: 0.853922	valid_0's binary_logloss: 0.134622	valid_1's auc: 0.837333	valid_1's binary_logloss: 0.144318
[11]	valid_0's auc: 0.854729	valid_0's binary_logloss: 0.133702	valid_1's auc: 0.83725	valid_1's binary_logloss: 0.143512
[12]	valid_0's auc: 0.856303	valid_0's binary_logloss: 0.132789	valid_1's auc: 0.837602	valid_1's binary_logloss: 0.142833
[13]	valid_0's auc: 0.857206	valid_0's binary_logloss: 0.132038	valid_1's auc: 0.837364	valid_1's binary_logloss: 0.142245
[14]	valid_0's auc: 0.858161	valid_0's binary_logloss: 0.131391	valid_1's auc: 0.83777	valid_1's binary_logloss: 0.141759
[15]	valid_0's auc: 0.858975	valid_0's binary_logloss: 0.130772	valid_1's auc: 0.837831	valid_1's binary_logloss: 0.14139
[16]	valid_0's auc: 0.859623	valid_0's binary_logloss: 0.130219	valid_1's auc: 0.837953	valid_1's binary_logloss: 0.141016
[17]	valid_0's auc: 0.860576	valid_0's binary_logloss: 0.129684	valid_1's auc: 0.837985	valid_1's binary_logloss: 0.140713
[18]	valid_0's auc: 0.861311	valid_0's binary_logloss: 0.129202	valid_1's auc: 0.83796	valid_1's binary_logloss: 0.140452
[19]	valid_0's auc: 0.862347	valid_0's binary_logloss: 0.128715	valid_1's auc: 0.838506	valid_1's binary_logloss: 0.140189
[20]	valid_0's auc: 0.86305	valid_0's binary_logloss: 0.128312	valid_1's auc: 0.837702	valid_1's binary_logloss: 0.140094
[21]	valid_0's auc: 0.863758	valid_0's binary_logloss: 0.127907	valid_1's auc: 0.838127	valid_1's binary_logloss: 0.139858
[22]	valid_0's auc: 0.864635	valid_0's binary_logloss: 0.127525	valid_1's auc: 0.838331	valid_1's binary_logloss: 0.139696
[23]	valid_0's auc: 0.865866	valid_0's binary_logloss: 0.127143	valid_1's auc: 0.837841	valid_1's binary_logloss: 0.139625
[24]	valid_0's auc: 0.867054	valid_0's binary_logloss: 0.126749	valid_1's auc: 0.838187	valid_1's binary_logloss: 0.139526
[25]	valid_0's auc: 0.867553	valid_0's binary_logloss: 0.126476	valid_1's auc: 0.838308	valid_1's binary_logloss: 0.13949
[26]	valid_0's auc: 0.868108	valid_0's binary_logloss: 0.126164	valid_1's auc: 0.838035	valid_1's binary_logloss: 0.139426
[27]	valid_0's auc: 0.869014	valid_0's binary_logloss: 0.125868	valid_1's auc: 0.837545	valid_1's binary_logloss: 0.139445
[28]	valid_0's auc: 0.869797	valid_0's binary_logloss: 0.12559	valid_1's auc: 0.837894	valid_1's binary_logloss: 0.139419
[29]	valid_0's auc: 0.870435	valid_0's binary_logloss: 0.1253	valid_1's auc: 0.838103	valid_1's binary_logloss: 0.139321
[30]	valid_0's auc: 0.87141	valid_0's binary_logloss: 0.125025	valid_1's auc: 0.838164	valid_1's binary_logloss: 0.139275
[31]	valid_0's auc: 0.872143	valid_0's binary_logloss: 0.124769	valid_1's auc: 0.837843	valid_1's binary_logloss: 0.139285
[32]	valid_0's auc: 0.872606	valid_0's binary_logloss: 0.124561	valid_1's auc: 0.837662	valid_1's binary_logloss: 0.139274
[33]	valid_0's auc: 0.873337	valid_0's binary_logloss: 0.124346	valid_1's auc: 0.837661	valid_1's binary_logloss: 0.139284
[34]	valid_0's auc: 0.873965	valid_0's binary_logloss: 0.124108	valid_1's auc: 0.837639	valid_1's binary_logloss: 0.139263
[35]	valid_0's auc: 0.87457	valid_0's binary_logloss: 0.123857	valid_1's auc: 0.838159	valid_1's binary_logloss: 0.139137
[36]	valid_0's auc: 0.874973	valid_0's binary_logloss: 0.123651	valid_1's auc: 0.838114	valid_1's binary_logloss: 0.139148
[37]	valid_0's auc: 0.875657	valid_0's binary_logloss: 0.123447	valid_1's auc: 0.838519	valid_1's binary_logloss: 0.139109
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.821427	valid_0's binary_logloss: 0.156592	valid_1's auc: 0.81711	valid_1's binary_logloss: 0.165273
[2]	valid_0's auc: 0.827893	valid_0's binary_logloss: 0.151336	valid_1's auc: 0.820533	valid_1's binary_logloss: 0.160243
[3]	valid_0's auc: 0.83753	valid_0's binary_logloss: 0.147487	valid_1's auc: 0.82841	valid_1's binary_logloss: 0.156547
[4]	valid_0's auc: 0.84038	valid_0's binary_logloss: 0.144428	valid_1's auc: 0.8313	valid_1's binary_logloss: 0.153575
[5]	valid_0's auc: 0.842945	valid_0's binary_logloss: 0.142089	valid_1's auc: 0.833579	valid_1's binary_logloss: 0.151354
[6]	valid_0's auc: 0.843246	valid_0's binary_logloss: 0.140186	valid_1's auc: 0.833781	valid_1's binary_logloss: 0.14953
[7]	valid_0's auc: 0.844301	valid_0's binary_logloss: 0.138471	valid_1's auc: 0.834317	valid_1's binary_logloss: 0.147954
[8]	valid_0's auc: 0.846945	valid_0's binary_logloss: 0.137078	valid_1's auc: 0.834895	valid_1's binary_logloss: 0.146786
[9]	valid_0's auc: 0.849381	valid_0's binary_logloss: 0.135906	valid_1's auc: 0.834922	valid_1's binary_logloss: 0.145762
[10]	valid_0's auc: 0.850944	valid_0's binary_logloss: 0.134855	valid_1's auc: 0.835441	valid_1's binary_logloss: 0.144958
[11]	valid_0's auc: 0.852557	valid_0's binary_logloss: 0.133895	valid_1's auc: 0.835103	valid_1's binary_logloss: 0.144293
[12]	valid_0's auc: 0.854609	valid_0's binary_logloss: 0.133013	valid_1's auc: 0.835686	valid_1's binary_logloss: 0.143793
[13]	valid_0's auc: 0.855817	valid_0's binary_logloss: 0.132247	valid_1's auc: 0.835296	valid_1's binary_logloss: 0.143302
[14]	valid_0's auc: 0.857501	valid_0's binary_logloss: 0.131545	valid_1's auc: 0.836432	valid_1's binary_logloss: 0.142761
[15]	valid_0's auc: 0.858907	valid_0's binary_logloss: 0.130878	valid_1's auc: 0.836329	valid_1's binary_logloss: 0.142383
[16]	valid_0's auc: 0.859887	valid_0's binary_logloss: 0.130287	valid_1's auc: 0.836611	valid_1's binary_logloss: 0.141883
[17]	valid_0's auc: 0.860889	valid_0's binary_logloss: 0.129757	valid_1's auc: 0.836848	valid_1's binary_logloss: 0.141535
[18]	valid_0's auc: 0.861827	valid_0's binary_logloss: 0.129301	valid_1's auc: 0.837106	valid_1's binary_logloss: 0.141257
[19]	valid_0's auc: 0.862972	valid_0's binary_logloss: 0.128826	valid_1's auc: 0.837185	valid_1's binary_logloss: 0.141043
[20]	valid_0's auc: 0.864083	valid_0's binary_logloss: 0.128369	valid_1's auc: 0.837509	valid_1's binary_logloss: 0.140794
[21]	valid_0's auc: 0.864747	valid_0's binary_logloss: 0.127959	valid_1's auc: 0.837888	valid_1's binary_logloss: 0.140626
[22]	valid_0's auc: 0.865769	valid_0's binary_logloss: 0.127562	valid_1's auc: 0.837811	valid_1's binary_logloss: 0.140487
[23]	valid_0's auc: 0.866657	valid_0's binary_logloss: 0.127217	valid_1's auc: 0.837884	valid_1's binary_logloss: 0.140328
[24]	valid_0's auc: 0.867293	valid_0's binary_logloss: 0.126875	valid_1's auc: 0.838481	valid_1's binary_logloss: 0.140215
[25]	valid_0's auc: 0.867983	valid_0's binary_logloss: 0.126562	valid_1's auc: 0.838239	valid_1's binary_logloss: 0.140124
[26]	valid_0's auc: 0.868559	valid_0's binary_logloss: 0.126248	valid_1's auc: 0.837903	valid_1's binary_logloss: 0.140092
[27]	valid_0's auc: 0.869394	valid_0's binary_logloss: 0.125936	valid_1's auc: 0.837493	valid_1's binary_logloss: 0.14006
[28]	valid_0's auc: 0.87048	valid_0's binary_logloss: 0.125677	valid_1's auc: 0.837623	valid_1's binary_logloss: 0.140007
[29]	valid_0's auc: 0.87105	valid_0's binary_logloss: 0.125405	valid_1's auc: 0.838216	valid_1's binary_logloss: 0.13986
[30]	valid_0's auc: 0.871749	valid_0's binary_logloss: 0.125147	valid_1's auc: 0.838898	valid_1's binary_logloss: 0.139742
[31]	valid_0's auc: 0.87247	valid_0's binary_logloss: 0.124907	valid_1's auc: 0.838959	valid_1's binary_logloss: 0.139727
[32]	valid_0's auc: 0.87282	valid_0's binary_logloss: 0.124724	valid_1's auc: 0.838675	valid_1's binary_logloss: 0.139761
[33]	valid_0's auc: 0.874106	valid_0's binary_logloss: 0.124412	valid_1's auc: 0.838893	valid_1's binary_logloss: 0.139687
[34]	valid_0's auc: 0.874887	valid_0's binary_logloss: 0.124169	valid_1's auc: 0.838801	valid_1's binary_logloss: 0.139672
[35]	valid_0's auc: 0.875447	valid_0's binary_logloss: 0.123934	valid_1's auc: 0.838835	valid_1's binary_logloss: 0.139667
[36]	valid_0's auc: 0.87617	valid_0's binary_logloss: 0.123693	valid_1's auc: 0.838505	valid_1's binary_logloss: 0.139699
[37]	valid_0's auc: 0.876793	valid_0's binary_logloss: 0.12346	valid_1's auc: 0.838104	valid_1's binary_logloss: 0.139783
[38]	valid_0's auc: 0.877265	valid_0's binary_logloss: 0.123251	valid_1's auc: 0.838267	valid_1's binary_logloss: 0.139787
[39]	valid_0's auc: 0.877869	valid_0's binary_logloss: 0.123018	valid_1's auc: 0.838004	valid_1's binary_logloss: 0.139806
[40]	valid_0's auc: 0.878509	valid_0's binary_logloss: 0.122803	valid_1's auc: 0.838086	valid_1's binary_logloss: 0.139745
[41]	valid_0's auc: 0.879077	valid_0's binary_logloss: 0.122585	valid_1's auc: 0.838538	valid_1's binary_logloss: 0.139694
[42]	valid_0's auc: 0.879515	valid_0's binary_logloss: 0.122368	valid_1's auc: 0.838647	valid_1's binary_logloss: 0.139655
[43]	valid_0's auc: 0.879985	valid_0's binary_logloss: 0.122166	valid_1's auc: 0.838495	valid_1's binary_logloss: 0.139653
[44]	valid_0's auc: 0.88041	valid_0's binary_logloss: 0.121985	valid_1's auc: 0.838221	valid_1's binary_logloss: 0.139755
[45]	valid_0's auc: 0.880907	valid_0's binary_logloss: 0.121777	valid_1's auc: 0.837981	valid_1's binary_logloss: 0.139769
[46]	valid_0's auc: 0.881216	valid_0's binary_logloss: 0.121594	valid_1's auc: 0.838471	valid_1's binary_logloss: 0.139693
[47]	valid_0's auc: 0.881591	valid_0's binary_logloss: 0.121422	valid_1's auc: 0.83861	valid_1's binary_logloss: 0.139687
[48]	valid_0's auc: 0.881867	valid_0's binary_logloss: 0.121266	valid_1's auc: 0.838593	valid_1's binary_logloss: 0.139682
[49]	valid_0's auc: 0.882285	valid_0's binary_logloss: 0.121041	valid_1's auc: 0.838317	valid_1's binary_logloss: 0.139741
[50]	valid_0's auc: 0.882828	valid_0's binary_logloss: 0.120853	valid_1's auc: 0.838244	valid_1's binary_logloss: 0.139759
[51]	valid_0's auc: 0.883154	valid_0's binary_logloss: 0.120688	valid_1's auc: 0.838222	valid_1's binary_logloss: 0.139803
[52]	valid_0's auc: 0.883348	valid_0's binary_logloss: 0.120567	valid_1's auc: 0.838064	valid_1's binary_logloss: 0.139824
[53]	valid_0's auc: 0.883583	valid_0's binary_logloss: 0.120424	valid_1's auc: 0.83788	valid_1's binary_logloss: 0.139844
[54]	valid_0's auc: 0.884106	valid_0's binary_logloss: 0.120208	valid_1's auc: 0.837625	valid_1's binary_logloss: 0.139886
[55]	valid_0's auc: 0.884777	valid_0's binary_logloss: 0.120039	valid_1's auc: 0.837585	valid_1's binary_logloss: 0.139902
[56]	valid_0's auc: 0.88511	valid_0's binary_logloss: 0.11989	valid_1's auc: 0.837646	valid_1's binary_logloss: 0.139926
[57]	valid_0's auc: 0.885365	valid_0's binary_logloss: 0.11975	valid_1's auc: 0.837639	valid_1's binary_logloss: 0.139934
[58]	valid_0's auc: 0.885606	valid_0's binary_logloss: 0.119595	valid_1's auc: 0.837726	valid_1's binary_logloss: 0.139938
[59]	valid_0's auc: 0.885965	valid_0's binary_logloss: 0.119403	valid_1's auc: 0.837558	valid_1's binary_logloss: 0.140007
[60]	valid_0's auc: 0.886208	valid_0's binary_logloss: 0.119263	valid_1's auc: 0.83744	valid_1's binary_logloss: 0.140079
[61]	valid_0's auc: 0.886458	valid_0's binary_logloss: 0.119118	valid_1's auc: 0.837349	valid_1's binary_logloss: 0.140059
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.835412	valid_0's binary_logloss: 0.155721	valid_1's auc: 0.81973	valid_1's binary_logloss: 0.164844
[2]	valid_0's auc: 0.841188	valid_0's binary_logloss: 0.150354	valid_1's auc: 0.823402	valid_1's binary_logloss: 0.16006
[3]	valid_0's auc: 0.846758	valid_0's binary_logloss: 0.146288	valid_1's auc: 0.824811	valid_1's binary_logloss: 0.15621
[4]	valid_0's auc: 0.850398	valid_0's binary_logloss: 0.143088	valid_1's auc: 0.830278	valid_1's binary_logloss: 0.153352
[5]	valid_0's auc: 0.853086	valid_0's binary_logloss: 0.140514	valid_1's auc: 0.833574	valid_1's binary_logloss: 0.151071
[6]	valid_0's auc: 0.855915	valid_0's binary_logloss: 0.138329	valid_1's auc: 0.834881	valid_1's binary_logloss: 0.149277
[7]	valid_0's auc: 0.858115	valid_0's binary_logloss: 0.136481	valid_1's auc: 0.833603	valid_1's binary_logloss: 0.14786
[8]	valid_0's auc: 0.859479	valid_0's binary_logloss: 0.134947	valid_1's auc: 0.834093	valid_1's binary_logloss: 0.146607
[9]	valid_0's auc: 0.86143	valid_0's binary_logloss: 0.133519	valid_1's auc: 0.833898	valid_1's binary_logloss: 0.14559
[10]	valid_0's auc: 0.862964	valid_0's binary_logloss: 0.132331	valid_1's auc: 0.835026	valid_1's binary_logloss: 0.144789
[11]	valid_0's auc: 0.864277	valid_0's binary_logloss: 0.13126	valid_1's auc: 0.834957	valid_1's binary_logloss: 0.144152
[12]	valid_0's auc: 0.865572	valid_0's binary_logloss: 0.130304	valid_1's auc: 0.833693	valid_1's binary_logloss: 0.143697
[13]	valid_0's auc: 0.867519	valid_0's binary_logloss: 0.129385	valid_1's auc: 0.833158	valid_1's binary_logloss: 0.143184
[14]	valid_0's auc: 0.869354	valid_0's binary_logloss: 0.128524	valid_1's auc: 0.833598	valid_1's binary_logloss: 0.142668
[15]	valid_0's auc: 0.870553	valid_0's binary_logloss: 0.127746	valid_1's auc: 0.833467	valid_1's binary_logloss: 0.142302
[16]	valid_0's auc: 0.871816	valid_0's binary_logloss: 0.126943	valid_1's auc: 0.83329	valid_1's binary_logloss: 0.142022
[17]	valid_0's auc: 0.872964	valid_0's binary_logloss: 0.126266	valid_1's auc: 0.83279	valid_1's binary_logloss: 0.141891
[18]	valid_0's auc: 0.874047	valid_0's binary_logloss: 0.125646	valid_1's auc: 0.831917	valid_1's binary_logloss: 0.141748
[19]	valid_0's auc: 0.875336	valid_0's binary_logloss: 0.125072	valid_1's auc: 0.831274	valid_1's binary_logloss: 0.141658
[20]	valid_0's auc: 0.876959	valid_0's binary_logloss: 0.124484	valid_1's auc: 0.831275	valid_1's binary_logloss: 0.141511
[21]	valid_0's auc: 0.878049	valid_0's binary_logloss: 0.123928	valid_1's auc: 0.830813	valid_1's binary_logloss: 0.141459
[22]	valid_0's auc: 0.878905	valid_0's binary_logloss: 0.123447	valid_1's auc: 0.83012	valid_1's binary_logloss: 0.141449
[23]	valid_0's auc: 0.879827	valid_0's binary_logloss: 0.12295	valid_1's auc: 0.829554	valid_1's binary_logloss: 0.141492
[24]	valid_0's auc: 0.880692	valid_0's binary_logloss: 0.122479	valid_1's auc: 0.829256	valid_1's binary_logloss: 0.141487
[25]	valid_0's auc: 0.881715	valid_0's binary_logloss: 0.121994	valid_1's auc: 0.829326	valid_1's binary_logloss: 0.141362
[26]	valid_0's auc: 0.883014	valid_0's binary_logloss: 0.121527	valid_1's auc: 0.829553	valid_1's binary_logloss: 0.14132
[27]	valid_0's auc: 0.884245	valid_0's binary_logloss: 0.121024	valid_1's auc: 0.829624	valid_1's binary_logloss: 0.14127
[28]	valid_0's auc: 0.885238	valid_0's binary_logloss: 0.12058	valid_1's auc: 0.829417	valid_1's binary_logloss: 0.141237
[29]	valid_0's auc: 0.88602	valid_0's binary_logloss: 0.120198	valid_1's auc: 0.82917	valid_1's binary_logloss: 0.141201
[30]	valid_0's auc: 0.88684	valid_0's binary_logloss: 0.119831	valid_1's auc: 0.82962	valid_1's binary_logloss: 0.141121
[31]	valid_0's auc: 0.887965	valid_0's binary_logloss: 0.119437	valid_1's auc: 0.83035	valid_1's binary_logloss: 0.14101
[32]	valid_0's auc: 0.88868	valid_0's binary_logloss: 0.119086	valid_1's auc: 0.82975	valid_1's binary_logloss: 0.141093
[33]	valid_0's auc: 0.889895	valid_0's binary_logloss: 0.118649	valid_1's auc: 0.829977	valid_1's binary_logloss: 0.141037
[34]	valid_0's auc: 0.890626	valid_0's binary_logloss: 0.118328	valid_1's auc: 0.829368	valid_1's binary_logloss: 0.141161
[35]	valid_0's auc: 0.89116	valid_0's binary_logloss: 0.11806	valid_1's auc: 0.829262	valid_1's binary_logloss: 0.141183
[36]	valid_0's auc: 0.891999	valid_0's binary_logloss: 0.11775	valid_1's auc: 0.828947	valid_1's binary_logloss: 0.14129
[37]	valid_0's auc: 0.892306	valid_0's binary_logloss: 0.117477	valid_1's auc: 0.828544	valid_1's binary_logloss: 0.141389
[38]	valid_0's auc: 0.892937	valid_0's binary_logloss: 0.117192	valid_1's auc: 0.827983	valid_1's binary_logloss: 0.141516
[39]	valid_0's auc: 0.893563	valid_0's binary_logloss: 0.116869	valid_1's auc: 0.828068	valid_1's binary_logloss: 0.141517
[40]	valid_0's auc: 0.893942	valid_0's binary_logloss: 0.11662	valid_1's auc: 0.827852	valid_1's binary_logloss: 0.141621
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.830474	valid_0's binary_logloss: 0.155928	valid_1's auc: 0.817343	valid_1's binary_logloss: 0.164928
[2]	valid_0's auc: 0.842931	valid_0's binary_logloss: 0.1503	valid_1's auc: 0.82699	valid_1's binary_logloss: 0.15948
[3]	valid_0's auc: 0.850877	valid_0's binary_logloss: 0.14631	valid_1's auc: 0.832212	valid_1's binary_logloss: 0.155775
[4]	valid_0's auc: 0.854431	valid_0's binary_logloss: 0.143104	valid_1's auc: 0.83392	valid_1's binary_logloss: 0.152698
[5]	valid_0's auc: 0.85663	valid_0's binary_logloss: 0.140582	valid_1's auc: 0.835094	valid_1's binary_logloss: 0.150349
[6]	valid_0's auc: 0.859142	valid_0's binary_logloss: 0.138289	valid_1's auc: 0.836166	valid_1's binary_logloss: 0.148424
[7]	valid_0's auc: 0.861364	valid_0's binary_logloss: 0.136413	valid_1's auc: 0.837184	valid_1's binary_logloss: 0.146912
[8]	valid_0's auc: 0.862199	valid_0's binary_logloss: 0.134841	valid_1's auc: 0.837545	valid_1's binary_logloss: 0.145726
[9]	valid_0's auc: 0.864095	valid_0's binary_logloss: 0.133364	valid_1's auc: 0.837242	valid_1's binary_logloss: 0.144736
[10]	valid_0's auc: 0.866024	valid_0's binary_logloss: 0.132096	valid_1's auc: 0.837719	valid_1's binary_logloss: 0.143766
[11]	valid_0's auc: 0.867454	valid_0's binary_logloss: 0.131002	valid_1's auc: 0.837865	valid_1's binary_logloss: 0.143009
[12]	valid_0's auc: 0.868329	valid_0's binary_logloss: 0.130024	valid_1's auc: 0.837259	valid_1's binary_logloss: 0.14244
[13]	valid_0's auc: 0.869137	valid_0's binary_logloss: 0.129145	valid_1's auc: 0.837689	valid_1's binary_logloss: 0.141896
[14]	valid_0's auc: 0.870957	valid_0's binary_logloss: 0.128226	valid_1's auc: 0.838226	valid_1's binary_logloss: 0.141392
[15]	valid_0's auc: 0.872273	valid_0's binary_logloss: 0.12745	valid_1's auc: 0.837906	valid_1's binary_logloss: 0.141019
[16]	valid_0's auc: 0.873243	valid_0's binary_logloss: 0.12672	valid_1's auc: 0.837761	valid_1's binary_logloss: 0.140677
[17]	valid_0's auc: 0.874251	valid_0's binary_logloss: 0.126044	valid_1's auc: 0.83701	valid_1's binary_logloss: 0.140582
[18]	valid_0's auc: 0.875622	valid_0's binary_logloss: 0.125387	valid_1's auc: 0.836179	valid_1's binary_logloss: 0.140485
[19]	valid_0's auc: 0.877031	valid_0's binary_logloss: 0.124759	valid_1's auc: 0.836188	valid_1's binary_logloss: 0.14029
[20]	valid_0's auc: 0.878046	valid_0's binary_logloss: 0.124156	valid_1's auc: 0.836531	valid_1's binary_logloss: 0.140133
[21]	valid_0's auc: 0.879478	valid_0's binary_logloss: 0.123507	valid_1's auc: 0.837068	valid_1's binary_logloss: 0.13995
[22]	valid_0's auc: 0.880423	valid_0's binary_logloss: 0.123029	valid_1's auc: 0.836817	valid_1's binary_logloss: 0.139912
[23]	valid_0's auc: 0.881684	valid_0's binary_logloss: 0.122492	valid_1's auc: 0.836983	valid_1's binary_logloss: 0.139762
[24]	valid_0's auc: 0.882873	valid_0's binary_logloss: 0.121986	valid_1's auc: 0.837319	valid_1's binary_logloss: 0.139659
[25]	valid_0's auc: 0.883597	valid_0's binary_logloss: 0.121566	valid_1's auc: 0.837154	valid_1's binary_logloss: 0.139623
[26]	valid_0's auc: 0.884814	valid_0's binary_logloss: 0.121104	valid_1's auc: 0.836302	valid_1's binary_logloss: 0.139668
[27]	valid_0's auc: 0.886026	valid_0's binary_logloss: 0.120635	valid_1's auc: 0.836521	valid_1's binary_logloss: 0.139601
[28]	valid_0's auc: 0.887071	valid_0's binary_logloss: 0.120222	valid_1's auc: 0.836646	valid_1's binary_logloss: 0.139557
[29]	valid_0's auc: 0.887946	valid_0's binary_logloss: 0.119804	valid_1's auc: 0.836735	valid_1's binary_logloss: 0.139518
[30]	valid_0's auc: 0.88898	valid_0's binary_logloss: 0.119416	valid_1's auc: 0.836858	valid_1's binary_logloss: 0.139499
[31]	valid_0's auc: 0.889792	valid_0's binary_logloss: 0.119058	valid_1's auc: 0.836917	valid_1's binary_logloss: 0.139463
[32]	valid_0's auc: 0.890876	valid_0's binary_logloss: 0.118631	valid_1's auc: 0.836346	valid_1's binary_logloss: 0.139532
[33]	valid_0's auc: 0.891629	valid_0's binary_logloss: 0.118259	valid_1's auc: 0.836206	valid_1's binary_logloss: 0.139603
[34]	valid_0's auc: 0.892446	valid_0's binary_logloss: 0.117893	valid_1's auc: 0.836005	valid_1's binary_logloss: 0.139603
[35]	valid_0's auc: 0.893407	valid_0's binary_logloss: 0.11752	valid_1's auc: 0.8361	valid_1's binary_logloss: 0.139574
[36]	valid_0's auc: 0.893836	valid_0's binary_logloss: 0.117247	valid_1's auc: 0.836147	valid_1's binary_logloss: 0.139608
[37]	valid_0's auc: 0.894774	valid_0's binary_logloss: 0.116913	valid_1's auc: 0.836601	valid_1's binary_logloss: 0.139569
[38]	valid_0's auc: 0.895494	valid_0's binary_logloss: 0.116611	valid_1's auc: 0.836232	valid_1's binary_logloss: 0.139645
[39]	valid_0's auc: 0.896102	valid_0's binary_logloss: 0.116275	valid_1's auc: 0.836415	valid_1's binary_logloss: 0.139653
[40]	valid_0's auc: 0.896715	valid_0's binary_logloss: 0.115934	valid_1's auc: 0.836463	valid_1's binary_logloss: 0.139671
[41]	valid_0's auc: 0.897232	valid_0's binary_logloss: 0.115612	valid_1's auc: 0.836223	valid_1's binary_logloss: 0.139762
[42]	valid_0's auc: 0.897875	valid_0's binary_logloss: 0.11528	valid_1's auc: 0.836151	valid_1's binary_logloss: 0.139777
[43]	valid_0's auc: 0.898493	valid_0's binary_logloss: 0.114999	valid_1's auc: 0.836216	valid_1's binary_logloss: 0.139761
[44]	valid_0's auc: 0.899179	valid_0's binary_logloss: 0.114703	valid_1's auc: 0.836328	valid_1's binary_logloss: 0.139755
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.834724	valid_0's binary_logloss: 0.15607	valid_1's auc: 0.822983	valid_1's binary_logloss: 0.165104
[2]	valid_0's auc: 0.842835	valid_0's binary_logloss: 0.150494	valid_1's auc: 0.830472	valid_1's binary_logloss: 0.159671
[3]	valid_0's auc: 0.847187	valid_0's binary_logloss: 0.146306	valid_1's auc: 0.830873	valid_1's binary_logloss: 0.155985
[4]	valid_0's auc: 0.850394	valid_0's binary_logloss: 0.143088	valid_1's auc: 0.830975	valid_1's binary_logloss: 0.15321
[5]	valid_0's auc: 0.853379	valid_0's binary_logloss: 0.140508	valid_1's auc: 0.832135	valid_1's binary_logloss: 0.150854
[6]	valid_0's auc: 0.855463	valid_0's binary_logloss: 0.138297	valid_1's auc: 0.833116	valid_1's binary_logloss: 0.149013
[7]	valid_0's auc: 0.856723	valid_0's binary_logloss: 0.136504	valid_1's auc: 0.833811	valid_1's binary_logloss: 0.147577
[8]	valid_0's auc: 0.858076	valid_0's binary_logloss: 0.13495	valid_1's auc: 0.835315	valid_1's binary_logloss: 0.146273
[9]	valid_0's auc: 0.861024	valid_0's binary_logloss: 0.133583	valid_1's auc: 0.835042	valid_1's binary_logloss: 0.145374
[10]	valid_0's auc: 0.862281	valid_0's binary_logloss: 0.132357	valid_1's auc: 0.834154	valid_1's binary_logloss: 0.144649
[11]	valid_0's auc: 0.864612	valid_0's binary_logloss: 0.131283	valid_1's auc: 0.834587	valid_1's binary_logloss: 0.143941
[12]	valid_0's auc: 0.866377	valid_0's binary_logloss: 0.130299	valid_1's auc: 0.834242	valid_1's binary_logloss: 0.143366
[13]	valid_0's auc: 0.868343	valid_0's binary_logloss: 0.129417	valid_1's auc: 0.833273	valid_1's binary_logloss: 0.142976
[14]	valid_0's auc: 0.86957	valid_0's binary_logloss: 0.128593	valid_1's auc: 0.833783	valid_1's binary_logloss: 0.142567
[15]	valid_0's auc: 0.871109	valid_0's binary_logloss: 0.127759	valid_1's auc: 0.834057	valid_1's binary_logloss: 0.142234
[16]	valid_0's auc: 0.872893	valid_0's binary_logloss: 0.126996	valid_1's auc: 0.835329	valid_1's binary_logloss: 0.141809
[17]	valid_0's auc: 0.874236	valid_0's binary_logloss: 0.12631	valid_1's auc: 0.834985	valid_1's binary_logloss: 0.141613
[18]	valid_0's auc: 0.875324	valid_0's binary_logloss: 0.125725	valid_1's auc: 0.834942	valid_1's binary_logloss: 0.141363
[19]	valid_0's auc: 0.876659	valid_0's binary_logloss: 0.125068	valid_1's auc: 0.835024	valid_1's binary_logloss: 0.141162
[20]	valid_0's auc: 0.877885	valid_0's binary_logloss: 0.124484	valid_1's auc: 0.835893	valid_1's binary_logloss: 0.140933
[21]	valid_0's auc: 0.879121	valid_0's binary_logloss: 0.12391	valid_1's auc: 0.837029	valid_1's binary_logloss: 0.140651
[22]	valid_0's auc: 0.880116	valid_0's binary_logloss: 0.123339	valid_1's auc: 0.837366	valid_1's binary_logloss: 0.140547
[23]	valid_0's auc: 0.881224	valid_0's binary_logloss: 0.12282	valid_1's auc: 0.837357	valid_1's binary_logloss: 0.140445
[24]	valid_0's auc: 0.882014	valid_0's binary_logloss: 0.122386	valid_1's auc: 0.837343	valid_1's binary_logloss: 0.140371
[25]	valid_0's auc: 0.88318	valid_0's binary_logloss: 0.121861	valid_1's auc: 0.83723	valid_1's binary_logloss: 0.140313
[26]	valid_0's auc: 0.884008	valid_0's binary_logloss: 0.121441	valid_1's auc: 0.837761	valid_1's binary_logloss: 0.140173
[27]	valid_0's auc: 0.884676	valid_0's binary_logloss: 0.121001	valid_1's auc: 0.838046	valid_1's binary_logloss: 0.140086
[28]	valid_0's auc: 0.885524	valid_0's binary_logloss: 0.120598	valid_1's auc: 0.838029	valid_1's binary_logloss: 0.140051
[29]	valid_0's auc: 0.886461	valid_0's binary_logloss: 0.120157	valid_1's auc: 0.837775	valid_1's binary_logloss: 0.140057
[30]	valid_0's auc: 0.887053	valid_0's binary_logloss: 0.119807	valid_1's auc: 0.837472	valid_1's binary_logloss: 0.140111
[31]	valid_0's auc: 0.888177	valid_0's binary_logloss: 0.119425	valid_1's auc: 0.837575	valid_1's binary_logloss: 0.140093
[32]	valid_0's auc: 0.889072	valid_0's binary_logloss: 0.119055	valid_1's auc: 0.837158	valid_1's binary_logloss: 0.140195
[33]	valid_0's auc: 0.889782	valid_0's binary_logloss: 0.118676	valid_1's auc: 0.837296	valid_1's binary_logloss: 0.140221
[34]	valid_0's auc: 0.890876	valid_0's binary_logloss: 0.118304	valid_1's auc: 0.837481	valid_1's binary_logloss: 0.140165
[35]	valid_0's auc: 0.891448	valid_0's binary_logloss: 0.11798	valid_1's auc: 0.837953	valid_1's binary_logloss: 0.140085
[36]	valid_0's auc: 0.892165	valid_0's binary_logloss: 0.11764	valid_1's auc: 0.837794	valid_1's binary_logloss: 0.140112
[37]	valid_0's auc: 0.892798	valid_0's binary_logloss: 0.117321	valid_1's auc: 0.837291	valid_1's binary_logloss: 0.140221
[38]	valid_0's auc: 0.893318	valid_0's binary_logloss: 0.117028	valid_1's auc: 0.837278	valid_1's binary_logloss: 0.140221
[39]	valid_0's auc: 0.894018	valid_0's binary_logloss: 0.116742	valid_1's auc: 0.83724	valid_1's binary_logloss: 0.140232
[40]	valid_0's auc: 0.894781	valid_0's binary_logloss: 0.116373	valid_1's auc: 0.836901	valid_1's binary_logloss: 0.140328
[41]	valid_0's auc: 0.895222	valid_0's binary_logloss: 0.116075	valid_1's auc: 0.836655	valid_1's binary_logloss: 0.140422
[42]	valid_0's auc: 0.895842	valid_0's binary_logloss: 0.115755	valid_1's auc: 0.836383	valid_1's binary_logloss: 0.140503
[43]	valid_0's auc: 0.896389	valid_0's binary_logloss: 0.115503	valid_1's auc: 0.836348	valid_1's binary_logloss: 0.140505
[44]	valid_0's auc: 0.896843	valid_0's binary_logloss: 0.115204	valid_1's auc: 0.836521	valid_1's binary_logloss: 0.140518
[45]	valid_0's auc: 0.897272	valid_0's binary_logloss: 0.114886	valid_1's auc: 0.836311	valid_1's binary_logloss: 0.140581
[46]	valid_0's auc: 0.898034	valid_0's binary_logloss: 0.114544	valid_1's auc: 0.835871	valid_1's binary_logloss: 0.140663
[47]	valid_0's auc: 0.898562	valid_0's binary_logloss: 0.114262	valid_1's auc: 0.835926	valid_1's binary_logloss: 0.140642
[48]	valid_0's auc: 0.898919	valid_0's binary_logloss: 0.114006	valid_1's auc: 0.835849	valid_1's binary_logloss: 0.140687
[49]	valid_0's auc: 0.899111	valid_0's binary_logloss: 0.113791	valid_1's auc: 0.835874	valid_1's binary_logloss: 0.140728
[50]	valid_0's auc: 0.89987	valid_0's binary_logloss: 0.113543	valid_1's auc: 0.835915	valid_1's binary_logloss: 0.14075
[51]	valid_0's auc: 0.90004	valid_0's binary_logloss: 0.113342	valid_1's auc: 0.835947	valid_1's binary_logloss: 0.140748
[52]	valid_0's auc: 0.900405	valid_0's binary_logloss: 0.113087	valid_1's auc: 0.836011	valid_1's binary_logloss: 0.140767
[53]	valid_0's auc: 0.900828	valid_0's binary_logloss: 0.112831	valid_1's auc: 0.836259	valid_1's binary_logloss: 0.140771
[54]	valid_0's auc: 0.901597	valid_0's binary_logloss: 0.112604	valid_1's auc: 0.836296	valid_1's binary_logloss: 0.14078
[55]	valid_0's auc: 0.901645	valid_0's binary_logloss: 0.112429	valid_1's auc: 0.836095	valid_1's binary_logloss: 0.140822
[56]	valid_0's auc: 0.902162	valid_0's binary_logloss: 0.112169	valid_1's auc: 0.835965	valid_1's binary_logloss: 0.14086
[57]	valid_0's auc: 0.902422	valid_0's binary_logloss: 0.111944	valid_1's auc: 0.835493	valid_1's binary_logloss: 0.140993
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.835412	valid_0's binary_logloss: 0.155721	valid_1's auc: 0.81973	valid_1's binary_logloss: 0.164844
[2]	valid_0's auc: 0.841188	valid_0's binary_logloss: 0.150354	valid_1's auc: 0.823402	valid_1's binary_logloss: 0.16006
[3]	valid_0's auc: 0.846758	valid_0's binary_logloss: 0.146288	valid_1's auc: 0.824811	valid_1's binary_logloss: 0.15621
[4]	valid_0's auc: 0.850398	valid_0's binary_logloss: 0.143088	valid_1's auc: 0.830278	valid_1's binary_logloss: 0.153352
[5]	valid_0's auc: 0.853086	valid_0's binary_logloss: 0.140514	valid_1's auc: 0.833574	valid_1's binary_logloss: 0.151071
[6]	valid_0's auc: 0.855915	valid_0's binary_logloss: 0.138329	valid_1's auc: 0.834881	valid_1's binary_logloss: 0.149277
[7]	valid_0's auc: 0.858115	valid_0's binary_logloss: 0.136481	valid_1's auc: 0.833603	valid_1's binary_logloss: 0.14786
[8]	valid_0's auc: 0.859479	valid_0's binary_logloss: 0.134947	valid_1's auc: 0.834093	valid_1's binary_logloss: 0.146607
[9]	valid_0's auc: 0.86143	valid_0's binary_logloss: 0.133519	valid_1's auc: 0.833898	valid_1's binary_logloss: 0.14559
[10]	valid_0's auc: 0.862964	valid_0's binary_logloss: 0.132331	valid_1's auc: 0.835026	valid_1's binary_logloss: 0.144789
[11]	valid_0's auc: 0.864277	valid_0's binary_logloss: 0.13126	valid_1's auc: 0.834957	valid_1's binary_logloss: 0.144152
[12]	valid_0's auc: 0.865572	valid_0's binary_logloss: 0.130304	valid_1's auc: 0.833693	valid_1's binary_logloss: 0.143697
[13]	valid_0's auc: 0.867519	valid_0's binary_logloss: 0.129385	valid_1's auc: 0.833158	valid_1's binary_logloss: 0.143184
[14]	valid_0's auc: 0.869354	valid_0's binary_logloss: 0.128524	valid_1's auc: 0.833598	valid_1's binary_logloss: 0.142668
[15]	valid_0's auc: 0.870553	valid_0's binary_logloss: 0.127746	valid_1's auc: 0.833467	valid_1's binary_logloss: 0.142302
[16]	valid_0's auc: 0.871816	valid_0's binary_logloss: 0.126943	valid_1's auc: 0.83329	valid_1's binary_logloss: 0.142022
[17]	valid_0's auc: 0.872964	valid_0's binary_logloss: 0.126266	valid_1's auc: 0.83279	valid_1's binary_logloss: 0.141891
[18]	valid_0's auc: 0.874047	valid_0's binary_logloss: 0.125646	valid_1's auc: 0.831917	valid_1's binary_logloss: 0.141748
[19]	valid_0's auc: 0.875336	valid_0's binary_logloss: 0.125072	valid_1's auc: 0.831274	valid_1's binary_logloss: 0.141658
[20]	valid_0's auc: 0.876959	valid_0's binary_logloss: 0.124484	valid_1's auc: 0.831275	valid_1's binary_logloss: 0.141511
[21]	valid_0's auc: 0.878049	valid_0's binary_logloss: 0.123928	valid_1's auc: 0.830813	valid_1's binary_logloss: 0.141459
[22]	valid_0's auc: 0.878905	valid_0's binary_logloss: 0.123447	valid_1's auc: 0.83012	valid_1's binary_logloss: 0.141449
[23]	valid_0's auc: 0.879827	valid_0's binary_logloss: 0.12295	valid_1's auc: 0.829554	valid_1's binary_logloss: 0.141492
[24]	valid_0's auc: 0.880692	valid_0's binary_logloss: 0.122479	valid_1's auc: 0.829256	valid_1's binary_logloss: 0.141487
[25]	valid_0's auc: 0.881715	valid_0's binary_logloss: 0.121994	valid_1's auc: 0.829326	valid_1's binary_logloss: 0.141362
[26]	valid_0's auc: 0.883014	valid_0's binary_logloss: 0.121527	valid_1's auc: 0.829553	valid_1's binary_logloss: 0.14132
[27]	valid_0's auc: 0.884245	valid_0's binary_logloss: 0.121024	valid_1's auc: 0.829624	valid_1's binary_logloss: 0.14127
[28]	valid_0's auc: 0.885238	valid_0's binary_logloss: 0.12058	valid_1's auc: 0.829417	valid_1's binary_logloss: 0.141237
[29]	valid_0's auc: 0.88602	valid_0's binary_logloss: 0.120198	valid_1's auc: 0.82917	valid_1's binary_logloss: 0.141201
[30]	valid_0's auc: 0.88684	valid_0's binary_logloss: 0.119831	valid_1's auc: 0.82962	valid_1's binary_logloss: 0.141121
[31]	valid_0's auc: 0.887965	valid_0's binary_logloss: 0.119437	valid_1's auc: 0.83035	valid_1's binary_logloss: 0.14101
[32]	valid_0's auc: 0.88868	valid_0's binary_logloss: 0.119086	valid_1's auc: 0.82975	valid_1's binary_logloss: 0.141093
[33]	valid_0's auc: 0.889895	valid_0's binary_logloss: 0.118649	valid_1's auc: 0.829977	valid_1's binary_logloss: 0.141037
[34]	valid_0's auc: 0.890626	valid_0's binary_logloss: 0.118328	valid_1's auc: 0.829368	valid_1's binary_logloss: 0.141161
[35]	valid_0's auc: 0.89116	valid_0's binary_logloss: 0.11806	valid_1's auc: 0.829262	valid_1's binary_logloss: 0.141183
[36]	valid_0's auc: 0.891999	valid_0's binary_logloss: 0.11775	valid_1's auc: 0.828947	valid_1's binary_logloss: 0.14129
[37]	valid_0's auc: 0.892306	valid_0's binary_logloss: 0.117477	valid_1's auc: 0.828544	valid_1's binary_logloss: 0.141389
[38]	valid_0's auc: 0.892937	valid_0's binary_logloss: 0.117192	valid_1's auc: 0.827983	valid_1's binary_logloss: 0.141516
[39]	valid_0's auc: 0.893563	valid_0's binary_logloss: 0.116869	valid_1's auc: 0.828068	valid_1's binary_logloss: 0.141517
[40]	valid_0's auc: 0.893942	valid_0's binary_logloss: 0.11662	valid_1's auc: 0.827852	valid_1's binary_logloss: 0.141621
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.830474	valid_0's binary_logloss: 0.155928	valid_1's auc: 0.817343	valid_1's binary_logloss: 0.164928
[2]	valid_0's auc: 0.842931	valid_0's binary_logloss: 0.1503	valid_1's auc: 0.82699	valid_1's binary_logloss: 0.15948
[3]	valid_0's auc: 0.850877	valid_0's binary_logloss: 0.14631	valid_1's auc: 0.832212	valid_1's binary_logloss: 0.155775
[4]	valid_0's auc: 0.854431	valid_0's binary_logloss: 0.143104	valid_1's auc: 0.83392	valid_1's binary_logloss: 0.152698
[5]	valid_0's auc: 0.85663	valid_0's binary_logloss: 0.140582	valid_1's auc: 0.835094	valid_1's binary_logloss: 0.150349
[6]	valid_0's auc: 0.859142	valid_0's binary_logloss: 0.138289	valid_1's auc: 0.836166	valid_1's binary_logloss: 0.148424
[7]	valid_0's auc: 0.861364	valid_0's binary_logloss: 0.136413	valid_1's auc: 0.837184	valid_1's binary_logloss: 0.146912
[8]	valid_0's auc: 0.862199	valid_0's binary_logloss: 0.134841	valid_1's auc: 0.837545	valid_1's binary_logloss: 0.145726
[9]	valid_0's auc: 0.864095	valid_0's binary_logloss: 0.133364	valid_1's auc: 0.837242	valid_1's binary_logloss: 0.144736
[10]	valid_0's auc: 0.866024	valid_0's binary_logloss: 0.132096	valid_1's auc: 0.837719	valid_1's binary_logloss: 0.143766
[11]	valid_0's auc: 0.867454	valid_0's binary_logloss: 0.131002	valid_1's auc: 0.837865	valid_1's binary_logloss: 0.143009
[12]	valid_0's auc: 0.868329	valid_0's binary_logloss: 0.130024	valid_1's auc: 0.837259	valid_1's binary_logloss: 0.14244
[13]	valid_0's auc: 0.869137	valid_0's binary_logloss: 0.129145	valid_1's auc: 0.837689	valid_1's binary_logloss: 0.141896
[14]	valid_0's auc: 0.870957	valid_0's binary_logloss: 0.128226	valid_1's auc: 0.838226	valid_1's binary_logloss: 0.141392
[15]	valid_0's auc: 0.872273	valid_0's binary_logloss: 0.12745	valid_1's auc: 0.837906	valid_1's binary_logloss: 0.141019
[16]	valid_0's auc: 0.873243	valid_0's binary_logloss: 0.12672	valid_1's auc: 0.837761	valid_1's binary_logloss: 0.140677
[17]	valid_0's auc: 0.874251	valid_0's binary_logloss: 0.126044	valid_1's auc: 0.83701	valid_1's binary_logloss: 0.140582
[18]	valid_0's auc: 0.875622	valid_0's binary_logloss: 0.125387	valid_1's auc: 0.836179	valid_1's binary_logloss: 0.140485
[19]	valid_0's auc: 0.877031	valid_0's binary_logloss: 0.124759	valid_1's auc: 0.836188	valid_1's binary_logloss: 0.14029
[20]	valid_0's auc: 0.878046	valid_0's binary_logloss: 0.124156	valid_1's auc: 0.836531	valid_1's binary_logloss: 0.140133
[21]	valid_0's auc: 0.879478	valid_0's binary_logloss: 0.123507	valid_1's auc: 0.837068	valid_1's binary_logloss: 0.13995
[22]	valid_0's auc: 0.880423	valid_0's binary_logloss: 0.123029	valid_1's auc: 0.836817	valid_1's binary_logloss: 0.139912
[23]	valid_0's auc: 0.881684	valid_0's binary_logloss: 0.122492	valid_1's auc: 0.836983	valid_1's binary_logloss: 0.139762
[24]	valid_0's auc: 0.882873	valid_0's binary_logloss: 0.121986	valid_1's auc: 0.837319	valid_1's binary_logloss: 0.139659
[25]	valid_0's auc: 0.883597	valid_0's binary_logloss: 0.121566	valid_1's auc: 0.837154	valid_1's binary_logloss: 0.139623
[26]	valid_0's auc: 0.884814	valid_0's binary_logloss: 0.121104	valid_1's auc: 0.836302	valid_1's binary_logloss: 0.139668
[27]	valid_0's auc: 0.886026	valid_0's binary_logloss: 0.120635	valid_1's auc: 0.836521	valid_1's binary_logloss: 0.139601
[28]	valid_0's auc: 0.887071	valid_0's binary_logloss: 0.120222	valid_1's auc: 0.836646	valid_1's binary_logloss: 0.139557
[29]	valid_0's auc: 0.887946	valid_0's binary_logloss: 0.119804	valid_1's auc: 0.836735	valid_1's binary_logloss: 0.139518
[30]	valid_0's auc: 0.88898	valid_0's binary_logloss: 0.119416	valid_1's auc: 0.836858	valid_1's binary_logloss: 0.139499
[31]	valid_0's auc: 0.889792	valid_0's binary_logloss: 0.119058	valid_1's auc: 0.836917	valid_1's binary_logloss: 0.139463
[32]	valid_0's auc: 0.890876	valid_0's binary_logloss: 0.118631	valid_1's auc: 0.836346	valid_1's binary_logloss: 0.139532
[33]	valid_0's auc: 0.891629	valid_0's binary_logloss: 0.118259	valid_1's auc: 0.836206	valid_1's binary_logloss: 0.139603
[34]	valid_0's auc: 0.892446	valid_0's binary_logloss: 0.117893	valid_1's auc: 0.836005	valid_1's binary_logloss: 0.139603
[35]	valid_0's auc: 0.893407	valid_0's binary_logloss: 0.11752	valid_1's auc: 0.8361	valid_1's binary_logloss: 0.139574
[36]	valid_0's auc: 0.893836	valid_0's binary_logloss: 0.117247	valid_1's auc: 0.836147	valid_1's binary_logloss: 0.139608
[37]	valid_0's auc: 0.894774	valid_0's binary_logloss: 0.116913	valid_1's auc: 0.836601	valid_1's binary_logloss: 0.139569
[38]	valid_0's auc: 0.895494	valid_0's binary_logloss: 0.116611	valid_1's auc: 0.836232	valid_1's binary_logloss: 0.139645
[39]	valid_0's auc: 0.896102	valid_0's binary_logloss: 0.116275	valid_1's auc: 0.836415	valid_1's binary_logloss: 0.139653
[40]	valid_0's auc: 0.896715	valid_0's binary_logloss: 0.115934	valid_1's auc: 0.836463	valid_1's binary_logloss: 0.139671
[41]	valid_0's auc: 0.897232	valid_0's binary_logloss: 0.115612	valid_1's auc: 0.836223	valid_1's binary_logloss: 0.139762
[42]	valid_0's auc: 0.897875	valid_0's binary_logloss: 0.11528	valid_1's auc: 0.836151	valid_1's binary_logloss: 0.139777
[43]	valid_0's auc: 0.898493	valid_0's binary_logloss: 0.114999	valid_1's auc: 0.836216	valid_1's binary_logloss: 0.139761
[44]	valid_0's auc: 0.899179	valid_0's binary_logloss: 0.114703	valid_1's auc: 0.836328	valid_1's binary_logloss: 0.139755
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	valid_0's auc: 0.834724	valid_0's binary_logloss: 0.15607	valid_1's auc: 0.822983	valid_1's binary_logloss: 0.165104
[2]	valid_0's auc: 0.842835	valid_0's binary_logloss: 0.150494	valid_1's auc: 0.830472	valid_1's binary_logloss: 0.159671
[3]	valid_0's auc: 0.847187	valid_0's binary_logloss: 0.146306	valid_1's auc: 0.830873	valid_1's binary_logloss: 0.155985
[4]	valid_0's auc: 0.850394	valid_0's binary_logloss: 0.143088	valid_1's auc: 0.830975	valid_1's binary_logloss: 0.15321
[5]	valid_0's auc: 0.853379	valid_0's binary_logloss: 0.140508	valid_1's auc: 0.832135	valid_1's binary_logloss: 0.150854
[6]	valid_0's auc: 0.855463	valid_0's binary_logloss: 0.138297	valid_1's auc: 0.833116	valid_1's binary_logloss: 0.149013
[7]	valid_0's auc: 0.856723	valid_0's binary_logloss: 0.136504	valid_1's auc: 0.833811	valid_1's binary_logloss: 0.147577
[8]	valid_0's auc: 0.858076	valid_0's binary_logloss: 0.13495	valid_1's auc: 0.835315	valid_1's binary_logloss: 0.146273
[9]	valid_0's auc: 0.861024	valid_0's binary_logloss: 0.133583	valid_1's auc: 0.835042	valid_1's binary_logloss: 0.145374
[10]	valid_0's auc: 0.862281	valid_0's binary_logloss: 0.132357	valid_1's auc: 0.834154	valid_1's binary_logloss: 0.144649
[11]	valid_0's auc: 0.864612	valid_0's binary_logloss: 0.131283	valid_1's auc: 0.834587	valid_1's binary_logloss: 0.143941
[12]	valid_0's auc: 0.866377	valid_0's binary_logloss: 0.130299	valid_1's auc: 0.834242	valid_1's binary_logloss: 0.143366
[13]	valid_0's auc: 0.868343	valid_0's binary_logloss: 0.129417	valid_1's auc: 0.833273	valid_1's binary_logloss: 0.142976
[14]	valid_0's auc: 0.86957	valid_0's binary_logloss: 0.128593	valid_1's auc: 0.833783	valid_1's binary_logloss: 0.142567
[15]	valid_0's auc: 0.871109	valid_0's binary_logloss: 0.127759	valid_1's auc: 0.834057	valid_1's binary_logloss: 0.142234
[16]	valid_0's auc: 0.872893	valid_0's binary_logloss: 0.126996	valid_1's auc: 0.835329	valid_1's binary_logloss: 0.141809
[17]	valid_0's auc: 0.874236	valid_0's binary_logloss: 0.12631	valid_1's auc: 0.834985	valid_1's binary_logloss: 0.141613
[18]	valid_0's auc: 0.875324	valid_0's binary_logloss: 0.125725	valid_1's auc: 0.834942	valid_1's binary_logloss: 0.141363
[19]	valid_0's auc: 0.876659	valid_0's binary_logloss: 0.125068	valid_1's auc: 0.835024	valid_1's binary_logloss: 0.141162
[20]	valid_0's auc: 0.877885	valid_0's binary_logloss: 0.124484	valid_1's auc: 0.835893	valid_1's binary_logloss: 0.140933
[21]	valid_0's auc: 0.879121	valid_0's binary_logloss: 0.12391	valid_1's auc: 0.837029	valid_1's binary_logloss: 0.140651
[22]	valid_0's auc: 0.880116	valid_0's binary_logloss: 0.123339	valid_1's auc: 0.837366	valid_1's binary_logloss: 0.140547
[23]	valid_0's auc: 0.881224	valid_0's binary_logloss: 0.12282	valid_1's auc: 0.837357	valid_1's binary_logloss: 0.140445
[24]	valid_0's auc: 0.882014	valid_0's binary_logloss: 0.122386	valid_1's auc: 0.837343	valid_1's binary_logloss: 0.140371
[25]	valid_0's auc: 0.88318	valid_0's binary_logloss: 0.121861	valid_1's auc: 0.83723	valid_1's binary_logloss: 0.140313
[26]	valid_0's auc: 0.884008	valid_0's binary_logloss: 0.121441	valid_1's auc: 0.837761	valid_1's binary_logloss: 0.140173
[27]	valid_0's auc: 0.884676	valid_0's binary_logloss: 0.121001	valid_1's auc: 0.838046	valid_1's binary_logloss: 0.140086
[28]	valid_0's auc: 0.885524	valid_0's binary_logloss: 0.120598	valid_1's auc: 0.838029	valid_1's binary_logloss: 0.140051
[29]	valid_0's auc: 0.886461	valid_0's binary_logloss: 0.120157	valid_1's auc: 0.837775	valid_1's binary_logloss: 0.140057
[30]	valid_0's auc: 0.887053	valid_0's binary_logloss: 0.119807	valid_1's auc: 0.837472	valid_1's binary_logloss: 0.140111
[31]	valid_0's auc: 0.888177	valid_0's binary_logloss: 0.119425	valid_1's auc: 0.837575	valid_1's binary_logloss: 0.140093
[32]	valid_0's auc: 0.889072	valid_0's binary_logloss: 0.119055	valid_1's auc: 0.837158	valid_1's binary_logloss: 0.140195
[33]	valid_0's auc: 0.889782	valid_0's binary_logloss: 0.118676	valid_1's auc: 0.837296	valid_1's binary_logloss: 0.140221
[34]	valid_0's auc: 0.890876	valid_0's binary_logloss: 0.118304	valid_1's auc: 0.837481	valid_1's binary_logloss: 0.140165
[35]	valid_0's auc: 0.891448	valid_0's binary_logloss: 0.11798	valid_1's auc: 0.837953	valid_1's binary_logloss: 0.140085
[36]	valid_0's auc: 0.892165	valid_0's binary_logloss: 0.11764	valid_1's auc: 0.837794	valid_1's binary_logloss: 0.140112
[37]	valid_0's auc: 0.892798	valid_0's binary_logloss: 0.117321	valid_1's auc: 0.837291	valid_1's binary_logloss: 0.140221
[38]	valid_0's auc: 0.893318	valid_0's binary_logloss: 0.117028	valid_1's auc: 0.837278	valid_1's binary_logloss: 0.140221
[39]	valid_0's auc: 0.894018	valid_0's binary_logloss: 0.116742	valid_1's auc: 0.83724	valid_1's binary_logloss: 0.140232
[40]	valid_0's auc: 0.894781	valid_0's binary_logloss: 0.116373	valid_1's auc: 0.836901	valid_1's binary_logloss: 0.140328
[41]	valid_0's auc: 0.895222	valid_0's binary_logloss: 0.116075	valid_1's auc: 0.836655	valid_1's binary_logloss: 0.140422
[42]	valid_0's auc: 0.895842	valid_0's binary_logloss: 0.115755	valid_1's auc: 0.836383	valid_1's binary_logloss: 0.140503
[43]	valid_0's auc: 0.896389	valid_0's binary_logloss: 0.115503	valid_1's auc: 0.836348	valid_1's binary_logloss: 0.140505
[44]	valid_0's auc: 0.896843	valid_0's binary_logloss: 0.115204	valid_1's auc: 0.836521	valid_1's binary_logloss: 0.140518
[45]	valid_0's auc: 0.897272	valid_0's binary_logloss: 0.114886	valid_1's auc: 0.836311	valid_1's binary_logloss: 0.140581
[46]	valid_0's auc: 0.898034	valid_0's binary_logloss: 0.114544	valid_1's auc: 0.835871	valid_1's binary_logloss: 0.140663
[47]	valid_0's auc: 0.898562	valid_0's binary_logloss: 0.114262	valid_1's auc: 0.835926	valid_1's binary_logloss: 0.140642
[48]	valid_0's auc: 0.898919	valid_0's binary_logloss: 0.114006	valid_1's auc: 0.835849	valid_1's binary_logloss: 0.140687
[49]	valid_0's auc: 0.899111	valid_0's binary_logloss: 0.113791	valid_1's auc: 0.835874	valid_1's binary_logloss: 0.140728
[50]	valid_0's auc: 0.89987	valid_0's binary_logloss: 0.113543	valid_1's auc: 0.835915	valid_1's binary_logloss: 0.14075
[51]	valid_0's auc: 0.90004	valid_0's binary_logloss: 0.113342	valid_1's auc: 0.835947	valid_1's binary_logloss: 0.140748
[52]	valid_0's auc: 0.900405	valid_0's binary_logloss: 0.113087	valid_1's auc: 0.836011	valid_1's binary_logloss: 0.140767
[53]	valid_0's auc: 0.900828	valid_0's binary_logloss: 0.112831	valid_1's auc: 0.836259	valid_1's binary_logloss: 0.140771
[54]	valid_0's auc: 0.901597	valid_0's binary_logloss: 0.112604	valid_1's auc: 0.836296	valid_1's binary_logloss: 0.14078
[55]	valid_0's auc: 0.901645	valid_0's binary_logloss: 0.112429	valid_1's auc: 0.836095	valid_1's binary_logloss: 0.140822
[56]	valid_0's auc: 0.902162	valid_0's binary_logloss: 0.112169	valid_1's auc: 0.835965	valid_1's binary_logloss: 0.14086
[57]	valid_0's auc: 0.902422	valid_0's binary_logloss: 0.111944	valid_1's auc: 0.835493	valid_1's binary_logloss: 0.140993
</pre>
<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[1]	training's auc: 0.824305	training's binary_logloss: 0.156217	valid_1's auc: 0.819488	valid_1's binary_logloss: 0.165016
[2]	training's auc: 0.828798	training's binary_logloss: 0.150959	valid_1's auc: 0.822075	valid_1's binary_logloss: 0.159734
[3]	training's auc: 0.839609	training's binary_logloss: 0.147147	valid_1's auc: 0.829436	valid_1's binary_logloss: 0.156119
[4]	training's auc: 0.845158	training's binary_logloss: 0.144107	valid_1's auc: 0.836147	valid_1's binary_logloss: 0.153073
[5]	training's auc: 0.847711	training's binary_logloss: 0.14162	valid_1's auc: 0.839041	valid_1's binary_logloss: 0.150773
[6]	training's auc: 0.849184	training's binary_logloss: 0.139622	valid_1's auc: 0.839076	valid_1's binary_logloss: 0.148948
[7]	training's auc: 0.85094	training's binary_logloss: 0.13786	valid_1's auc: 0.839943	valid_1's binary_logloss: 0.147346
[8]	training's auc: 0.853386	training's binary_logloss: 0.136418	valid_1's auc: 0.84098	valid_1's binary_logloss: 0.146068
[9]	training's auc: 0.854751	training's binary_logloss: 0.135188	valid_1's auc: 0.840686	valid_1's binary_logloss: 0.14506
[10]	training's auc: 0.855887	training's binary_logloss: 0.134098	valid_1's auc: 0.841299	valid_1's binary_logloss: 0.144134
[11]	training's auc: 0.856935	training's binary_logloss: 0.133117	valid_1's auc: 0.841659	valid_1's binary_logloss: 0.14327
[12]	training's auc: 0.858464	training's binary_logloss: 0.132253	valid_1's auc: 0.841543	valid_1's binary_logloss: 0.14261
[13]	training's auc: 0.859951	training's binary_logloss: 0.131471	valid_1's auc: 0.841645	valid_1's binary_logloss: 0.14205
[14]	training's auc: 0.861343	training's binary_logloss: 0.130767	valid_1's auc: 0.841389	valid_1's binary_logloss: 0.14164
[15]	training's auc: 0.863266	training's binary_logloss: 0.130102	valid_1's auc: 0.84154	valid_1's binary_logloss: 0.141254
[16]	training's auc: 0.864645	training's binary_logloss: 0.129469	valid_1's auc: 0.841108	valid_1's binary_logloss: 0.140999
[17]	training's auc: 0.865605	training's binary_logloss: 0.128901	valid_1's auc: 0.840563	valid_1's binary_logloss: 0.140752
[18]	training's auc: 0.866635	training's binary_logloss: 0.128334	valid_1's auc: 0.839571	valid_1's binary_logloss: 0.140569
[19]	training's auc: 0.867769	training's binary_logloss: 0.127836	valid_1's auc: 0.839656	valid_1's binary_logloss: 0.14032
[20]	training's auc: 0.868754	training's binary_logloss: 0.127334	valid_1's auc: 0.839451	valid_1's binary_logloss: 0.140153
[21]	training's auc: 0.86983	training's binary_logloss: 0.12692	valid_1's auc: 0.839806	valid_1's binary_logloss: 0.139937
[22]	training's auc: 0.870884	training's binary_logloss: 0.126484	valid_1's auc: 0.839529	valid_1's binary_logloss: 0.13983
[23]	training's auc: 0.871649	training's binary_logloss: 0.126082	valid_1's auc: 0.839217	valid_1's binary_logloss: 0.139727
[24]	training's auc: 0.872461	training's binary_logloss: 0.125727	valid_1's auc: 0.838771	valid_1's binary_logloss: 0.139684
[25]	training's auc: 0.873292	training's binary_logloss: 0.125365	valid_1's auc: 0.838891	valid_1's binary_logloss: 0.139609
[26]	training's auc: 0.874599	training's binary_logloss: 0.124992	valid_1's auc: 0.839175	valid_1's binary_logloss: 0.139492
[27]	training's auc: 0.875485	training's binary_logloss: 0.124654	valid_1's auc: 0.83916	valid_1's binary_logloss: 0.139441
[28]	training's auc: 0.876195	training's binary_logloss: 0.124346	valid_1's auc: 0.838877	valid_1's binary_logloss: 0.139445
[29]	training's auc: 0.877178	training's binary_logloss: 0.124027	valid_1's auc: 0.839368	valid_1's binary_logloss: 0.139322
[30]	training's auc: 0.878447	training's binary_logloss: 0.123667	valid_1's auc: 0.838922	valid_1's binary_logloss: 0.139324
[31]	training's auc: 0.879197	training's binary_logloss: 0.123402	valid_1's auc: 0.838453	valid_1's binary_logloss: 0.139316
[32]	training's auc: 0.880183	training's binary_logloss: 0.123092	valid_1's auc: 0.838572	valid_1's binary_logloss: 0.139283
[33]	training's auc: 0.881377	training's binary_logloss: 0.122805	valid_1's auc: 0.838535	valid_1's binary_logloss: 0.139271
[34]	training's auc: 0.882181	training's binary_logloss: 0.122567	valid_1's auc: 0.83825	valid_1's binary_logloss: 0.139275
[35]	training's auc: 0.883237	training's binary_logloss: 0.122275	valid_1's auc: 0.838533	valid_1's binary_logloss: 0.139208
[36]	training's auc: 0.884433	training's binary_logloss: 0.121989	valid_1's auc: 0.838446	valid_1's binary_logloss: 0.139217
[37]	training's auc: 0.885423	training's binary_logloss: 0.121707	valid_1's auc: 0.838379	valid_1's binary_logloss: 0.139221
[38]	training's auc: 0.88628	training's binary_logloss: 0.121411	valid_1's auc: 0.838156	valid_1's binary_logloss: 0.139254
[39]	training's auc: 0.886985	training's binary_logloss: 0.121175	valid_1's auc: 0.838432	valid_1's binary_logloss: 0.139181
[40]	training's auc: 0.887543	training's binary_logloss: 0.120933	valid_1's auc: 0.838247	valid_1's binary_logloss: 0.139215
[41]	training's auc: 0.888425	training's binary_logloss: 0.120677	valid_1's auc: 0.83826	valid_1's binary_logloss: 0.139218
GridSearchCV 최적 파라미터: {'max_depth': 128, 'min_child_samples': 100, 'num_leaves': 32, 'subsample': 0.8}
ROC AUC: 0.8417
</pre>

```python
### 최적화된 파라미터를 LightGBM에 다시 적용

lgbm_clf = LGBMClassifier(n_estimators = 1000, num_leaves = 32, sumbsample = 0.8, 
                          min_child_samples = 100, max_depth = 128)

evals = [(X_test, y_test)]
lgbm_clf.fit(X_train, y_train, early_stopping_rounds = 100, 
             eval_metric = "auc", eval_set = evals, verbose = True)

lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:,1],average = 'macro')
print('ROC AUC: {0:.4f}'.format(lgbm_roc_score))
```

<pre>
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.
  _log_warning("'verbose' argument is deprecated and will be removed in a future release of LightGBM. "
</pre>
<pre>
[LightGBM] [Warning] Unknown parameter: sumbsample
[1]	valid_0's auc: 0.819488	valid_0's binary_logloss: 0.165016
[2]	valid_0's auc: 0.822075	valid_0's binary_logloss: 0.159734
[3]	valid_0's auc: 0.829436	valid_0's binary_logloss: 0.156119
[4]	valid_0's auc: 0.836147	valid_0's binary_logloss: 0.153073
[5]	valid_0's auc: 0.839041	valid_0's binary_logloss: 0.150773
[6]	valid_0's auc: 0.839076	valid_0's binary_logloss: 0.148948
[7]	valid_0's auc: 0.839943	valid_0's binary_logloss: 0.147346
[8]	valid_0's auc: 0.84098	valid_0's binary_logloss: 0.146068
[9]	valid_0's auc: 0.840686	valid_0's binary_logloss: 0.14506
[10]	valid_0's auc: 0.841299	valid_0's binary_logloss: 0.144134
[11]	valid_0's auc: 0.841659	valid_0's binary_logloss: 0.14327
[12]	valid_0's auc: 0.841543	valid_0's binary_logloss: 0.14261
[13]	valid_0's auc: 0.841645	valid_0's binary_logloss: 0.14205
[14]	valid_0's auc: 0.841389	valid_0's binary_logloss: 0.14164
[15]	valid_0's auc: 0.84154	valid_0's binary_logloss: 0.141254
[16]	valid_0's auc: 0.841108	valid_0's binary_logloss: 0.140999
[17]	valid_0's auc: 0.840563	valid_0's binary_logloss: 0.140752
[18]	valid_0's auc: 0.839571	valid_0's binary_logloss: 0.140569
[19]	valid_0's auc: 0.839656	valid_0's binary_logloss: 0.14032
[20]	valid_0's auc: 0.839451	valid_0's binary_logloss: 0.140153
[21]	valid_0's auc: 0.839806	valid_0's binary_logloss: 0.139937
[22]	valid_0's auc: 0.839529	valid_0's binary_logloss: 0.13983
[23]	valid_0's auc: 0.839217	valid_0's binary_logloss: 0.139727
[24]	valid_0's auc: 0.838771	valid_0's binary_logloss: 0.139684
[25]	valid_0's auc: 0.838891	valid_0's binary_logloss: 0.139609
[26]	valid_0's auc: 0.839175	valid_0's binary_logloss: 0.139492
[27]	valid_0's auc: 0.83916	valid_0's binary_logloss: 0.139441
[28]	valid_0's auc: 0.838877	valid_0's binary_logloss: 0.139445
[29]	valid_0's auc: 0.839368	valid_0's binary_logloss: 0.139322
[30]	valid_0's auc: 0.838922	valid_0's binary_logloss: 0.139324
[31]	valid_0's auc: 0.838453	valid_0's binary_logloss: 0.139316
[32]	valid_0's auc: 0.838572	valid_0's binary_logloss: 0.139283
[33]	valid_0's auc: 0.838535	valid_0's binary_logloss: 0.139271
[34]	valid_0's auc: 0.83825	valid_0's binary_logloss: 0.139275
[35]	valid_0's auc: 0.838533	valid_0's binary_logloss: 0.139208
[36]	valid_0's auc: 0.838446	valid_0's binary_logloss: 0.139217
[37]	valid_0's auc: 0.838379	valid_0's binary_logloss: 0.139221
[38]	valid_0's auc: 0.838156	valid_0's binary_logloss: 0.139254
[39]	valid_0's auc: 0.838432	valid_0's binary_logloss: 0.139181
[40]	valid_0's auc: 0.838247	valid_0's binary_logloss: 0.139215
[41]	valid_0's auc: 0.83826	valid_0's binary_logloss: 0.139218
[42]	valid_0's auc: 0.838578	valid_0's binary_logloss: 0.139154
[43]	valid_0's auc: 0.83859	valid_0's binary_logloss: 0.139169
[44]	valid_0's auc: 0.838508	valid_0's binary_logloss: 0.139168
[45]	valid_0's auc: 0.838529	valid_0's binary_logloss: 0.139115
[46]	valid_0's auc: 0.838474	valid_0's binary_logloss: 0.139123
[47]	valid_0's auc: 0.839008	valid_0's binary_logloss: 0.139046
[48]	valid_0's auc: 0.838863	valid_0's binary_logloss: 0.139068
[49]	valid_0's auc: 0.83888	valid_0's binary_logloss: 0.13906
[50]	valid_0's auc: 0.838809	valid_0's binary_logloss: 0.139075
[51]	valid_0's auc: 0.83859	valid_0's binary_logloss: 0.139096
[52]	valid_0's auc: 0.838282	valid_0's binary_logloss: 0.139147
[53]	valid_0's auc: 0.838288	valid_0's binary_logloss: 0.139141
[54]	valid_0's auc: 0.838278	valid_0's binary_logloss: 0.139142
[55]	valid_0's auc: 0.838434	valid_0's binary_logloss: 0.139125
[56]	valid_0's auc: 0.838412	valid_0's binary_logloss: 0.139145
[57]	valid_0's auc: 0.838626	valid_0's binary_logloss: 0.139127
[58]	valid_0's auc: 0.838384	valid_0's binary_logloss: 0.139188
[59]	valid_0's auc: 0.838063	valid_0's binary_logloss: 0.139236
[60]	valid_0's auc: 0.838145	valid_0's binary_logloss: 0.13923
[61]	valid_0's auc: 0.837988	valid_0's binary_logloss: 0.139245
[62]	valid_0's auc: 0.838005	valid_0's binary_logloss: 0.139256
[63]	valid_0's auc: 0.837845	valid_0's binary_logloss: 0.139268
[64]	valid_0's auc: 0.837656	valid_0's binary_logloss: 0.139293
[65]	valid_0's auc: 0.837549	valid_0's binary_logloss: 0.139317
[66]	valid_0's auc: 0.83779	valid_0's binary_logloss: 0.139279
[67]	valid_0's auc: 0.837827	valid_0's binary_logloss: 0.1393
[68]	valid_0's auc: 0.837746	valid_0's binary_logloss: 0.13934
[69]	valid_0's auc: 0.837685	valid_0's binary_logloss: 0.139328
[70]	valid_0's auc: 0.837589	valid_0's binary_logloss: 0.139355
[71]	valid_0's auc: 0.837816	valid_0's binary_logloss: 0.139335
[72]	valid_0's auc: 0.837883	valid_0's binary_logloss: 0.139324
[73]	valid_0's auc: 0.837614	valid_0's binary_logloss: 0.139416
[74]	valid_0's auc: 0.837565	valid_0's binary_logloss: 0.139416
[75]	valid_0's auc: 0.837359	valid_0's binary_logloss: 0.139475
[76]	valid_0's auc: 0.837393	valid_0's binary_logloss: 0.139458
[77]	valid_0's auc: 0.837358	valid_0's binary_logloss: 0.13945
[78]	valid_0's auc: 0.837298	valid_0's binary_logloss: 0.139506
[79]	valid_0's auc: 0.837193	valid_0's binary_logloss: 0.139552
[80]	valid_0's auc: 0.836945	valid_0's binary_logloss: 0.1396
[81]	valid_0's auc: 0.836893	valid_0's binary_logloss: 0.139662
[82]	valid_0's auc: 0.836907	valid_0's binary_logloss: 0.139651
[83]	valid_0's auc: 0.836779	valid_0's binary_logloss: 0.139714
[84]	valid_0's auc: 0.836733	valid_0's binary_logloss: 0.139704
[85]	valid_0's auc: 0.836814	valid_0's binary_logloss: 0.139706
[86]	valid_0's auc: 0.836638	valid_0's binary_logloss: 0.139738
[87]	valid_0's auc: 0.836471	valid_0's binary_logloss: 0.139816
[88]	valid_0's auc: 0.836511	valid_0's binary_logloss: 0.139833
[89]	valid_0's auc: 0.836355	valid_0's binary_logloss: 0.13986
[90]	valid_0's auc: 0.836314	valid_0's binary_logloss: 0.139907
[91]	valid_0's auc: 0.836143	valid_0's binary_logloss: 0.139945
[92]	valid_0's auc: 0.836124	valid_0's binary_logloss: 0.139954
[93]	valid_0's auc: 0.836073	valid_0's binary_logloss: 0.139961
[94]	valid_0's auc: 0.83596	valid_0's binary_logloss: 0.139981
[95]	valid_0's auc: 0.835924	valid_0's binary_logloss: 0.140014
[96]	valid_0's auc: 0.835947	valid_0's binary_logloss: 0.140001
[97]	valid_0's auc: 0.835798	valid_0's binary_logloss: 0.140069
[98]	valid_0's auc: 0.835699	valid_0's binary_logloss: 0.140112
[99]	valid_0's auc: 0.835598	valid_0's binary_logloss: 0.140139
[100]	valid_0's auc: 0.835567	valid_0's binary_logloss: 0.140156
[101]	valid_0's auc: 0.83541	valid_0's binary_logloss: 0.140183
[102]	valid_0's auc: 0.835235	valid_0's binary_logloss: 0.140234
[103]	valid_0's auc: 0.835304	valid_0's binary_logloss: 0.140213
[104]	valid_0's auc: 0.834946	valid_0's binary_logloss: 0.140301
[105]	valid_0's auc: 0.834578	valid_0's binary_logloss: 0.140374
[106]	valid_0's auc: 0.834617	valid_0's binary_logloss: 0.140395
[107]	valid_0's auc: 0.834575	valid_0's binary_logloss: 0.14042
[108]	valid_0's auc: 0.834393	valid_0's binary_logloss: 0.140467
[109]	valid_0's auc: 0.834307	valid_0's binary_logloss: 0.14051
[110]	valid_0's auc: 0.834382	valid_0's binary_logloss: 0.14051
[111]	valid_0's auc: 0.83436	valid_0's binary_logloss: 0.14054
ROC AUC: 0.8417
</pre>
- 테스트 데이터에서의 ROC-AUC가 약 로 측정됨

