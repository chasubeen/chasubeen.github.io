---
layout: single
title:  "[ECC DS ìŠ¤í„°ë”” 9ì£¼ì°¨] Tutorial: CatBoost Overview"
categories: ML
tags: [ECC, DS, Catboost] 
author_profile: false
---

<head>
  <style>
    table.dataframe {
      white-space: normal;
      width: 100%;
      height: 240px;
      display: block;
      overflow: auto;
      font-family: Arial, sans-serif;
      font-size: 0.9rem;
      line-height: 20px;
      text-align: center;
      border: 0px !important;
    }

    table.dataframe th {
      text-align: center;
      font-weight: bold;
      padding: 8px;
    }

    table.dataframe td {
      text-align: center;
      padding: 8px;
    }

    table.dataframe tr:hover {
      background: #b8d1f3; 
    }

    .output_prompt {
      overflow: auto;
      font-size: 0.9rem;
      line-height: 1.45;
      border-radius: 0.3rem;
      -webkit-overflow-scrolling: touch;
      padding: 0.8rem;
      margin-top: 0;
      margin-bottom: 15px;
      font: 1rem Consolas, "Liberation Mono", Menlo, Courier, monospace;
      color: $code-text-color;
      border: solid 1px $border-color;
      border-radius: 0.3rem;
      word-break: normal;
      white-space: pre;
    }

  .dataframe tbody tr th:only-of-type {
      vertical-align: middle;
  }

  .dataframe tbody tr th {
      vertical-align: top;
  }

  .dataframe thead th {
      text-align: center !important;
      padding: 8px;
  }

  .page__content p {
      margin: 0 0 0px !important;
  }

  .page__content p > strong {
    font-size: 0.8rem !important;
  }

  </style>
</head>


# **0. Introduction**


- CatboostëŠ” decision treeë¥¼ ê¸°ë°˜ ëª¨ë¸ë¡œ í™œìš©í•˜ëŠ” ```gradient boosting``` ëª¨ë¸ì„ ë°œì „ì‹œí‚¨ ì•Œê³ ë¦¬ì¦˜

- CatboostëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë¬¸ì œë“¤ì„ í•´ê²°í•˜ëŠ” ë° í™œìš©ë  ìˆ˜ ìˆìŒ

  - ë¶„ë¥˜(ì´ì§„, ë‹¤ì¤‘)

  - íšŒê·€

  - ranking

- ì´ëŸ¬í•œ ì‘ì—…ë“¤ì€ ê·¸ë“¤ì˜ ```ëª©ì  í•¨ìˆ˜(objective function)```ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ

  - ê²½ì‚¬ í•˜ê°• ì¤‘ ìµœì†Œí™”í•˜ë ¤ëŠ” ê²ƒ

- CatboostëŠ” ëª¨ë¸ì˜ ì •í™•ë„ë¥¼ ì¸¡ì •í•˜ê¸° ìœ„í•´ ```ì‚¬ì „ì— êµ¬ì¶•ëœ``` í‰ê°€ ì§€í‘œ(metric)ê°€ ì¡´ì¬

- [ê³µì‹ ë„íë¨¼íŠ¸](https://catboost.ai/#benchmark)


## **ğŸ“Œ Catboostì˜ ê°•ì **

**1. ë²”ì£¼í˜• ë³€ìˆ˜ì— ëŒ€í•œ ì§€ì›**  

- ```ë²”ì£¼í˜•``` ë³€ìˆ˜ê°€ ìˆëŠ” ë°ì´í„°ì˜ ê²½ìš° CatBoostì˜ ì •í™•ë„ê°€ ë‹¤ë¥¸ ì•Œê³ ë¦¬ì¦˜ì— ë¹„í•´ ë” ì¢‹ìŒ

- ë²”ì£¼í˜• ë³€ìˆ˜ì— ëŒ€í•œ ì „ì²˜ë¦¬(ex> one-hot encoding)ê°€ í•„ìš” x

  - ëª‡ëª‡ ```í•˜ì´í¼ íŒŒë¼ë¯¸í„°```ë§Œ ì§€ì •í•˜ë©´ ok



**2. ê³¼ì í•©(overfitting) í•¸ë“¤ë§ì´ ìš©ì´**  

- CatBoostëŠ” ê¸°ì¡´ ë¶€ìŠ¤íŒ… ì•Œê³ ë¦¬ì¦˜ì˜ ëŒ€ì•ˆì¸ ```ìˆœì„œí™”ëœ``` ë¶€ìŠ¤íŒ… êµ¬í˜„ì„ í™œìš©

- ì˜ˆë¥¼ ë“¤ì–´, gradient boostingì€ ì‘ì€ ë°ì´í„°ì…‹ì— ëŒ€í•´ ì‰½ê²Œ ê³¼ì í•©ë¨

  - Catboostì—ì„œëŠ” ì´ëŸ¬í•œ ê²½ìš°ì— ëŒ€í•œ íŠ¹ë³„í•œ ë³€í˜•ì´ ì¡´ì¬ -> ê³¼ì í•© ë°©ì§€



**3. ë¹ ë¥´ê³  GPU í•™ìŠµì„ í™œìš©í•˜ê¸°ì— ìš©ì´**  

- GPU í•™ìŠµì„ ì§€ì›



**4. ë‹¤ë¥¸ ìœ ìš©í•œ í”¼ì³ë“¤**  

- ê²°ì¸¡ì¹˜ì— ëŒ€í•œ ì²˜ë¦¬

- í›Œë¥­í•œ ì‹œê°í™”



# **1. Catboost ì„¤ì¹˜**



```python
# í•´ë‹¹ ì˜ˆì œë¥¼ ìˆ˜í–‰í•˜ë ¤ë©´ 0.14.2 ì´ìƒì´ì—¬ì•¼ í•¨

!pip install catboost 
```

<pre>
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting catboost
  Downloading catboost-1.2-cp310-cp310-manylinux2014_x86_64.whl (98.6 MB)
[2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m98.6/98.6 MB[0m [31m10.0 MB/s[0m eta [36m0:00:00[0m
[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)
Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.22.4)
Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)
Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)
Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.13.1)
Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)
Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)
Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2022.7.1)
Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.0.7)
Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)
Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.39.3)
Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)
Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)
Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (8.4.0)
Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.0.9)
Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.2)
Installing collected packages: catboost
Successfully installed catboost-1.2
</pre>

```python
import catboost
print(catboost.__version__)
```

<pre>
1.2
</pre>
# **2. ë¶„ë¥˜ ì‘ì—… ìˆ˜í–‰**


## **2-1. ë¼ì´ë¸ŒëŸ¬ë¦¬ & ë°ì´í„° import**



```python
### ë¶„ë¥˜ë¥¼ ìœ„í•œ ëª¨ë“ˆ import

from catboost import CatBoostClassifier
```


```python
### ë°ì´í„° ì¤€ë¹„

from catboost import datasets

train_df, test_df = datasets.amazon() # ì˜¤ì§ ë²”ì£¼í˜• ë³€ìˆ˜ë§Œ ìˆëŠ” ê·¼ì‚¬í•œ ë°ì´í„°ì…‹

train_df.shape, test_df.shape
```

<pre>
((32769, 10), (58921, 10))
</pre>

```python
### ë°ì´í„° í™•ì¸

train_df.head()
```

<pre>
   ACTION  RESOURCE  MGR_ID  ROLE_ROLLUP_1  ROLE_ROLLUP_2  ROLE_DEPTNAME  \
0       1     39353   85475         117961         118300         123472   
1       1     17183    1540         117961         118343         123125   
2       1     36724   14457         118219         118220         117884   
3       1     36135    5396         117961         118343         119993   
4       1     42680    5905         117929         117930         119569   

   ROLE_TITLE  ROLE_FAMILY_DESC  ROLE_FAMILY  ROLE_CODE  
0      117905            117906       290919     117908  
1      118536            118536       308574     118539  
2      117879            267952        19721     117880  
3      118321            240983       290919     118322  
4      119323            123932        19793     119325  
</pre>
- train_dfì—ëŠ” label(target) ì¹¼ëŸ¼ì´ í¬í•¨ë˜ì–´ ìˆì§€ë§Œ, test_dfì™€ ì»¬ëŸ¼ì˜ ê°œìˆ˜ê°€ ë™ì¼í•¨

  - test_df ë°ì´í„° ì„¸íŠ¸ì—ë„ targetì´ í¬í•¨ë˜ì–´ ìˆë‚˜?



```python
test_df.head()
```

<pre>
   id  RESOURCE  MGR_ID  ROLE_ROLLUP_1  ROLE_ROLLUP_2  ROLE_DEPTNAME  \
0   1     78766   72734         118079         118080         117878   
1   2     40644    4378         117961         118327         118507   
2   3     75443    2395         117961         118300         119488   
3   4     43219   19986         117961         118225         118403   
4   5     42093   50015         117961         118343         119598   

   ROLE_TITLE  ROLE_FAMILY_DESC  ROLE_FAMILY  ROLE_CODE  
0      117879            118177        19721     117880  
1      118863            122008       118398     118865  
2      118172            301534       249618     118175  
3      120773            136187       118960     120774  
4      118422            300136       118424     118425  
</pre>
- target ê°’ì„ í¬í•¨í•˜ê³  ìˆëŠ” ê²ƒì€ ì•„ë‹˜

  - id ì»¬ëŸ¼ì´ ì¶”ê°€ì ìœ¼ë¡œ ìˆëŠ” ê²ƒì´ë‹¤.


- ë°ì´í„° ì„¸íŠ¸ì— ë°ì´í„°ë“¤ì´ ìˆ«ìë¡œ í¬í•¨ë˜ì–´ ìˆì§€ë§Œ, ì´ëŸ¬í•œ featureë“¤ì€ ì‹¤ì œë¡œ ê´€ë¦¬ì ID, íšŒì‚¬ ì—­í•  ì½”ë“œ ë“± ì§ì›ì˜ ë‹¤ì–‘í•œ ```ì†ì„±```ì— ëŒ€í•œ ì½”ë“œì„

  - ë”°ë¼ì„œ, ```ë²”ì£¼í˜•``` ë³€ìˆ˜ë¼ê³  í•´ì„í•´ì•¼ í•¨


## **2-2. ë°ì´í„° ì¤€ë¹„**



```python
y = train_df['ACTION']
X = train_df.drop(columns = 'ACTION') 

### ë˜ëŠ” Xë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì¤€ë¹„í•´ë„ OK
# X = train_df.drop('ACTION', axis = 1)
```


```python
X_test = test_df.drop(columns = 'id') # ë¶ˆí•„ìš”í•œ id ì»¬ëŸ¼ ì œê±°
```


```python
### ì´í›„ ë™ì¼í•œ ë°ì´í„°ë¥¼ ë‹¤ì‹œ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ seed ê°’ ì„¤ì •

SEED = 1
```


```python
from sklearn.model_selection import train_test_split

X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.25, random_state = SEED)
```

## **2-3. ëª¨ë¸ë§**


### **a) 1st - ê¸°ë³¸ ëª¨ë¸**



```python
%%time 
# ìˆ˜í–‰ ì‹œê°„ì„ ì¸¡ì •í•˜ì!

### íŒŒë¼ë¯¸í„° ëª©ë¡
params = {'loss_function': 'Logloss', # ì†ì‹¤í•¨ìˆ˜(ëª©ì í•¨ìˆ˜, objective fuction)
          'eval_metric':'AUC', # í‰ê°€ ì§€í‘œ(metric)
          'verbose':  200, # 200íšŒ ë°˜ë³µí•  ë•Œë§ˆë‹¤ êµìœ¡ ê³¼ì •ì— ëŒ€í•œ ì •ë³´ë¥¼ stdoutìœ¼ë¡œ ì¶œë ¥
          'random_seed': SEED # seed ì„¤ì •
         }

cbc_1 = CatBoostClassifier(**params) # ëª¨ë¸ ê°ì²´ ì„ ì–¸
cbc_1.fit(X_train, y_train, # í•™ìŠµí•  ë°ì´í„°
          eval_set = (X_valid, y_valid), # ê²€ì¦ìš© ë°ì´í„°
          use_best_model = True, # ëª¨ë¸ì´ í•­ìƒ ìµœì  íŒŒë¼ë¯¸í„°ë¡œ íŠœë‹ëœ ìƒíƒœë¥¼ ìœ ì§€í•˜ë„ë¡
          plot = True # ì‹œê°í™”
         );
```

<pre>
MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))
</pre>
<pre>
Learning rate set to 0.069882
0:	test: 0.5400959	best: 0.5400959 (0)	total: 57.5ms	remaining: 57.4s
200:	test: 0.8020842	best: 0.8020842 (200)	total: 2.04s	remaining: 8.13s
400:	test: 0.8237941	best: 0.8237941 (400)	total: 5.24s	remaining: 7.83s
600:	test: 0.8328464	best: 0.8330283 (598)	total: 7.02s	remaining: 4.66s
800:	test: 0.8366271	best: 0.8370599 (785)	total: 8.88s	remaining: 2.21s
999:	test: 0.8417832	best: 0.8417832 (999)	total: 10.6s	remaining: 0us

bestTest = 0.8417831567
bestIteration = 999

CPU times: user 15.5 s, sys: 942 ms, total: 16.5 s
Wall time: 10.7 s
</pre>
<pre>
<catboost.core.CatBoostClassifier at 0x7f05f08678b0>
</pre>
- ëª¨ë¸ì´ ë” ë§ì€ ë°˜ë³µì„ í†µí•´ í›ˆë ¨ëœë‹¤ë©´ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤„ ìˆ˜ ìˆìŒ(iteration ì¦ê°€ ì‹œ, default = 1000)

- ë¬´ì—‡ë³´ë‹¤ë„, ìš°ë¦¬ëŠ” ì–´ë–¤ featureë“¤ì´ ```ë²”ì£¼í˜•``` ë³€ìˆ˜ì¸ì§€ ëª…ì‹œí•´ì•¼ í•¨

  - ìœ„ ëª¨ë¸ì—ì„œ CatboostëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ëª…ì‹œí•˜ì§€ ì•Šì•„ ì´ë“¤ì„ ëª¨ë‘ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë¡œ ì²˜ë¦¬í•¨

  - ë²”ì£¼ë“¤ ì‚¬ì´ì— ```ìˆœìœ„```ê°€ ë§¤ê²¨ì§(class 2 > class 1)

  - ```cat_features = [i1,i2,...,in]```ë¡œ ë²”ì£¼í˜• ë³€ìˆ˜ì„ì„ ëª…ì‹œ



```python
### Catboostê°€ ë²”ì£¼í˜• ë³€ìˆ˜ë“¤ë¡œ ì·¨ê¸‰í•  ì¹¼ëŸ¼ì˜ index
# ë°ì´í„° ì„¸íŠ¸ì˜ ëª¨ë“  featureë“¤ì€ ë²”ì£¼í˜• ë³€ìˆ˜ì„

cat_features = list(range(X.shape[1]))
print(cat_features)
```

<pre>
[0, 1, 2, 3, 4, 5, 6, 7, 8]
</pre>

```python
### ë°©ë²• 2)

cat_features_names = X.columns # categorical featuresì˜ ì´ë¦„ì„ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œ
cat_features = [X.columns.get_loc(col) for col in cat_features_names]
print(cat_features)
```

<pre>
[0, 1, 2, 3, 4, 5, 6, 7, 8]
</pre>

```python
### ë°©ë²• 3)

condition = True # ë²”ì£¼í˜• íŠ¹ì§•ì˜ ì´ë¦„ìœ¼ë¡œë§Œ ì¶©ì¡±ë˜ì–´ì•¼ í•˜ëŠ” ì¡°ê±´ì„ ì§€ì •

cat_features_names = [col for col in X.columns if condition]
cat_features = [X.columns.get_loc(col) for col in cat_features_names]
print(cat_features)
```

<pre>
[0, 1, 2, 3, 4, 5, 6, 7, 8]
</pre>
### **b) 2nd - ë²”ì£¼í˜• ë³€ìˆ˜ ëª…ì‹œ**



```python
### ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ëª©ë¡ì„ ëª…ì‹œí•˜ì—¬ ì¬í•™ìŠµ

%%time

params = {'loss_function': 'Logloss',
          'eval_metric': 'AUC',
          'cat_features':  cat_features, # ë²”ì£¼í˜• ë³€ìˆ˜ ëª…ì‹œ
          'verbose':  200,
          'random_seed':  SEED
         }

cbc_2 = CatBoostClassifier(**params)
cbc_2.fit(X_train, y_train,
          eval_set = (X_valid, y_valid),
          use_best_model = True,
          plot = True
         );
```

<pre>
MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))
</pre>
<pre>
Learning rate set to 0.069882
0:	test: 0.5637606	best: 0.5637606 (0)	total: 69.5ms	remaining: 1m 9s
200:	test: 0.8955617	best: 0.8955872 (198)	total: 15.2s	remaining: 1m
400:	test: 0.8985912	best: 0.8987220 (386)	total: 32s	remaining: 47.9s
600:	test: 0.9004468	best: 0.9005457 (595)	total: 43s	remaining: 28.6s
800:	test: 0.8997008	best: 0.9007469 (631)	total: 55.5s	remaining: 13.8s
999:	test: 0.8985767	best: 0.9007469 (631)	total: 1m 9s	remaining: 0us

bestTest = 0.9007468588
bestIteration = 631

Shrink model to first 632 iterations.
CPU times: user 1min 35s, sys: 2.02 s, total: 1min 37s
Wall time: 1min 10s
</pre>
<pre>
<catboost.core.CatBoostClassifier at 0x7f05f08dc6a0>
</pre>
- ì´ì „ì— ë¹„í•´ ì„±ëŠ¥ì´ í–¥ìƒë¨

- ì „ì²´ì ì¸ í›ˆë ¨ ì‹œê°„ì€ ì¦ê°€í•˜ì˜€ì§€ë§Œ, ìµœê³  ì„±ëŠ¥ì€ ë” ì ì€ ë°˜ë³µìˆ˜ë¡œ ì–»ì–´ëƒ„(631íšŒ ë°˜ë³µ)



- ```early_stopping_rounds = N```ì„ ì§€ì •í•˜ì—¬ í•™ìŠµì„ ì¡°ê¸° ì¤‘ë‹¨ì‹œí‚¬ ìˆ˜ ìˆìŒ

  - N-roundì— ëŒ€í•œ metric ê²°ê³¼ê°€ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ ëª¨ë¸ì€ í•™ìŠµì„ ì¤‘ë‹¨ì‹œí‚´



```python
### early stopping ì ìš©

%%time

params = {'loss_function': 'Logloss',
          'eval_metric': 'AUC',
          'cat_features': cat_features,
          'early_stopping_rounds': 200,
          'verbose': 200,
          'random_seed': SEED
         }

cbc_2 = CatBoostClassifier(**params)
cbc_2.fit(X_train, y_train, 
          eval_set = (X_valid, y_valid), 
          use_best_model = True, 
          plot = True
         );
```

<pre>
MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))
</pre>
<pre>
Learning rate set to 0.069882
0:	test: 0.5637606	best: 0.5637606 (0)	total: 46ms	remaining: 45.9s
200:	test: 0.8955617	best: 0.8955872 (198)	total: 10.6s	remaining: 42s
400:	test: 0.8985912	best: 0.8987220 (386)	total: 24.3s	remaining: 36.3s
600:	test: 0.9004468	best: 0.9005457 (595)	total: 35.2s	remaining: 23.4s
800:	test: 0.8997008	best: 0.9007469 (631)	total: 50.2s	remaining: 12.5s
Stopped by overfitting detector  (200 iterations wait)

bestTest = 0.9007468588
bestIteration = 631

Shrink model to first 632 iterations.
CPU times: user 1min 18s, sys: 1.6 s, total: 1min 20s
Wall time: 53.3 s
</pre>
<pre>
<catboost.core.CatBoostClassifier at 0x7f05f08dfa30>
</pre>
### **c) 3rd - GPU ì—°ì‚° í™œìš©**


- ê¸°ë³¸ì ìœ¼ë¡œ CatBoostëŠ” ```CPU```ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³„ì‚°

- GPUì—ì„œ ê³„ì‚°ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ë ¤ë©´ ```task_type = 'GPU'```ë¥¼ ì§€ì •í•˜ë©´ ë¨


â€» ì½”ë©ì—ì„œ ì‹¤í–‰ ì‹œ ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ -> GPUë¡œ!



```python
### GPU í™œìš©

%%time

params = {'loss_function': 'Logloss',
          'eval_metric': 'AUC',
          'cat_features': cat_features,
          'task_type':  'GPU',
          'verbose':  200,
          'random_seed': SEED
         }

cbc_3 = CatBoostClassifier(**params)
cbc_3.fit(X_train, y_train,
          eval_set = (X_valid, y_valid), 
          use_best_model = True,
          plot = True
         );
```

<pre>
MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))
</pre>
<pre>
Learning rate set to 0.054241
</pre>
<pre>
Default metric period is 5 because AUC is/are not implemented for GPU
</pre>
<pre>
0:	test: 0.6184174	best: 0.6184174 (0)	total: 78.7ms	remaining: 1m 18s
200:	test: 0.8792616	best: 0.8792616 (200)	total: 10.7s	remaining: 42.6s
400:	test: 0.8832826	best: 0.8833058 (390)	total: 20.7s	remaining: 30.9s
600:	test: 0.8845304	best: 0.8845304 (600)	total: 33.5s	remaining: 22.3s
800:	test: 0.8854544	best: 0.8854544 (800)	total: 42.4s	remaining: 10.5s
999:	test: 0.8866701	best: 0.8867319 (995)	total: 58.1s	remaining: 0us
bestTest = 0.886731863
bestIteration = 995
Shrink model to first 996 iterations.
CPU times: user 52.6 s, sys: 14.3 s, total: 1min 6s
Wall time: 59.7 s
</pre>
<pre>
<catboost.core.CatBoostClassifier at 0x7f05f08dfbb0>
</pre>
- ì„±ëŠ¥ì´ í¬ê²Œ ê°œì„ ë˜ì§€ëŠ” ì•Šì•˜ìŒ

- ëª‡ëª‡ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë“¤ì€ ì˜¤ì§ GPU ëª¨ë“œì—ì„œë§Œ ì„¤ì • ê°€ëŠ¥í•¨

  - ```grow_policy```: íŠ¸ë¦¬ ìƒì„± ê·œì¹™

  - ```min_data_in_leaf```: ë¦¬í”„ ë…¸ë“œì˜ ìµœì†Œ í›ˆë ¨ ìƒ˜í”Œ ìˆ˜

  - ```max_leaves```: ê²°ê³¼ íŠ¸ë¦¬ì—ì„œì˜ ìµœëŒ€ ë¦¬í”„ ìˆ˜


- ì¼ë¶€ ë°ì´í„° ì„¸íŠ¸ì—ì„œëŠ” GPU í•™ìŠµì´ í›¨ì”¬ ì ì€ ì‹œê°„ì´ ì†Œìš”ë¨

- ```border_count = N```ì„ ì§€ì •í•˜ì—¬ GPU í•™ìŠµì„ ë”ìš¸ ê°€ì†í™” í•  ìˆ˜ ìˆìŒ

  - N: ê° featureì— ëŒ€í•´ ê³ ë ¤ë˜ëŠ” ë¶„í• ì˜ ìˆ˜

  - ê³µì‹ ë¬¸ì„œì—ì„œëŠ” GPU í•™ìŠµ ì‹œ ì´ë¥¼ 32ë¡œ ì„¤ì •í•  ê²ƒì„ ì œì•ˆí•¨

  - ë§ì€ ê²½ìš° ì´ëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ì—ëŠ” ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•Šì§€ë§Œ í›ˆë ¨ ì†ë„ë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚´


### **d) 4th - GPU íŒŒë¼ë¯¸í„° íŠœë‹** 



```python
%%time

params = {'loss_function': 'Logloss',
          'eval_metric': 'AUC',
          'cat_features': cat_features,
          'task_type':  'GPU',
          'border_count': 32,
          'verbose': 200,
          'random_seed': SEED
         }

cbc_4 = CatBoostClassifier(**params)
cbc_4.fit(X_train, y_train, 
          eval_set = (X_valid, y_valid), 
          use_best_model = True, 
          plot = True
         );
```

<pre>
MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))
</pre>
<pre>
Learning rate set to 0.054241
0:	test: 0.6184174	best: 0.6184174 (0)	total: 34.2ms	remaining: 34.1s
</pre>
<pre>
Default metric period is 5 because AUC is/are not implemented for GPU
</pre>
<pre>
200:	test: 0.8792616	best: 0.8792616 (200)	total: 8.22s	remaining: 32.7s
400:	test: 0.8832826	best: 0.8833058 (390)	total: 17.8s	remaining: 26.6s
600:	test: 0.8845304	best: 0.8845304 (600)	total: 27.9s	remaining: 18.5s
800:	test: 0.8854544	best: 0.8854544 (800)	total: 38.6s	remaining: 9.59s
999:	test: 0.8866701	best: 0.8867319 (995)	total: 53.8s	remaining: 0us
bestTest = 0.886731863
bestIteration = 995
Shrink model to first 996 iterations.
CPU times: user 50.7 s, sys: 11.6 s, total: 1min 2s
Wall time: 54.6 s
</pre>
<pre>
<catboost.core.CatBoostClassifier at 0x7f05f08df4f0>
</pre>
- ì„±ëŠ¥ì— í° ì°¨ì´ëŠ” ì—†ì§€ë§Œ ì†ë„ëŠ” í›¨ì”¬ ë¹¨ë¼ì¡ŒìŒ


### **e) 5th, 6th - ë³€ìˆ˜ ì„ íƒ(feature selection)**


- ê²½ìš°ì— ë”°ë¼ ì¼ë¶€ featureë“¤ì´ ```ì˜ëª»ëœ``` ì •ë³´ë¥¼ ì œê³µí•œë‹¤ê³  ì˜ì‹¬í•  ìˆ˜ ìˆìŒ

- ì´ë¥¼ ì‹¤í—˜í•´ë³´ê¸° ìœ„í•´ ìˆ˜ë§ì€ ë°ì´í„° ì¡°ê°ì„ ë§Œë“¤ê±°ë‚˜ ```ignored_slice = [i1,i2,...,in]```ìœ¼ë¡œ ëª¨ë¸ì—ì„œ ë¬´ì‹œí•  ì—´ ë²ˆí˜¸ ëª©ë¡ì„ ì§€ì •í•  ìˆ˜ ìˆìŒ



```python
### ì‹¤í—˜ 1) ë°ì´í„° ì¡°ê° ë§Œë“¤ê¸°

import numpy as np
import warnings
warnings.filterwarnings("ignore")
```


```python
np.random.seed(SEED)

noise_cols = [f'noise_{i}' for i in range(5)]
for col in noise_cols:
    X_train[col] = y_train * np.random.rand(X_train.shape[0])
    X_valid[col] = np.random.rand(X_valid.shape[0])
```


```python
X_train.head()
```

<pre>
       RESOURCE  MGR_ID  ROLE_ROLLUP_1  ROLE_ROLLUP_2  ROLE_DEPTNAME  \
16773     27798    1350         117961         118052         122938   
23491     80701    4571         117961         118225         119924   
32731     34039    5113         117961         118300         119890   
7855      42085    4733         118290         118291         120126   
16475     16358    6046         117961         118446         120317   

       ROLE_TITLE  ROLE_FAMILY_DESC  ROLE_FAMILY  ROLE_CODE   noise_0  \
16773      117905            117906       290919     117908  0.417022   
23491      118685            279443       308574     118687  0.720324   
32731      119433            133686       118424     119435  0.000114   
7855       118980            166203       118295     118982  0.302333   
16475      307024            306404       118331     118332  0.146756   

        noise_1   noise_2   noise_3   noise_4  
16773  0.097850  0.665600  0.979025  0.491624  
23491  0.855900  0.311763  0.929346  0.391708  
32731  0.287838  0.896624  0.704050  0.606467  
7855   0.264320  0.482195  0.028493  0.182570  
16475  0.022876  0.009307  0.726750  0.623357  
</pre>

```python
%%time

params = {'loss_function': 'Logloss',
          'eval_metric': 'AUC',
          'cat_features': cat_features,
          'verbose': 200,
          'random_seed': SEED
         }

cbc_5 = CatBoostClassifier(**params)
cbc_5.fit(X_train, y_train, 
          eval_set = (X_valid, y_valid), 
          use_best_model = True, 
          plot = True
         );
```

<pre>
MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))
</pre>
<pre>
Learning rate set to 0.069882
0:	test: 0.4990944	best: 0.4990944 (0)	total: 78.3ms	remaining: 1m 18s
200:	test: 0.5831370	best: 0.5894476 (7)	total: 9.93s	remaining: 39.5s
400:	test: 0.5831376	best: 0.5894476 (7)	total: 17s	remaining: 25.4s
600:	test: 0.5831376	best: 0.5894476 (7)	total: 25.4s	remaining: 16.9s
800:	test: 0.5831378	best: 0.5894476 (7)	total: 32.9s	remaining: 8.16s
999:	test: 0.5831381	best: 0.5894476 (7)	total: 38.7s	remaining: 0us

bestTest = 0.5894475816
bestIteration = 7

Shrink model to first 8 iterations.
CPU times: user 1min 4s, sys: 1.25 s, total: 1min 5s
Wall time: 39.2 s
</pre>
<pre>
<catboost.core.CatBoostClassifier at 0x7f05eeb78ac0>
</pre>
- ì„±ëŠ¥ì´ í¬ê²Œ í•˜ë½í•¨



```python
### ì‹¤í—˜ 2) ë¬´ì‹œí•  ì»¬ëŸ¼ ëª©ë¡ ì§€ì •

ignored_features = list(range(X_train.shape[1] - 5, X_train.shape[1]))
print(ignored_features)
```

<pre>
[9, 10, 11, 12, 13]
</pre>

```python
%%time

params = {'loss_function': 'Logloss',
          'eval_metric': 'AUC',
          'cat_features': cat_features,
          'ignored_features': ignored_features, # ë¬´ì‹œí•  ë³€ìˆ˜ë“¤
          'early_stopping_rounds': 200,
          'verbose': 200,
          'random_seed': SEED
         }

cbc_6 = CatBoostClassifier(**params)
cbc_6.fit(X_train, y_train, 
          eval_set = (X_valid, y_valid), 
          use_best_model = True, 
          plot = True
         );
```

<pre>
MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))
</pre>
<pre>
Learning rate set to 0.069882
0:	test: 0.5637606	best: 0.5637606 (0)	total: 42.2ms	remaining: 42.1s
200:	test: 0.8955617	best: 0.8955872 (198)	total: 10.4s	remaining: 41.3s
400:	test: 0.8985912	best: 0.8987220 (386)	total: 21.7s	remaining: 32.4s
600:	test: 0.9004468	best: 0.9005457 (595)	total: 33.4s	remaining: 22.2s
800:	test: 0.8997008	best: 0.9007469 (631)	total: 45s	remaining: 11.2s
Stopped by overfitting detector  (200 iterations wait)

bestTest = 0.9007468588
bestIteration = 631

Shrink model to first 632 iterations.
CPU times: user 1min 18s, sys: 1.44 s, total: 1min 20s
Wall time: 47 s
</pre>
<pre>
<catboost.core.CatBoostClassifier at 0x7f05eeb7b8b0>
</pre>

```python
### ì‹¤í—˜ 1ë¡œ ë§Œë“  noiseë¥¼ ì œê±°í•˜ê³  ë°ì´í„°ë¥¼ ì›ë˜ ìƒíƒœë¡œ ëŒë¦¬ê¸°

X_train = X_train.drop(columns = noise_cols)
X_valid = X_valid.drop(columns = noise_cols)
```


```python
X_train.head()
```

<pre>
       RESOURCE  MGR_ID  ROLE_ROLLUP_1  ROLE_ROLLUP_2  ROLE_DEPTNAME  \
16773     27798    1350         117961         118052         122938   
23491     80701    4571         117961         118225         119924   
32731     34039    5113         117961         118300         119890   
7855      42085    4733         118290         118291         120126   
16475     16358    6046         117961         118446         120317   

       ROLE_TITLE  ROLE_FAMILY_DESC  ROLE_FAMILY  ROLE_CODE  
16773      117905            117906       290919     117908  
23491      118685            279443       308574     118687  
32731      119433            133686       118424     119435  
7855       118980            166203       118295     118982  
16475      307024            306404       118331     118332  
</pre>
### **f) 7th - Pool ê°ì²´ í™œìš©**


- CatboostëŠ” í•™ìŠµ ë°ì´í„°ë¡œ Pool ê°ì²´ë„ ë°›ì„ ìˆ˜ ìˆìŒ

- ```Pool ê°ì²´```

  - ë²”ì£¼í˜• ì»¬ëŸ¼ ì¸ë±ìŠ¤(ì •ìˆ˜ë¡œ ì§€ì •) ë˜ëŠ” ì´ë¦„(ë¬¸ìì—´ë¡œ ì§€ì •)ì˜ 1ì°¨ì› ë°°ì—´



```python
from catboost import Pool

train_data = Pool(data = X_train,
                  label = y_train,
                  cat_features = cat_features
                 )

valid_data = Pool(data = X_valid,
                  label = y_valid,
                  cat_features = cat_features
                 )
```


```python
%%time

params = {'loss_function':'Logloss',
          'eval_metric':'AUC',
#         'cat_features': cat_features, # ì´ë¯¸ Pool ê°ì²´ì—ì„œ ì§€ì •í•¨
          'early_stopping_rounds': 200,
          'verbose': 200,
          'random_seed': SEED
         }

cbc_7 = CatBoostClassifier(**params)
cbc_7.fit(train_data, # instead of X_train, y_train
          eval_set = valid_data, # instead of (X_valid, y_valid)
          use_best_model = True, 
          plot = True
         );
```

<pre>
MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))
</pre>
<pre>
Learning rate set to 0.069882
0:	test: 0.5637606	best: 0.5637606 (0)	total: 44.6ms	remaining: 44.6s
200:	test: 0.8955617	best: 0.8955872 (198)	total: 13.6s	remaining: 54.2s
400:	test: 0.8985912	best: 0.8987220 (386)	total: 27.7s	remaining: 41.4s
600:	test: 0.9004468	best: 0.9005457 (595)	total: 49.6s	remaining: 32.9s
800:	test: 0.8997008	best: 0.9007469 (631)	total: 1m 2s	remaining: 15.5s
Stopped by overfitting detector  (200 iterations wait)

bestTest = 0.9007468588
bestIteration = 631

Shrink model to first 632 iterations.
CPU times: user 1min 19s, sys: 1.65 s, total: 1min 20s
Wall time: 1min 4s
</pre>
<pre>
<catboost.core.CatBoostClassifier at 0x7f05f08df190>
</pre>
### **ğŸ“Œ Pool ê°ì²´ë¥¼ í™œìš©í•˜ëŠ” ì´ìœ **

- ì˜ˆë¥¼ ë“¤ì–´, ë°ì´í„°ì˜ ì¼ë¶€ê°€ êµ¬ì‹ì´ê±°ë‚˜ ë¶€ì •í™•í•  ìˆ˜ ìˆìŒ

  - ```Pool.set_weight()```ë¥¼ í†µí•´ ë°ì´í„°ì˜ ì¸ìŠ¤í„´ìŠ¤(=> í–‰)ì— ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•  ìˆ˜ ìˆìŒ

- ë˜ëŠ” Poolì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ê·¸ë£¹ì„ ë‚˜ëˆŒ ìˆ˜ ìˆìŒ

  - ```set_group_id()```ë¥¼ ì§€ì •í•˜ê³  ```Pool.set_group_weight()```ì„ í™œìš©í•˜ì—¬ ì„œë¡œ ë‹¤ë¥¸ ê·¸ë£¹ì— ëŒ€í•´ ì„œë¡œ ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•  ìˆ˜ ìˆìŒ



- ê¸°ì¤€ì„ ì„ ê³„ì‚°í•  ìˆ˜ ìˆìŒ

  - ```Pool.set_baseline()```ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ì…ë ¥ ê°œì²´ì— ëŒ€í•œ ì´ˆê¸° ìˆ˜ì‹ ê°’ì„ ì œê³µí•  ìˆ˜ ìˆìŒ

  - í›ˆë ¨ì´ 0ì—ì„œ ì‹œì‘í•˜ëŠ” ê²ƒì´ ì•„ë‹Œ ì§€ì •ëœ ê°’ì—ì„œ ì‹œì‘í•¨

- Pool ê°ì²´ëŠ” ë°ì´í„°ì˜ ê²½ê³„ ë¶€ë¶„ì„ í¬í•¨í•  ìˆ˜ ìˆëŠ” ì¢‹ì€ ë°©ë²•ì„





### **g) 8th - êµì°¨ ê²€ì¦(Cross Validation)**



```python
from catboost import cv
```


```python
%%time

params = {'loss_function': 'Logloss',
          'eval_metric': 'AUC',
          'verbose': 200,
          'random_seed': SEED
         }

all_train_data = Pool(data = X,
                      label = y,
                      cat_features = cat_features
                     )

scores = cv(pool = all_train_data,
            params = params, 
            fold_count = 4,
            seed = SEED, 
            shuffle = True,
            stratified = True, # Trueë©´ ê° í´ë˜ìŠ¤ì— ëŒ€í•œ í‘œë³¸ ë¹„ìœ¨ì„ ë³´ì¡´í•˜ë©° fold ìƒì„±
            plot = True
           )
```

<pre>
MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))
</pre>
<pre>
Training on fold [0/4]
0:	test: 0.5000000	best: 0.5000000 (0)	total: 15.7ms	remaining: 15.7s
200:	test: 0.8948050	best: 0.8948050 (200)	total: 11.1s	remaining: 44s
400:	test: 0.8993043	best: 0.8993043 (400)	total: 22.7s	remaining: 33.9s
600:	test: 0.9019037	best: 0.9019037 (600)	total: 36.6s	remaining: 24.3s
800:	test: 0.9027905	best: 0.9031492 (781)	total: 48.8s	remaining: 12.1s
999:	test: 0.9036792	best: 0.9036792 (999)	total: 1m 1s	remaining: 0us

bestTest = 0.9036791642
bestIteration = 999

Training on fold [1/4]
0:	test: 0.5000000	best: 0.5000000 (0)	total: 16.8ms	remaining: 16.7s
200:	test: 0.8835559	best: 0.8840146 (166)	total: 10.4s	remaining: 41.3s
400:	test: 0.8852191	best: 0.8853875 (382)	total: 23.1s	remaining: 34.5s
600:	test: 0.8859059	best: 0.8859447 (591)	total: 36.8s	remaining: 24.4s
800:	test: 0.8860087	best: 0.8865844 (746)	total: 49.7s	remaining: 12.3s
999:	test: 0.8841890	best: 0.8865844 (746)	total: 1m 2s	remaining: 0us

bestTest = 0.8865843778
bestIteration = 746

Training on fold [2/4]
0:	test: 0.5000000	best: 0.5000000 (0)	total: 60.1ms	remaining: 1m
200:	test: 0.8762431	best: 0.8762994 (198)	total: 11.4s	remaining: 45.5s
400:	test: 0.8825299	best: 0.8825365 (399)	total: 24.9s	remaining: 37.1s
600:	test: 0.8859397	best: 0.8859462 (593)	total: 38.5s	remaining: 25.6s
800:	test: 0.8876071	best: 0.8876071 (800)	total: 52.4s	remaining: 13s
999:	test: 0.8890818	best: 0.8890895 (998)	total: 1m 7s	remaining: 0us

bestTest = 0.8890894812
bestIteration = 998

Training on fold [3/4]
0:	test: 0.5000000	best: 0.5000000 (0)	total: 15.7ms	remaining: 15.7s
200:	test: 0.8848750	best: 0.8848750 (200)	total: 11.9s	remaining: 47.2s
400:	test: 0.8886395	best: 0.8886395 (400)	total: 33.3s	remaining: 49.7s
600:	test: 0.8917459	best: 0.8917475 (599)	total: 49.4s	remaining: 32.8s
800:	test: 0.8926586	best: 0.8928882 (763)	total: 1m 3s	remaining: 15.8s
999:	test: 0.8919993	best: 0.8928882 (763)	total: 1m 18s	remaining: 0us

bestTest = 0.892888207
bestIteration = 763

CPU times: user 6min 21s, sys: 33.8 s, total: 6min 55s
Wall time: 4min 30s
</pre>

```python
### í”¼ì²˜ ì¤‘ìš”ë„ ì‹œê°í™”

import pandas as pd

feature_importance_df = cbc_7.get_feature_importance(prettified = True)
feature_importance_df
```

<pre>
         Feature Id  Importances
0          RESOURCE    19.191502
1     ROLE_DEPTNAME    15.756340
2            MGR_ID    15.621862
3     ROLE_ROLLUP_2    13.129965
4  ROLE_FAMILY_DESC    10.059007
5        ROLE_TITLE     7.790703
6       ROLE_FAMILY     6.412647
7     ROLE_ROLLUP_1     6.224750
8         ROLE_CODE     5.813223
</pre>

```python
### ì‹œê°í™”

from matplotlib import pyplot as plt
import seaborn as sns

plt.figure(figsize=(12, 6));
sns.barplot(x= 'Importances', y="Feature Id", data=feature_importance_df);
plt.title('CatBoost features importance:')
```

<pre>
Text(0.5, 1.0, 'CatBoost features importance:')
</pre>
<pre>
<Figure size 1200x600 with 1 Axes>
</pre>
- ë” ìì„¸íˆ ì‚´í´ë³´ì.



```python
!pip install shap
```

<pre>
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting shap
  Downloading shap-0.41.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (572 kB)
[2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m572.6/572.6 kB[0m [31m36.1 MB/s[0m eta [36m0:00:00[0m
[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.22.4)
Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.10.1)
Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)
Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.3)
Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.65.0)
Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.1)
Collecting slicer==0.0.7 (from shap)
  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)
Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.56.4)
Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)
Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.39.1)
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->shap) (67.7.2)
Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)
Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2022.7.1)
Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.2.0)
Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.1.0)
Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)
Installing collected packages: slicer, shap
Successfully installed shap-0.41.0 slicer-0.0.7
</pre>

```python
import shap
explainer = shap.TreeExplainer(cbc_7) # ëª¨ë¸ ê°ì²´
shap_values = explainer.shap_values(train_data) # í•™ìŠµìš© Pool ê°ì²´

shap.initjs()
shap.force_plot(explainer.expected_value, shap_values[:100,:], X_train.iloc[:100,:])
```

- ë™ì ì¸ ì‹œê°í™” plotì„(interactive plot)

  - ê°€ë¡œì¶•ê³¼ ì„¸ë¡œì¶• ëª¨ë‘ì— ëŒ€í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ì „í™˜í•˜ì—¬ ëª¨í˜•ì„ ë¶„ì„í•  ìˆ˜ ìˆìŒ

  


- summary plot í™•ì¸



```python
shap.summary_plot(shap_values, X_train)
```

<pre>
<Figure size 800x510 with 2 Axes>
</pre>
Look like it matters who is your manager (MGR_ID) :D



- ìœ„ ë‹¤ì´ì–´ê·¸ë¨ì—ì„œ ëª¨ë“  ì§ì›(ë°ì´í„° ì„¸íŠ¸ì˜ ì¸ìŠ¤í„´ìŠ¤/í–‰)ì€ ê° í–‰ì— ì  í•˜ë‚˜ì”©ìœ¼ë¡œ í‘œì‹œë¨

  - ì ì˜ ```x ì¢Œí‘œ```ëŠ” í•´ë‹¹ í˜•ìƒì´ ëª¨í˜•ì˜ ì˜ˆì¸¡ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì˜ë¯¸

  - ì ì˜ ```ìƒ‰ìƒ```ì€ í•´ë‹¹ ì§ì›ì— ëŒ€í•œ í•´ë‹¹ featureì˜ ê°’ì„ ì˜ë¯¸

  - í–‰ì— ë§ì§€ ì•ŠëŠ” ì ë“¤ì€ ìŒ“ì—¬ì„œ ë°€ë„ë¥¼ í‘œí˜„

- ì—¬ê¸°ì„œ ```ROLE_ROLLUP_1``` ë° ```ROLE_CODE``` í”¼ì³ëŠ” ëª¨ë¸ ì˜ˆì¸¡ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ ì ìœ¼ë©°, ëŒ€ë¶€ë¶„ì˜ ì§ì›ì˜ ê²½ìš° ì˜í–¥ì´ ê±°ì˜ ì—†ìŒì„ ì•Œ ìˆ˜ ìˆìŒ


## **2-5. ìµœì¢… ì˜ˆì¸¡(Prediction)**



```python
%%time

from sklearn.model_selection import StratifiedKFold

n_fold = 4 # amount of data folds
folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=SEED)

params = {'loss_function':'Logloss',
          'eval_metric':'AUC',
          'verbose': 200,
          'random_seed': SEED
         }

test_data = Pool(data=X_test,
                 cat_features=cat_features)

scores = []
prediction = np.zeros(X_test.shape[0])
for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):
    
    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index] # train and validation data splits
    y_train, y_valid = y[train_index], y[valid_index]
    
    train_data = Pool(data=X_train, 
                      label=y_train,
                      cat_features=cat_features)
    valid_data = Pool(data=X_valid, 
                      label=y_valid,
                      cat_features=cat_features)
    
    model = CatBoostClassifier(**params)
    model.fit(train_data,
              eval_set=valid_data, 
              use_best_model=True
             )
    
    score = model.get_best_score()['validation']['AUC']
    scores.append(score)

    y_pred = model.predict_proba(test_data)[:, 1]
    prediction += y_pred

prediction /= n_fold
print('CV mean: {:.4f}, CV std: {:.4f}'.format(np.mean(scores), np.std(scores)))
```

<pre>
Learning rate set to 0.069882
0:	test: 0.5797111	best: 0.5797111 (0)	total: 89.7ms	remaining: 1m 29s
200:	test: 0.8638646	best: 0.8638646 (200)	total: 11.6s	remaining: 46.1s
400:	test: 0.8690869	best: 0.8691354 (377)	total: 22.8s	remaining: 34.1s
600:	test: 0.8730484	best: 0.8730484 (600)	total: 34.1s	remaining: 22.6s
800:	test: 0.8758933	best: 0.8761898 (791)	total: 45.1s	remaining: 11.2s
999:	test: 0.8758019	best: 0.8767012 (846)	total: 56.1s	remaining: 0us

bestTest = 0.8767012179
bestIteration = 846

Shrink model to first 847 iterations.
Learning rate set to 0.069883
0:	test: 0.5000000	best: 0.5000000 (0)	total: 31.2ms	remaining: 31.2s
200:	test: 0.8946113	best: 0.8947113 (198)	total: 10.6s	remaining: 42s
400:	test: 0.9000046	best: 0.9000046 (400)	total: 22s	remaining: 32.8s
600:	test: 0.9016458	best: 0.9017362 (584)	total: 33.5s	remaining: 22.2s
800:	test: 0.9017343	best: 0.9020394 (723)	total: 45.1s	remaining: 11.2s
999:	test: 0.8998936	best: 0.9021903 (817)	total: 56.4s	remaining: 0us

bestTest = 0.9021902605
bestIteration = 817

Shrink model to first 818 iterations.
Learning rate set to 0.069883
0:	test: 0.5000000	best: 0.5000000 (0)	total: 14.2ms	remaining: 14.2s
200:	test: 0.9042458	best: 0.9043000 (199)	total: 10.6s	remaining: 42.3s
400:	test: 0.9046762	best: 0.9059032 (260)	total: 22s	remaining: 32.8s
600:	test: 0.9027506	best: 0.9059032 (260)	total: 33s	remaining: 21.9s
800:	test: 0.9008662	best: 0.9059032 (260)	total: 44.1s	remaining: 10.9s
999:	test: 0.8987709	best: 0.9059032 (260)	total: 54.5s	remaining: 0us

bestTest = 0.9059031548
bestIteration = 260

Shrink model to first 261 iterations.
Learning rate set to 0.069883
0:	test: 0.5000000	best: 0.5000000 (0)	total: 28.8ms	remaining: 28.8s
200:	test: 0.8951500	best: 0.8951673 (199)	total: 10.4s	remaining: 41.5s
400:	test: 0.8960953	best: 0.8963737 (320)	total: 21.9s	remaining: 32.8s
600:	test: 0.8974762	best: 0.8976249 (598)	total: 33.2s	remaining: 22s
800:	test: 0.8980579	best: 0.8981457 (794)	total: 44.5s	remaining: 11.1s
999:	test: 0.8972463	best: 0.8983501 (946)	total: 55.9s	remaining: 0us

bestTest = 0.8983501224
bestIteration = 946

Shrink model to first 947 iterations.
CV mean: 0.8958, CV std: 0.0113
CPU times: user 6min 27s, sys: 7.5 s, total: 6min 34s
Wall time: 3min 45s
</pre>
# **ğŸ“š Resources**

1. [CatBoost documentation](https://catboost.ai/en/docs/)

2. [CatBoost tutorials repository](https://github.com/catboost/tutorials)

3. [Introduction to gradient boosting on decision trees with Catboost](https://towardsdatascience.com/introduction-to-gradient-boosting-on-decision-trees-with-catboost-d511a9ccbd14)

4. [Working with categorical data: Catboost](https://medium.com/whats-your-data/working-with-categorical-data-catboost-8b5e11267a37)

5. [Interpretable Machine Learning with XGBoost](https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27)

